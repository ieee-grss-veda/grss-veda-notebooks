[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GRSS VEDA Docs",
    "section": "",
    "text": "IEEE GRSS has deployed VEDA (Developed by NASA’s Earth Science Data Systems (ESDS) Program) as a platform for the GRSS community to share and access data, stories, and example code for geospatial data analysis and visualization.\nVEDA (Visualization, Exploration and Data Analysis) is a redeployable data platform to support scientific visualization and analysis.\nBy combining interactive storytelling with open science principles, VEDA enables researchers to engage new audiences and share their analysis results effectively.\nThese docs help you use the services provided by the NASA VEDA Platform and learn about the open-source software ecosystem that it is based on."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "GRSS VEDA Docs",
    "section": "",
    "text": "IEEE GRSS has deployed VEDA (Developed by NASA’s Earth Science Data Systems (ESDS) Program) as a platform for the GRSS community to share and access data, stories, and example code for geospatial data analysis and visualization.\nVEDA (Visualization, Exploration and Data Analysis) is a redeployable data platform to support scientific visualization and analysis.\nBy combining interactive storytelling with open science principles, VEDA enables researchers to engage new audiences and share their analysis results effectively.\nThese docs help you use the services provided by the NASA VEDA Platform and learn about the open-source software ecosystem that it is based on."
  },
  {
    "objectID": "index.html#checkout-the-notebooks",
    "href": "index.html#checkout-the-notebooks",
    "title": "GRSS VEDA Docs",
    "section": "Checkout the notebooks",
    "text": "Checkout the notebooks\n\nDatasets\n\nWetland Methane Emissions, LPJ-EOSIM Model\n\n\n\nQuickstart guides\n\nGetting Started with VEDA\nDownload Assets\nMap plot\nMap plot"
  },
  {
    "objectID": "index.html#new-to-veda",
    "href": "index.html#new-to-veda",
    "title": "GRSS VEDA Docs",
    "section": "New to VEDA?",
    "text": "New to VEDA?\nLearn more about VEDA from its documentation at docs.openveda.cloud."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html",
    "title": "Get tiles from COGs",
    "section": "",
    "text": "You can launch this notbook using mybinder, by clicking the button below."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#run-this-notebook",
    "title": "Get tiles from COGs",
    "section": "",
    "text": "You can launch this notbook using mybinder, by clicking the button below."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#approach",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#approach",
    "title": "Get tiles from COGs",
    "section": "Approach",
    "text": "Approach\n\nIdentify available dates within a bounding box, which is also an area of interest (AOI) in this example, for a given collection\nRegister a dynamic tiler search for an AOI and specific date range for a given collection\nExplore different options for displaying multi-band Harmonized Landsat and Sentinel (HLS) assets with the Raster API."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#about-the-data",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#about-the-data",
    "title": "Get tiles from COGs",
    "section": "About the Data",
    "text": "About the Data\nA small subset of HLS data has been ingested to the VEDA datastore to visually explore data using the Raster API, which is a VEDA instance of (pgstac-titiler). This limited subset includes two granules for dates before and after Hurricane Maria in 2017 and Hurricane Ida in 2021.\nNote about HLS datasets: The Sentinel and Landsat assets have been “harmonized” in the sense that these products have been generated to use the same spatial resolution and grid system. Thus these 2 HLS S30 and L30 productscan be used interchangeably in algorithms. However, the individual band assets are specific to each provider. This notebook focuses on displaying HLS data with a dynamic tiler so separate examples are provided for rendering the unique band assets of each collection.\nAdditional Resources\n\nHLSL30 Dataset Landing Page\nLandsat 8 Bands and Combinations Blog\nHLSS30 Dataset Landing Page\nSentinel 2 Bands and Combinations Blog\nCQL2 STAC-API Examples\nCQL2 Playground\n\n\nimport json\nimport requests\n\nfrom folium import Map, TileLayer"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#parameters-for-investigating-hurricane-events-with-the-dynamic-tiler-and-custom-band-combinations",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#parameters-for-investigating-hurricane-events-with-the-dynamic-tiler-and-custom-band-combinations",
    "title": "Get tiles from COGs",
    "section": "Parameters for investigating hurricane events with the dynamic tiler and custom band combinations",
    "text": "Parameters for investigating hurricane events with the dynamic tiler and custom band combinations\nIn this notebook we will focus on HLS S30 data for Hurricane Ida, but Hurricane Maria and L30 parameters are provided below for further exploration.\n\n# Endpoints\nSTAC_API_URL = \"https://openveda.cloud/api/stac\"\nRASTER_API_URL = \"https://openveda.cloud/api/raster\"\n\n# Harmonized Sentinel collection id and configuration info\ns30_collection_id = \"hls-s30-002-ej-reprocessed\"\ns30_swir_assets = [\"B12\", \"B8A\", \"B04\"]\ns30_vegetation_index_assets = [\"B08\", \"B04\"]\ns30_vegetation_index_expression = \"(B08_b1-B04_b1)/(B08_b1+B04_b1)\"\ns30_vegetation_index_rescaling = \"0,1\"\ns30_vegetation_index_colormap = \"rdylgn\"\n\n# Harmonized Landsat collection id and map configuration info\nl30_collection_id = \"hls-l30-002-ej-reprocessed\"\nl30_swir_assets = [\"B07\", \"B05\", \"B04\"]\nl30_ndwi_expression = \"(B03_b1-B05_b1)/(B03_b1+B05_b1)\"\nl30_ndwi_assets = [\"B03\", \"B05\"]\nl30_ndwi_rescaling = \"0,1\"\nl30_ndwi_colormap = \"spectral\"\n\n# Search criteria for events in both HLS Events collections\nmaria_bbox = [-66.167596, 17.961538, -65.110098, 18.96772]\nmaria_temporal_range = [\"2017-10-02T00:00:00Z\", \"2017-10-17T00:00:00Z\"]\n\nida_bbox = [-90.932637, 29.705366, -89.766437, 30.71627]\nida_temporal_range = [\"2021-09-02T00:00:00Z\", \"2021-09-17T00:00:00Z\"]\n\n\nFirst, search the STAC API to find the specific dates available within timeframe of interest (Hurricane Ida)\nTo focus on a specific point in time, we will restrict the temporal range when defining the item search in the example below.\nNote: For STAC there are more succinct ways of filtering, but we will use full cql2-json syntax in this example so that the filter are reusable with the Raster API.\n\ncollections_filter = {\n    \"op\": \"=\",\n    \"args\": [{\"property\": \"collection\"}, s30_collection_id],\n}\n\nspatial_filter = {\"op\": \"s_intersects\", \"args\": [{\"property\": \"bbox\"}, ida_bbox]}\n\ntemporal_filter = {\n    \"op\": \"t_intersects\",\n    \"args\": [{\"property\": \"datetime\"}, {\"interval\": ida_temporal_range}],\n}\n\n# Additional filters can be applied for other search criteria like &lt;= maximum eo:cloud_cover in item properties\ncloud_filter = {\"op\": \"&lt;=\", \"args\": [{\"property\": \"eo:cloud_cover\"}, 80]}\n\n# Specify cql2-json filter language in search body and add sort by datetime\nsearch_body = {\n    \"filter-lang\": \"cql2-json\",\n    \"limit\": 100,\n    \"sortby\": [{\"direction\": \"asc\", \"field\": \"properties.datetime\"}],\n    \"filter\": {\n        \"op\": \"and\",\n        \"args\": [collections_filter, spatial_filter, temporal_filter, cloud_filter],\n    },\n}\n\nstac_items_response = requests.post(\n    f\"{STAC_API_URL}/search\",\n    json=search_body,\n).json()\n\n# Check how many items were matched in search\nprint(\"Number of items returned:\", stac_items_response[\"numberMatched\"])\n\n# Iterate over search results to get an array of item datetimes\n[item[\"properties\"][\"datetime\"] for item in stac_items_response[\"features\"]]\n\nNumber of items returned: 2\n\n\n['2021-09-02T16:55:09.568600+00:00', '2021-09-07T16:55:13.430530+00:00']"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#visualizing-the-data-on-a-map",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#visualizing-the-data-on-a-map",
    "title": "Get tiles from COGs",
    "section": "Visualizing the data on a map",
    "text": "Visualizing the data on a map\nThe VEDA backend is based on eoAPI, an application for searching and tiling earth observation STAC records. The application uses titiler-pgstac for dynamically mosaicing cloud optimized data from a registered STAC API search.\nTo use the dynamic tiler, register a STAC item search and then use the registered search ID to dynamically mosaic the search results on the map\n\nUpdate the temporal range in search body and register that search with the Raster API\nThe registered search id can be reused for alternate map layer visualizations.\n\nmosaic_response = requests.post(\n    f\"{RASTER_API_URL}/searches/register\",\n    json=search_body,\n).json()\nprint(json.dumps(mosaic_response, indent=2))\n\n{\n  \"id\": \"60c4cc6fc305665fce131dc218f2bb46\",\n  \"links\": [\n    {\n      \"href\": \"https://openveda.cloud/api/raster/searches/60c4cc6fc305665fce131dc218f2bb46/info\",\n      \"rel\": \"metadata\",\n      \"title\": \"Mosaic metadata\"\n    },\n    {\n      \"href\": \"https://openveda.cloud/api/raster/searches/60c4cc6fc305665fce131dc218f2bb46/{tileMatrixSetId}/tilejson.json\",\n      \"rel\": \"tilejson\",\n      \"templated\": true,\n      \"title\": \"Link for TileJSON (Template URL)\"\n    },\n    {\n      \"href\": \"https://openveda.cloud/api/raster/searches/60c4cc6fc305665fce131dc218f2bb46/{tileMatrixSetId}/WMTSCapabilities.xml\",\n      \"rel\": \"wmts\",\n      \"templated\": true,\n      \"title\": \"Link for WMTS (Template URL)\"\n    }\n  ]\n}\n\n\n\n# Get base url for tiler from the register mosaic request\ntiles_href = next(\n    link[\"href\"] for link in mosaic_response[\"links\"] if link[\"rel\"] == \"tilejson\"\n)\n\n\n\nConfigure map formatting parameters\nSee the openveda.cloud/api/raster/docs for more formatting options"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#use-the-built-in-swir-post-processing-algorithm",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#use-the-built-in-swir-post-processing-algorithm",
    "title": "Get tiles from COGs",
    "section": "Use the built-in SWIR post processing algorithm",
    "text": "Use the built-in SWIR post processing algorithm\nNote in the example below the band assets for HLS S30 are selected. The equivalent SWIR band assets for L30 are provided at the top of this notebook.\n\n# Add additional map formatting parameters to tiles url\n\n# Use default tile matrix set\ntile_matrix_set_id = \"WebMercatorQuad\"\n\ntilejson_response = requests.get(\n    tiles_href.format(tileMatrixSetId=tile_matrix_set_id),\n    params={\n        # Info to add to the tilejson response\n        \"minzoom\": 6,\n        \"maxzoom\": 12,\n        \"algorithm\": \"swir\",\n        \"assets\": s30_swir_assets\n    },\n).json()\nprint(json.dumps(tilejson_response, indent=2))\n\n{\n  \"tilejson\": \"2.2.0\",\n  \"name\": \"60c4cc6fc305665fce131dc218f2bb46\",\n  \"version\": \"1.0.0\",\n  \"scheme\": \"xyz\",\n  \"tiles\": [\n    \"https://openveda.cloud/api/raster/searches/60c4cc6fc305665fce131dc218f2bb46/tiles/WebMercatorQuad/{z}/{x}/{y}?algorithm=swir&assets=B12&assets=B8A&assets=B04\"\n  ],\n  \"minzoom\": 6,\n  \"maxzoom\": 12,\n  \"bounds\": [\n    -180.0,\n    -85.0511287798066,\n    180.00000000000009,\n    85.0511287798066\n  ],\n  \"center\": [\n    4.263256414560601e-14,\n    0.0,\n    6\n  ]\n}\n\n\n\nDisplay the data on a map\n\n# Use bbox initial zoom and map\n# Set up a map located w/in event bounds\nzoom_start = 11\nm = Map(\n    tiles=\"OpenStreetMap\",\n    location=((ida_bbox[1] + ida_bbox[3]) / 2, (ida_bbox[0] + ida_bbox[2]) / 2),\n    zoom_start=zoom_start,\n)\n\n# Add the formatted map layer\nmap_layer = TileLayer(\n    tiles=tilejson_response[\"tiles\"][0],\n    attr=\"Mosaic\",\n)\nmap_layer.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nFormat and render tiles using custom formatting\nThe titiler/raster-api supports user defined band combinations, band math expressions, rescaling, band index, resampling and more.\n\n# Add additional map formatting parameters to tiles url\n\n# Use default tile matrix set\ntile_matrix_set_id = \"WebMercatorQuad\"\n\ntilejson_response = requests.get(\n    tiles_href.format(tileMatrixSetId=tile_matrix_set_id),\n    params={\n        # Info to add to the tilejson response\n        \"minzoom\": 6,\n        \"maxzoom\": 12,\n        \"assets\": s30_vegetation_index_assets,\n        \"expression\": s30_vegetation_index_expression,\n        \"rescale\": s30_vegetation_index_rescaling,\n        \"colormap_name\": s30_vegetation_index_colormap,\n    },\n).json()\nprint(json.dumps(tilejson_response, indent=2))\n\n{\n  \"tilejson\": \"2.2.0\",\n  \"name\": \"60c4cc6fc305665fce131dc218f2bb46\",\n  \"version\": \"1.0.0\",\n  \"scheme\": \"xyz\",\n  \"tiles\": [\n    \"https://openveda.cloud/api/raster/searches/60c4cc6fc305665fce131dc218f2bb46/tiles/WebMercatorQuad/{z}/{x}/{y}?assets=B08&assets=B04&expression=%28B08_b1-B04_b1%29%2F%28B08_b1%2BB04_b1%29&rescale=0%2C1&colormap_name=rdylgn\"\n  ],\n  \"minzoom\": 6,\n  \"maxzoom\": 12,\n  \"bounds\": [\n    -180.0,\n    -85.0511287798066,\n    180.00000000000009,\n    85.0511287798066\n  ],\n  \"center\": [\n    4.263256414560601e-14,\n    0.0,\n    6\n  ]\n}\n\n\n\n# Use bbox initial zoom and map\n# Set up a map located w/in event bounds\nzoom_start = 11\nm = Map(\n    tiles=\"OpenStreetMap\",\n    location=((ida_bbox[1] + ida_bbox[3]) / 2, (ida_bbox[0] + ida_bbox[2]) / 2),\n    zoom_start=zoom_start,\n)\n\n# Add the formatted map layer\nmap_layer = TileLayer(\n    tiles=tilejson_response[\"tiles\"][0],\n    attr=\"Mosaic\",\n)\nmap_layer.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#l30-hurricane-maria-example",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#l30-hurricane-maria-example",
    "title": "Get tiles from COGs",
    "section": "L30 Hurricane Maria Example",
    "text": "L30 Hurricane Maria Example\n\ncollections_filter = {\n    \"op\": \"=\", \n    \"args\" : [{ \"property\": \"collection\" }, l30_collection_id]\n}\n\nspatial_filter = {\n    \"op\": \"s_intersects\",\n    \"args\": [\n        {\"property\": \"bbox\"}, maria_bbox\n    ]\n}\n\ntemporal_filter = {\n    \"op\": \"t_intersects\",\n    \"args\": [\n        { \"property\": \"datetime\" },\n        { \"interval\" : maria_temporal_range }\n    ]\n}\n\n# Additional filters can be applied for other search criteria like &lt;= maximum eo:cloud_cover in item properties\ncloud_filter = {\n    \"op\": \"&lt;=\",\n    \"args\": [\n        {\"property\": \"eo:cloud_cover\"},\n        80\n    ]\n}\n\n# Specify cql2-json filter language in search body and add sort by datetime\nsearch_body = {\n    \"filter-lang\": \"cql2-json\",\n    \"sortby\": [{\"direction\": \"asc\", \"field\": \"properties.datetime\"}],\n    \"filter\": {\n        \"op\": \"and\",\n        \"args\": [\n            collections_filter,\n            temporal_filter,\n            cloud_filter\n        ]\n    }\n}\n\nmosaic_response = requests.post(\n    f\"{RASTER_API_URL}/searches/register\",\n    json=search_body,\n).json()\n\n\n# Set up format for Map API url\n# Get base url for tiler from the register mosaic request\ntiles_href = next(link[\"href\"] for link in mosaic_response[\"links\"] if link[\"rel\"]==\"tilejson\")\n\n# Use default tile matrix set\ntile_matrix_set_id = \"WebMercatorQuad\"\n\ntilejson_response = requests.get(\n    tiles_href.format(tileMatrixSetId=tile_matrix_set_id),\n    params={\n        # Info to add to the tilejson response\n        \"minzoom\": 6,\n        \"maxzoom\": 12,\n        \"assets\": l30_ndwi_assets,\n        \"expression\": l30_ndwi_expression,\n        \"rescale\": l30_ndwi_rescaling,\n        \"colormap_name\": \"viridis\"\n    }\n).json()\n\n\n# Use bbox initial zoom and map\n# Set up a map located w/in event bounds\nzoom_start = 11\nm = Map(\n    tiles=\"OpenStreetMap\",\n    location=((maria_bbox[1] + maria_bbox[3]) / 2,(maria_bbox[0] + maria_bbox[2]) / 2),\n    zoom_start=zoom_start\n)\n\n# Add the formatted map layer\nmap_layer = TileLayer(\n    tiles=tilejson_response[\"tiles\"][0],\n    attr=\"Mosaic\",  \n)\nmap_layer.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html",
    "title": "Get timeseries from COGs",
    "section": "",
    "text": "You can launch this notbook using mybinder, by clicking the button below."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#run-this-notebook",
    "title": "Get timeseries from COGs",
    "section": "",
    "text": "You can launch this notbook using mybinder, by clicking the button below."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#approach",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#approach",
    "title": "Get timeseries from COGs",
    "section": "Approach",
    "text": "Approach\n\nUsing a list of STAC items and a bouding box fetch stats from /statistics endpoint\nGenerate a timeseries plot using statistics from each time step\nSpeed up workflow using Dask\n\nThe /statistics endoint is provided by the VEDA implementation of titiler. This service provides an API that can be used by websites and programmatically to produce dynamic tiles and data aggretations. For VEDA, it also provides a public interface for the data since the API is publicly accessible even though the underlying data requires AWS authentication or running on the hub.\nTitiler is a powerful tool for visualization but has inherent limitations when compared with direct data access. One of these limitations is that the body of any given request must be smaller than 16Kb. This can create issues when the request contains verbose content such as geojson. Just remember that as long as you are on the hub, you always have the ability to access the data directly and do any manipulations within the notebook.\n\nimport json\nimport sys\nimport requests\nimport folium\nimport shapely\n\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#declare-your-collection-of-interest",
    "title": "Get timeseries from COGs",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac\"\nRASTER_API_URL = \"https://openveda.cloud/api/raster\"\n\ncollection_id = \"no2-monthly\""
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#fetch-stac-collection",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#fetch-stac-collection",
    "title": "Get timeseries from COGs",
    "section": "Fetch STAC collection",
    "text": "Fetch STAC collection\nWe will use requests to fetch all the metadata about the collection of interest from STAC.\n\nresponse = requests.get(f\"{STAC_API_URL}/collections/{collection_id}\")\n\nassert response.ok, response.text\n\ncollection = response.json()\ncollection\n\n{'id': 'no2-monthly',\n 'type': 'Collection',\n 'links': [{'rel': 'items',\n   'type': 'application/geo+json',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly/items'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/'},\n  {'rel': 'self',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly'},\n  {'rel': 'http://www.opengis.net/def/rel/ogc/1.0/queryables',\n   'type': 'application/schema+json',\n   'title': 'Queryables',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly/queryables'}],\n 'title': 'NO₂',\n 'assets': {'thumbnail': {'href': 'https://thumbnails.openveda.cloud/no2--dataset-cover.jpg',\n   'type': 'image/jpeg',\n   'roles': ['thumbnail'],\n   'title': 'Thumbnail',\n   'description': 'Photo by [Mick Truyts](https://unsplash.com/photos/x6WQeNYJC1w) (Power plant shooting steam at the sky)'}},\n 'extent': {'spatial': {'bbox': [[-180.0, -90.0, 180.0, 90.0]]},\n  'temporal': {'interval': [['2016-01-01T00:00:00+00:00',\n     '2022-12-31T00:00:00+00:00']]}},\n 'license': 'MIT',\n 'renders': {'dashboard': {'bidx': [1],\n   'title': 'VEDA Dashboard Render Parameters',\n   'assets': ['cog_default'],\n   'rescale': [[0, 15000000000000000]],\n   'resampling': 'bilinear',\n   'color_formula': 'gamma r 1.05',\n   'colormap_name': 'rdbu_r'}},\n 'providers': [{'url': 'https://disc.gsfc.nasa.gov/',\n   'name': 'NASA Goddard Earth Sciences Data and Information Services Center',\n   'roles': ['producer', 'processor']},\n  {'url': 'https://www.earthdata.nasa.gov/dashboard/',\n   'name': 'NASA VEDA',\n   'roles': ['host']}],\n 'summaries': {'datetime': ['2016-01-01T00:00:00Z', '2023-09-30T00:00:00Z']},\n 'description': 'Darker colors indicate higher nitrogen dioxide (NO₂) levels and more activity. Lighter colors indicate lower levels of NO₂ and less activity. Missing pixels indicate areas of no data most likely associated with cloud cover or snow.',\n 'item_assets': {'cog_default': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': 'Default COG Layer',\n   'description': 'Cloud optimized default layer to display on map'}},\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/item-assets/v1.0.0/schema.json',\n  'https://stac-extensions.github.io/render/v1.0.0/schema.json'],\n 'dashboard:is_periodic': True,\n 'dashboard:time_density': 'month'}\n\n\n\nDescribe the periodic nature of the data\nIn the collection above we will pay particular attention to the fields that define the periodicity of the data.\n\ncollection[\"dashboard:is_periodic\"]\n\nTrue\n\n\n\ncollection[\"dashboard:time_density\"]\n\n'month'\n\n\n\ncollection[\"summaries\"]\n\n{'datetime': ['2016-01-01T00:00:00Z', '2023-09-30T00:00:00Z']}"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#fetch-stac-items",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#fetch-stac-items",
    "title": "Get timeseries from COGs",
    "section": "Fetch STAC items",
    "text": "Fetch STAC items\nGet the list of all the STAC items within this collection.\n\nresponse = requests.get(\n    f\"{STAC_API_URL}/collections/{collection_id}/items?limit=100\"\n)\n\nassert response.ok, response.text\n\nitems = response.json()[\"features\"]\nlen(items)\n\n93\n\n\nWe can inspect one of these items to get a sense of what metadata is available.\n\nitems[0]\n\n{'id': 'OMI_trno2_0.10x0.10_202309_Col3_V4.nc',\n 'bbox': [-180.0, -90.0, 180.0, 90.0],\n 'type': 'Feature',\n 'links': [{'rel': 'collection',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/'},\n  {'rel': 'self',\n   'type': 'application/geo+json',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly/items/OMI_trno2_0.10x0.10_202309_Col3_V4.nc'},\n  {'title': 'Map of Item',\n   'href': 'https://openveda.cloud/api/raster/collections/no2-monthly/items/OMI_trno2_0.10x0.10_202309_Col3_V4.nc/map?bidx=1&assets=cog_default&rescale=0%2C15000000000000000&resampling=bilinear&color_formula=gamma+r+1.05&colormap_name=rdbu_r',\n   'rel': 'preview',\n   'type': 'text/html'}],\n 'assets': {'cog_default': {'href': 's3://veda-data-store/no2-monthly/OMI_trno2_0.10x0.10_202309_Col3_V4.nc.tif',\n   'type': 'image/tiff; application=geotiff',\n   'roles': ['data', 'layer'],\n   'title': 'Default COG Layer',\n   'proj:bbox': [-180.0, -90.0, 180.0, 90.0],\n   'proj:epsg': 4326,\n   'proj:wkt2': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n   'proj:shape': [1800, 3600],\n   'description': 'Cloud optimized default layer to display on map',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -1.2676506002282294e+30,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 11639639471292416,\n      'min': -4024247454269440.0,\n      'count': 11,\n      'buckets': [24, 1128, 403168, 64788, 5583, 1096, 252, 64, 19, 4]},\n     'statistics': {'mean': 343251029873510.25,\n      'stddev': 563904505347325.8,\n      'maximum': 11639639471292416,\n      'minimum': -4024247454269440.0,\n      'valid_percent': 90.81382751464844}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [180.0, -90.0],\n      [180.0, 90.0],\n      [-180.0, 90.0],\n      [-180.0, -90.0]]]},\n   'proj:projjson': {'id': {'code': 4326, 'authority': 'EPSG'},\n    'name': 'WGS 84',\n    'type': 'GeographicCRS',\n    'datum': {'name': 'World Geodetic System 1984',\n     'type': 'GeodeticReferenceFrame',\n     'ellipsoid': {'name': 'WGS 84',\n      'semi_major_axis': 6378137,\n      'inverse_flattening': 298.257223563}},\n    '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json',\n    'coordinate_system': {'axis': [{'name': 'Geodetic latitude',\n       'unit': 'degree',\n       'direction': 'north',\n       'abbreviation': 'Lat'},\n      {'name': 'Geodetic longitude',\n       'unit': 'degree',\n       'direction': 'east',\n       'abbreviation': 'Lon'}],\n     'subtype': 'ellipsoidal'}},\n   'proj:transform': [0.1, 0.0, -180.0, 0.0, -0.1, 90.0, 0.0, 0.0, 1.0]},\n  'rendered_preview': {'title': 'Rendered preview',\n   'href': 'https://openveda.cloud/api/raster/collections/no2-monthly/items/OMI_trno2_0.10x0.10_202309_Col3_V4.nc/preview.png?bidx=1&assets=cog_default&rescale=0%2C15000000000000000&resampling=bilinear&color_formula=gamma+r+1.05&colormap_name=rdbu_r',\n   'rel': 'preview',\n   'roles': ['overview'],\n   'type': 'image/png'}},\n 'geometry': {'type': 'Polygon',\n  'coordinates': [[[-180, -90],\n    [180, -90],\n    [180, 90],\n    [-180, 90],\n    [-180, -90]]]},\n 'collection': 'no2-monthly',\n 'properties': {'end_datetime': '2023-09-30T00:00:00+00:00',\n  'start_datetime': '2023-09-01T00:00:00+00:00'},\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/raster/v1.1.0/schema.json',\n  'https://stac-extensions.github.io/projection/v1.1.0/schema.json']}"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#define-an-area-of-interest",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#define-an-area-of-interest",
    "title": "Get timeseries from COGs",
    "section": "Define an area of interest",
    "text": "Define an area of interest\nWe will be using a bounding box over metropolitan france. We’ll use that bounding box to subset the data when calculating the timeseries.\n\nfrance_bounding_box = {\n    \"type\": \"Feature\",\n    \"properties\": {\"ADMIN\": \"France\", \"ISO_A3\": \"FRA\"},\n    \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n            [\n                [-5.183429, 42.332925],\n                [8.233998, 42.332925],\n                [8.233998, 51.066135],\n                [-5.183429, 51.066135],\n                [-5.183429, 42.332925],\n            ]\n        ],\n    },\n}\n\nLet’s take a look at that box.\n\nm = folium.Map(\n    location=[40, 0],\n    zoom_start=3,\n)\n\nfolium.GeoJson(france_bounding_box, name=\"France\").add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#use-statistics-to-get-data-for-the-aoi",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#use-statistics-to-get-data-for-the-aoi",
    "title": "Get timeseries from COGs",
    "section": "Use /statistics to get data for the AOI",
    "text": "Use /statistics to get data for the AOI\nFirst, we create a generate_stats function and then we call it with the bounding box defined for France.\nNOTE: The RASTER_API expects AOI as a Feature or a FeatureCollection. The datatype of the input matches the datatype of the output. So if you use a FeatureCollection as input, you will get back a FeatureCollection.\n\ndef generate_stats(item, geojson):\n    \"\"\" Generate statistics for a particular item and AOI\n\n    NOTE: This function assumes that the AOI is a geojson `Feature`.\n    \"\"\"\n    response = requests.post(\n        f\"{RASTER_API_URL}/collections/{collection_id}/items/{item['id']}/statistics\",\n        json=geojson\n    )\n    assert response.ok, response.text\n    return {\n        **response.json()[\"properties\"][\"statistics\"][\"cog_default_b1\"],\n        \"start_datetime\": item[\"properties\"][\"start_datetime\"],\n    }\n\nLet’s run this function on a single item to get a sense of the output\n\n%%time\n\ngenerate_stats(items[0], france_bounding_box)\n\nCPU times: user 4.1 ms, sys: 0 ns, total: 4.1 ms\nWall time: 518 ms\n\n\n{'min': -387779578036224.0,\n 'max': 5971174383157248.0,\n 'mean': 1636077207936257.2,\n 'count': 11880.0,\n 'sum': 1.9436597230282736e+19,\n 'std': 808762440624020.6,\n 'median': 1506456557846528.0,\n 'majority': 1143241374171136.0,\n 'minority': -387779578036224.0,\n 'unique': 11875.0,\n 'histogram': [[120, 1616, 4274, 3441, 1384, 624, 244, 125, 40, 12],\n  [-387779578036224.0,\n   248115831504896.0,\n   884011241046016.0,\n   1519906650587136.0,\n   2155802060128256.0,\n   2791697603887104.0,\n   3427592744992768.0,\n   4063488422969344.0,\n   4699383564075008.0,\n   5335279242051584.0,\n   5971174383157248.0]],\n 'valid_percent': 100.0,\n 'masked_pixels': 0.0,\n 'valid_pixels': 11880.0,\n 'percentile_2': 395780397465600.0,\n 'percentile_98': 3847018581590016.0,\n 'start_datetime': '2023-09-01T00:00:00+00:00'}\n\n\n\nGenerate stats\nThis may take some time due to the complexity of the shape we’re requesting. See the end of this notebook for tips on how to speed this up.\n\n%%time\nstats = [generate_stats(item, france_bounding_box) for item in items]\n\nCPU times: user 282 ms, sys: 43.8 ms, total: 326 ms\nWall time: 50 s"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#plot-timeseries",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#plot-timeseries",
    "title": "Get timeseries from COGs",
    "section": "Plot timeseries",
    "text": "Plot timeseries\nIt is easier to interact with these results as a pandas dataframe so create one from the list of dicts.\n\ndf = pd.DataFrame(stats)\n\nConvert the start_datetime column to real pandas datetime dtype:\n\ndf[\"date\"] = pd.to_datetime(df[\"start_datetime\"])\n\n\nConstruct the plot\n\nfig = plt.figure(figsize=(20, 10))\n\nplt.plot(df[\"date\"], df[\"mean\"], \"black\", label=\"Mean monthly NO2 values\")\n\nplt.fill_between(\n    df[\"date\"],\n    df[\"mean\"] + df[\"std\"],\n    df[\"mean\"] - df[\"std\"],\n    facecolor=\"lightgray\",\n    interpolate=False,\n    label=\"+/- one standard devation\",\n)\n\nplt.plot(\n    df[\"date\"],\n    df[\"min\"],\n    color=\"blue\",\n    linestyle=\"-\",\n    linewidth=0.5,\n    label=\"Min monthly NO2 values\",\n)\nplt.plot(\n    df[\"date\"],\n    df[\"max\"],\n    color=\"red\",\n    linestyle=\"-\",\n    linewidth=0.5,\n    label=\"Max monhtly NO2 values\",\n)\n\nplt.legend()\nplt.title(\"NO2 Values in France (2016-2022)\")\n\nText(0.5, 1.0, 'NO2 Values in France (2016-2022)')\n\n\n\n\n\nIn this graph we can see the yearly cycles in NO2 values due to seasonal variations, as well as a slight downward slope in maximum NO2 values"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#complex-aoi",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#complex-aoi",
    "title": "Get timeseries from COGs",
    "section": "Complex AOI",
    "text": "Complex AOI\nThe values plotted above don’t correspond exactly to Fance, since the bounding box excludes Corsica and overseas territories such as Mayotte and French Polynesia, and covers parts of neighboring countries including Spain, Italy, Germany and the entirety of Luxembourg. We can fetch GeoJSON from an authoritative online source (https://gadm.org/download_country.html).\nWhile the NO2 values above correspond more or less to those of in France, we can be much more precise by using a complex geojson that represents the boundaries of France exactly, including overseas territories in the Carribean and Indian Oceans, and South America.\nNote: In this notebook we write out the whole perimeter as a MultiPolygon in geojson. In practice you will often be reading this kind of shape from a file (usually with the help of geopandas).\n\nresponse = requests.get(\n    \"https://github.com/wmgeolab/geoBoundaries/raw/9469f09/releaseData/gbOpen/FRA/ADM0/geoBoundaries-FRA-ADM0.geojson\"\n)\n\n# If anything goes wrong with this request output error contents\nassert response.ok, response.text\n\nresult = response.json()\nprint(f\"There are {len(result['features'])} features in this collection\")\n\nThere are 1 features in this collection\n\n\nThat is the geojson for a feature collection, but since there is only one feature in it we can grab just that.\n\nfrance_aoi = result[\"features\"][0]\n\nLet’s take a look at this AOI on a map\n\nm = folium.Map(\n    location=[46, 0],\n    zoom_start=5,\n)\n\nfolium.GeoJson(france_aoi, name=\"France\").add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#simplifying-the-aoi",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#simplifying-the-aoi",
    "title": "Get timeseries from COGs",
    "section": "Simplifying the AOI",
    "text": "Simplifying the AOI\nYou might notice that that is a highly detailed border. In fact it is so detailed that it is too big to pass to the Raster API. It will get rejected. The limit on the Raster API is 16 Kb. And our current AOI is roughly:\n\nsize = sys.getsizeof(json.dumps(france_aoi))\nprint(f\"{size // 1024} Kb\")\n\n137 Kb\n\n\nSo can we simplify it? Naively let’s try just using shapely’s .simplify method:\n\nfrance = shapely.from_geojson(json.dumps(france_aoi))\nfrance_simplified = france.simplify(0.01)\n\nsize = sys.getsizeof(shapely.to_geojson(france_simplified))\nprint(f\"{size // 1024} Kb\")\n\n30 Kb\n\n\nStill too big… what if we increase the tolerance? Basically you can increase it as high as you want but you’ll never get below the 16 Kb threshold because there are a ton of little islands. What if we applied a buffer and then unapplied it before simplifying:\n\nfrance_simplified = (\n    france\n        .buffer(0.1).buffer(-0.1)\n        .simplify(0.01)\n)\n\nsize = sys.getsizeof(shapely.to_geojson(france_simplified))\nprint(f\"{size // 1024} Kb\")\n\n17 Kb\n\n\nThat is getting better, but if we look at the coordinates we can see that they have a ton of precision that is unnecessary:\n\nshapely.to_geojson(france_simplified)[:100]\n\n'{\"type\":\"MultiPolygon\",\"coordinates\":[[[[8.542647846187508,42.232268053459805],[8.561307373976677,42'\n\n\nMaybe we can round all of those.\n\nfrance_simplified = shapely.set_precision(\n    france\n        .buffer(0.1).buffer(-0.1)\n        .simplify(0.01), \n    0.0001\n)\n\nsize = sys.getsizeof(shapely.to_geojson(france_simplified))\nprint(f\"{size // 1024} Kb\")\n\n7 Kb\n\n\nLet’s make sure that AOI still looks decent:\n\nm = folium.Map(\n    location=[46, 0],\n    zoom_start=5,\n)\n\nfolium.GeoJson(france_simplified, name=\"France\").add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nWe can now request the NO2 values for this AOI the same way as for the bounding box.\nNotice, however, that due to the complexity of the shape (even the simplified shape), it takes a little longer to gather the requested data as for the bounding box example above.\n\nfrance_new_aoi = {\n    **france_aoi,\n    \"geometry\": json.loads(shapely.to_geojson(france_simplified))\n}\n\n\n%%time\n\nstats = [generate_stats(item, france_new_aoi) for item in items]\n\nCPU times: user 336 ms, sys: 52.7 ms, total: 389 ms\nWall time: 36.7 s\n\n\n\naoi_df = pd.DataFrame(stats)\naoi_df[\"date\"] = pd.to_datetime(aoi_df[\"start_datetime\"])\n\nWe can compare the mean monthly NO2 values calculated when using the bounding box and when using the country’s exact borders\n\nfig = plt.figure(figsize=(20, 10))\n\nplt.plot(\n    df[\"date\"],\n    df[\"mean\"],\n    color=\"blue\",\n    label=\"Mean monthly NO2 values using bounding box\",\n)\nplt.plot(\n    aoi_df[\"date\"],\n    aoi_df[\"mean\"],\n    color=\"red\",\n    label=\"Mean monthly NO2 values using complex AOI\",\n)\n\nplt.legend()\nplt.title(\"NO2 Values in France (2016-2022)\")\n\nText(0.5, 1.0, 'NO2 Values in France (2016-2022)')\n\n\n\n\n\nWhile the difference is small, it is very interesting to note that the NO2 values calculated using the exact borders are systematically less than when using the bounding box. This may be due to the fact that the bounding box includes parts of western Germany and northern Italy that have a lot industrial activity, whereas the areas included when using the exact borders that are not included in the bounding box case, are overseas territories much less industrial activity."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#speed-things-up-parallelize-computation-with-dask",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#speed-things-up-parallelize-computation-with-dask",
    "title": "Get timeseries from COGs",
    "section": "Speed things up: parallelize computation with Dask",
    "text": "Speed things up: parallelize computation with Dask\nWe can drastically reduce the time it takes to generate the timeseries, even with the complex AOI above, by parallelizing our code. The /statistics endpoint is powered by AWS Lambda which executes each request in a separate instance. This means the requests are highly scalable. Since each statistics request is for a single timestamp, we can request statistics for multiple timesteps concurrently, and greatly reduce the amount of time needed. We will demonstrate this by using the Dask.\n\nSubmit work\nFirst we will create a Dask client. In this case we will use the threads on the same server that is running this jupyter notebook. We will submit the generate_stats function for each item in our list and collect a list of futures. This will immediately kick off work in dask. We can then gather all the results.\n\n%%time\nimport dask.distributed  # noqa\n\nwith dask.distributed.Client() as client:\n    futures = [client.submit(generate_stats, item, france_new_aoi) for item in items]\n    stats = client.gather(futures)\n\nCPU times: user 1.83 s, sys: 126 ms, total: 1.96 s\nWall time: 13.5 s\n\n\n\n\nAlternate approach\nIf you are familiar with the concurrent.futures library you can use that instead of Dask. Or you can use httpx instead of requests to fetch the statistics asynchronously."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html",
    "title": "Downsample zarr",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#run-this-notebook",
    "title": "Downsample zarr",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#approach",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#approach",
    "title": "Downsample zarr",
    "section": "Approach",
    "text": "Approach\nThis notebook demonstrates 2 strategies for resampling data from a Zarr dataset in order to visualize within the memory limits of a notebook.\n\nDownsample the temporal resolution of the data using xarray.DataArray.resample\nCoarsening the spatial resolution of the data using xarray.DataArray.coarsen\n\nA strategy for visualizing any large amount of data is Datashader which bins data into a fixed 2-D array. Using the rasterize argument within hvplot calls ensures the use of the datashader library to bin the data. Optionally an external Dask cluster is used to parallelize and distribute these large downsampling operations across compute nodes."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#about-the-data",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#about-the-data",
    "title": "Downsample zarr",
    "section": "About the data",
    "text": "About the data\nThe SMAP mission is an orbiting observatory that measures the amount of water in the surface soil everywhere on Earth."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#load-libraries",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#load-libraries",
    "title": "Downsample zarr",
    "section": "Load libraries",
    "text": "Load libraries\n\nimport xarray as xr\nimport hvplot.xarray\nimport cartopy.crs as ccrs"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#optional-create-and-scale-a-dask-cluster",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#optional-create-and-scale-a-dask-cluster",
    "title": "Downsample zarr",
    "section": "Optional: Create and Scale a Dask Cluster",
    "text": "Optional: Create and Scale a Dask Cluster\nWe create a separate Dask cluster to speed up reprojecting the data (and other potential computations which could be required and are parallelizable).\nNote if you skip this cell you will still be using Dask, you’ll just be using the machine where you are running this notebook.\n\nfrom dask_gateway import GatewayCluster, Gateway\n\ngateway = Gateway()\nclusters = gateway.list_clusters()\n\n# connect to an existing cluster - this is useful when the kernel shutdown in the middle of an interactive session\nif clusters:\n    cluster = gateway.connect(clusters[0].name)\nelse:\n    cluster = GatewayCluster(shutdown_on_close=True)\n\ncluster.scale(16)\nclient = cluster.get_client()\nclient\n\n\n     \n    \n        Client\n        Client-05313042-8cbb-11f0-816a-9ee98308dd31\n        \n\n\n\nConnection method: Cluster object\nCluster type: dask_gateway.GatewayCluster\n\n\nDashboard: /services/dask-gateway/clusters/prod.ad9ae8551f5e47a48262103ee2e6acb9/status\n\n\n\n\n\n\n        \n            \n                Launch dashboard in JupyterLab\n            \n        \n\n        \n            \n            Cluster Info\n            \n  GatewayCluster\n  \n    Name: prod.ad9ae8551f5e47a48262103ee2e6acb9\n    Dashboard: /services/dask-gateway/clusters/prod.ad9ae8551f5e47a48262103ee2e6acb9/status"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#open-the-dataset-from-s3",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#open-the-dataset-from-s3",
    "title": "Downsample zarr",
    "section": "Open the dataset from S3",
    "text": "Open the dataset from S3\n\nds = xr.open_zarr(\"s3://veda-data-store-staging/EIS/zarr/SPL3SMP.zarr\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 68GB\nDimensions:                        (northing_m: 406, easting_m: 964,\n                                    datetime: 1679)\nCoordinates:\n  * datetime                       (datetime) datetime64[ns] 13kB 2018-01-01 ...\n  * easting_m                      (easting_m) float64 8kB -1.735e+07 ... 1.7...\n  * northing_m                     (northing_m) float64 3kB 7.297e+06 ... -7....\nData variables: (12/26)\n    albedo                         (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    albedo_pm                      (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    bulk_density                   (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    bulk_density_pm                (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    clay_fraction                  (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    clay_fraction_pm               (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    ...                             ...\n    static_water_body_fraction     (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    static_water_body_fraction_pm  (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    surface_flag                   (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    surface_flag_pm                (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    surface_temperature            (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    surface_temperature_pm         (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;xarray.DatasetDimensions:northing_m: 406easting_m: 964datetime: 1679Coordinates: (3)datetime(datetime)datetime64[ns]2018-01-01 ... 2022-09-09array(['2018-01-01T00:00:00.000000000', '2018-01-02T00:00:00.000000000',\n       '2018-01-03T00:00:00.000000000', ..., '2022-09-07T00:00:00.000000000',\n       '2022-09-08T00:00:00.000000000', '2022-09-09T00:00:00.000000000'],\n      shape=(1679,), dtype='datetime64[ns]')easting_m(easting_m)float64-1.735e+07 -1.731e+07 ... 1.735e+07array([-17349514.34, -17313482.12, -17277449.9 , ...,  17277449.08,\n        17313481.3 ,  17349513.52], shape=(964,))northing_m(northing_m)float647.297e+06 7.26e+06 ... -7.297e+06array([ 7296524.72,  7260492.5 ,  7224460.28, ..., -7224459.94, -7260492.16,\n       -7296524.38], shape=(406,))Data variables: (26)albedo(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Diffuse reflecting power of the Earth&apos;s surface used in DCA within the grid cell.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\nalbedo_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nDiffuse reflecting power of the Earth&apos;s surface used in DCA retrievals within the grid cell.\n\nvalid_max :\n\n1.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nbulk_density\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nA unitless value that is indicative of aggregated bulk_density within the 36 km grid cell.\n\nvalid_max :\n\n2.6500000953674316\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nbulk_density_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nA unitless value that is indicative of aggregated bulk density within the 36 km grid cell.\n\nvalid_max :\n\n2.6500000953674316\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nclay_fraction\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nA unitless value that is indicative of aggregated clay fraction within the 36 km grid cell.\n\nvalid_max :\n\n1.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nclay_fraction_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nA unitless value that is indicative of aggregated clay fraction within the 36 km grid cell.\n\nvalid_max :\n\n1.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nfreeze_thaw_fraction\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nFraction of the 36 km grid cell that is denoted as frozen. Based on binary flag that specifies freeze thaw conditions in each of the component 3 km grid cells.\n\nvalid_max :\n\n1.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nfreeze_thaw_fraction_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nFraction of the 36 km grid cell that is denoted as frozen. Based on binary flag that specifies freeze thaw conditions in each of the component 3 km grid cells.\n\nvalid_max :\n\n1.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\ngrid_surface_status\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nIndicates if the grid point lies on land (0) or water (1).\n\nvalid_max :\n\n1\n\nvalid_min :\n\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\ngrid_surface_status_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nIndicates if the grid point lies on land (0) or water (1).\n\nvalid_max :\n\n1\n\nvalid_min :\n\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nradar_water_body_fraction\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nThe fraction of the area of the 36 km grid cell that is covered by water based on the radar detection algorithm.\n\nvalid_max :\n\n1.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nradar_water_body_fraction_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nThe fraction of the area of the 36 km grid cell that is covered by water based on the radar detection algorithm.\n\nvalid_max :\n\n1.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nretrieval_qual_flag\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nflag_masks :\n\n1s, 2s, 4s, 8s\n\nflag_meanings :\n\nRetrieval_recommended Retrieval_attempted Retrieval_success FT_retrieval_success\n\nlong_name :\n\nBit flags that record the conditions and the quality of the DCA retrieval algorithms that generate soil moisture for the grid cell.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nretrieval_qual_flag_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nflag_masks :\n\n1s, 2s, 4s, 8s\n\nflag_meanings :\n\nRetrieval_recommended Retrieval_attempted Retrieval_success FT_retrieval_success\n\nlong_name :\n\nBit flags that record the conditions and the quality of the DCA retrieval algorithms that generate soil moisture for the grid cell.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nroughness_coefficient\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nA unitless value that is indicative of bare soil roughness used in DCA within the 36 km grid cell.\n\nvalid_max :\n\n1.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nroughness_coefficient_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nA unitless value that is indicative of bare soil roughness used in DCA retrievals within the 36 km grid cell.\n\nvalid_max :\n\n1.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nsoil_moisture\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nRepresentative DCA soil moisture measurement for the Earth based grid cell.\n\nunits :\n\ncm**3/cm**3\n\nvalid_max :\n\n0.5\n\nvalid_min :\n\n0.019999999552965164\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nsoil_moisture_error\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nNet uncertainty measure of soil moisture measure for the Earth based grid cell. - Calculation method is TBD.\n\nunits :\n\ncm**3/cm**3\n\nvalid_max :\n\n0.20000000298023224\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nsoil_moisture_error_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nNet uncertainty measure of soil moisture measure for the Earth based grid cell. - Calculation method is TBD.\n\nunits :\n\ncm**3/cm**3\n\nvalid_max :\n\n0.20000000298023224\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nsoil_moisture_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nRepresentative DCA soil moisture measurement for the Earth based grid cell.\n\nunits :\n\ncm**3/cm**3\n\nvalid_max :\n\n0.5\n\nvalid_min :\n\n0.019999999552965164\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nstatic_water_body_fraction\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nThe fraction of the area of the 36 km grid cell that is covered by static water based on a Digital Elevation Map.\n\nvalid_max :\n\n1.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nstatic_water_body_fraction_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nThe fraction of the area of the 36 km grid cell that is covered by static water based on a Digital Elevation Map.\n\nvalid_max :\n\n1.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nsurface_flag\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nflag_masks :\n\n1s, 2s, 4s, 8s, 16s, 32s, 64s, 128s, 256s, 512s, 1024s, 2048s\n\nflag_meanings :\n\n36_km_static_water_body 36_km_radar_water_body_detection 36_km_coastal_proximity 36_km_urban_area 36_km_precipitation 36_km_snow_or_ice 36_km_permanent_snow_or_ice 36_km_radiometer_frozen_ground 36_km_model_frozen_ground 36_km_mountainous_terrain 36_km_dense_vegetation 36_km_nadir_region\n\nlong_name :\n\nBit flags that record ambient surface conditions for the grid cell\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nsurface_flag_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nflag_masks :\n\n1s, 2s, 4s, 8s, 16s, 32s, 64s, 128s, 256s, 512s, 1024s, 2048s\n\nflag_meanings :\n\n36_km_static_water_body 36_km_radar_water_body_detection 36_km_coastal_proximity 36_km_urban_area 36_km_precipitation 36_km_snow_or_ice 36_km_permanent_snow_or_ice 36_km_radar_frozen_ground 36_km_model_frozen_ground 36_km_mountainous_terrain 36_km_dense_vegetation 36_km_nadir_region\n\nlong_name :\n\nBit flags that record ambient surface conditions for the grid cell\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nsurface_temperature\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nTemperature at land surface based on GMAO GEOS-5 data.\n\nunits :\n\nKelvins\n\nvalid_max :\n\n350.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nsurface_temperature_pm\n\n\n(northing_m, easting_m, datetime)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nTemperature at land surface based on GMAO GEOS-5 data.\n\nunits :\n\nKelvins\n\nvalid_max :\n\n350.0\n\nvalid_min :\n\n0.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\nIndexes: (3)datetimePandasIndexPandasIndex(DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n               '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08',\n               '2018-01-09', '2018-01-10',\n               ...\n               '2022-08-31', '2022-09-01', '2022-09-02', '2022-09-03',\n               '2022-09-04', '2022-09-05', '2022-09-06', '2022-09-07',\n               '2022-09-08', '2022-09-09'],\n              dtype='datetime64[ns]', name='datetime', length=1679, freq=None))easting_mPandasIndexPandasIndex(Index([      -17349514.34,       -17313482.12,        -17277449.9,\n             -17241417.68,       -17205385.46,       -17169353.24,\n             -17133321.02,        -17097288.8,       -17061256.58,\n             -17025224.36,\n       ...\n       17025223.540000003,        17061255.76,        17097287.98,\n               17133320.2, 17169352.419999998, 17205384.640000004,\n       17241416.860000003, 17277449.080000002,         17313481.3,\n              17349513.52],\n      dtype='float64', name='easting_m', length=964))northing_mPandasIndexPandasIndex(Index([        7296524.72,          7260492.5,  7224460.279999999,\n               7188428.06,         7152395.84,         7116363.62,\n        7080331.399999999,         7044299.18,         7008266.96,\n               6972234.74,\n       ...\n       -6972234.400000001,        -7008266.62, -7044298.840000001,\n       -7080331.060000001,        -7116363.28, -7152395.500000001,\n       -7188427.720000002,        -7224459.94, -7260492.160000001,\n              -7296524.38],\n      dtype='float64', name='northing_m', length=406))Attributes: (0)\n\n\nSelect the variable of interest (soil moisture for this example).\n\nsoil_moisture = ds.soil_moisture\nsoil_moisture\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'soil_moisture' (northing_m: 406, easting_m: 964,\n                                   datetime: 1679)&gt; Size: 3GB\ndask.array&lt;open_dataset-soil_moisture, shape=(406, 964, 1679), dtype=float32, chunksize=(100, 100, 100), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * datetime    (datetime) datetime64[ns] 13kB 2018-01-01 ... 2022-09-09\n  * easting_m   (easting_m) float64 8kB -1.735e+07 -1.731e+07 ... 1.735e+07\n  * northing_m  (northing_m) float64 3kB 7.297e+06 7.26e+06 ... -7.297e+06\nAttributes:\n    long_name:  Representative DCA soil moisture measurement for the Earth ba...\n    units:      cm**3/cm**3\n    valid_max:  0.5\n    valid_min:  0.019999999552965164xarray.DataArray'soil_moisture'northing_m: 406easting_m: 964datetime: 1679dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (3)datetime(datetime)datetime64[ns]2018-01-01 ... 2022-09-09array(['2018-01-01T00:00:00.000000000', '2018-01-02T00:00:00.000000000',\n       '2018-01-03T00:00:00.000000000', ..., '2022-09-07T00:00:00.000000000',\n       '2022-09-08T00:00:00.000000000', '2022-09-09T00:00:00.000000000'],\n      shape=(1679,), dtype='datetime64[ns]')easting_m(easting_m)float64-1.735e+07 -1.731e+07 ... 1.735e+07array([-17349514.34, -17313482.12, -17277449.9 , ...,  17277449.08,\n        17313481.3 ,  17349513.52], shape=(964,))northing_m(northing_m)float647.297e+06 7.26e+06 ... -7.297e+06array([ 7296524.72,  7260492.5 ,  7224460.28, ..., -7224459.94, -7260492.16,\n       -7296524.38], shape=(406,))Indexes: (3)datetimePandasIndexPandasIndex(DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n               '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08',\n               '2018-01-09', '2018-01-10',\n               ...\n               '2022-08-31', '2022-09-01', '2022-09-02', '2022-09-03',\n               '2022-09-04', '2022-09-05', '2022-09-06', '2022-09-07',\n               '2022-09-08', '2022-09-09'],\n              dtype='datetime64[ns]', name='datetime', length=1679, freq=None))easting_mPandasIndexPandasIndex(Index([      -17349514.34,       -17313482.12,        -17277449.9,\n             -17241417.68,       -17205385.46,       -17169353.24,\n             -17133321.02,        -17097288.8,       -17061256.58,\n             -17025224.36,\n       ...\n       17025223.540000003,        17061255.76,        17097287.98,\n               17133320.2, 17169352.419999998, 17205384.640000004,\n       17241416.860000003, 17277449.080000002,         17313481.3,\n              17349513.52],\n      dtype='float64', name='easting_m', length=964))northing_mPandasIndexPandasIndex(Index([        7296524.72,          7260492.5,  7224460.279999999,\n               7188428.06,         7152395.84,         7116363.62,\n        7080331.399999999,         7044299.18,         7008266.96,\n               6972234.74,\n       ...\n       -6972234.400000001,        -7008266.62, -7044298.840000001,\n       -7080331.060000001,        -7116363.28, -7152395.500000001,\n       -7188427.720000002,        -7224459.94, -7260492.160000001,\n              -7296524.38],\n      dtype='float64', name='northing_m', length=406))Attributes: (4)long_name :Representative DCA soil moisture measurement for the Earth based grid cell.units :cm**3/cm**3valid_max :0.5valid_min :0.019999999552965164"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#strategy-1-downsample-the-temporal-resolution-of-the-data",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#strategy-1-downsample-the-temporal-resolution-of-the-data",
    "title": "Downsample zarr",
    "section": "Strategy 1: Downsample the temporal resolution of the data",
    "text": "Strategy 1: Downsample the temporal resolution of the data\nTo plot one day from every month, resample the data to 1 observation a month.\n\nsomo_one_month = soil_moisture.resample(datetime=\"1ME\").nearest()\n\nNotice that that took very little time because it was just setting up the calculation. We can call .compute() to tell dask to trigger evaluation.\n\n%%time\n\nsomo_one_month_evaluated = somo_one_month.compute()\n\nCPU times: user 94.9 ms, sys: 64.3 ms, total: 159 ms\nWall time: 3.97 s\n\n\n\nQuick plot\nWe can generate a quick plot using hvplot and datashader.\n\nsomo_one_month_evaluated.hvplot(\n    x=\"easting_m\",\n    y=\"northing_m\",\n    groupby=\"datetime\",\n    crs=ccrs.epsg(6933),  # this is a workaround for https://github.com/holoviz/hvplot/issues/1329\n    rasterize=True,\n    geo=True,\n    coastline=True,\n    aggregator=\"mean\",\n    frame_height=400,\n    widget_location=\"bottom\",\n)\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nReproject before plotting\nReproject the data for map visualization.\n\nsomo_one_month = somo_one_month.transpose(\"datetime\", \"northing_m\", \"easting_m\")\nsomo_one_month = somo_one_month.rio.set_spatial_dims(\n    x_dim=\"easting_m\", y_dim=\"northing_m\"\n)\nsomo_one_month = somo_one_month.rio.write_crs(\"EPSG:6933\")\nsomo_reprojected = somo_one_month.rio.reproject(\"EPSG:4326\")\nsomo_reprojected\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'soil_moisture' (datetime: 57, y: 1046, x: 2214)&gt; Size: 528MB\narray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]],\n      shape=(57, 1046, 2214), dtype=float32)\nCoordinates:\n  * x            (x) float64 18kB -179.9 -179.8 -179.6 ... 179.6 179.8 179.9\n  * y            (y) float64 8kB 84.96 84.8 84.64 84.48 ... -84.64 -84.8 -84.96\n  * datetime     (datetime) datetime64[ns] 456B 2018-01-31 ... 2022-09-30\n    spatial_ref  int64 8B 0\nAttributes:\n    long_name:  Representative DCA soil moisture measurement for the Earth ba...\n    units:      cm**3/cm**3\n    valid_max:  0.5\n    valid_min:  0.019999999552965164xarray.DataArray'soil_moisture'datetime: 57y: 1046x: 2214nan nan nan nan nan nan nan nan ... nan nan nan nan nan nan nan nanarray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]],\n      shape=(57, 1046, 2214), dtype=float32)Coordinates: (4)x(x)float64-179.9 -179.8 ... 179.8 179.9axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([-179.918425, -179.755825, -179.593224, ...,  179.591393,  179.753993,\n        179.916594], shape=(2214,))y(y)float6484.96 84.8 84.64 ... -84.8 -84.96axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([ 84.963262,  84.800655,  84.638047, ..., -84.636773, -84.79938 ,\n       -84.961988], shape=(1046,))datetime(datetime)datetime64[ns]2018-01-31 ... 2022-09-30array(['2018-01-31T00:00:00.000000000', '2018-02-28T00:00:00.000000000',\n       '2018-03-31T00:00:00.000000000', '2018-04-30T00:00:00.000000000',\n       '2018-05-31T00:00:00.000000000', '2018-06-30T00:00:00.000000000',\n       '2018-07-31T00:00:00.000000000', '2018-08-31T00:00:00.000000000',\n       '2018-09-30T00:00:00.000000000', '2018-10-31T00:00:00.000000000',\n       '2018-11-30T00:00:00.000000000', '2018-12-31T00:00:00.000000000',\n       '2019-01-31T00:00:00.000000000', '2019-02-28T00:00:00.000000000',\n       '2019-03-31T00:00:00.000000000', '2019-04-30T00:00:00.000000000',\n       '2019-05-31T00:00:00.000000000', '2019-06-30T00:00:00.000000000',\n       '2019-07-31T00:00:00.000000000', '2019-08-31T00:00:00.000000000',\n       '2019-09-30T00:00:00.000000000', '2019-10-31T00:00:00.000000000',\n       '2019-11-30T00:00:00.000000000', '2019-12-31T00:00:00.000000000',\n       '2020-01-31T00:00:00.000000000', '2020-02-29T00:00:00.000000000',\n       '2020-03-31T00:00:00.000000000', '2020-04-30T00:00:00.000000000',\n       '2020-05-31T00:00:00.000000000', '2020-06-30T00:00:00.000000000',\n       '2020-07-31T00:00:00.000000000', '2020-08-31T00:00:00.000000000',\n       '2020-09-30T00:00:00.000000000', '2020-10-31T00:00:00.000000000',\n       '2020-11-30T00:00:00.000000000', '2020-12-31T00:00:00.000000000',\n       '2021-01-31T00:00:00.000000000', '2021-02-28T00:00:00.000000000',\n       '2021-03-31T00:00:00.000000000', '2021-04-30T00:00:00.000000000',\n       '2021-05-31T00:00:00.000000000', '2021-06-30T00:00:00.000000000',\n       '2021-07-31T00:00:00.000000000', '2021-08-31T00:00:00.000000000',\n       '2021-09-30T00:00:00.000000000', '2021-10-31T00:00:00.000000000',\n       '2021-11-30T00:00:00.000000000', '2021-12-31T00:00:00.000000000',\n       '2022-01-31T00:00:00.000000000', '2022-02-28T00:00:00.000000000',\n       '2022-03-31T00:00:00.000000000', '2022-04-30T00:00:00.000000000',\n       '2022-05-31T00:00:00.000000000', '2022-06-30T00:00:00.000000000',\n       '2022-07-31T00:00:00.000000000', '2022-08-31T00:00:00.000000000',\n       '2022-09-30T00:00:00.000000000'], dtype='datetime64[ns]')spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-179.99972539195164 0.1626005508861423 0.0 85.04456635019852 0.0 -0.16260789541619725array(0)Indexes: (3)xPandasIndexPandasIndex(Index([-179.91842511650856, -179.75582456562242, -179.59322401473628,\n       -179.43062346385014,   -179.268022912964, -179.10542236207786,\n        -178.9428218111917, -178.78022126030555,  -178.6176207094194,\n       -178.45502015853327,\n       ...\n        178.45318903654908,  178.61578958743524,  178.77839013832136,\n        178.94099068920752,  179.10359124009364,   179.2661917909798,\n        179.42879234186597,  179.59139289275208,  179.75399344363825,\n        179.91659399452436],\n      dtype='float64', name='x', length=2214))yPandasIndexPandasIndex(Index([ 84.96326240249043,  84.80065450707423,  84.63804661165804,\n        84.47543871624184,  84.31283082082564,  84.15022292540944,\n        83.98761502999325,  83.82500713457705,  83.66239923916085,\n        83.49979134374465,\n       ...\n       -83.49851724868991, -83.66112514410612, -83.82373303952231,\n        -83.9863409349385, -84.14894883035471,  -84.3115567257709,\n       -84.47416462118711,  -84.6367725166033, -84.79938041201949,\n        -84.9619883074357],\n      dtype='float64', name='y', length=1046))datetimePandasIndexPandasIndex(DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30',\n               '2018-05-31', '2018-06-30', '2018-07-31', '2018-08-31',\n               '2018-09-30', '2018-10-31', '2018-11-30', '2018-12-31',\n               '2019-01-31', '2019-02-28', '2019-03-31', '2019-04-30',\n               '2019-05-31', '2019-06-30', '2019-07-31', '2019-08-31',\n               '2019-09-30', '2019-10-31', '2019-11-30', '2019-12-31',\n               '2020-01-31', '2020-02-29', '2020-03-31', '2020-04-30',\n               '2020-05-31', '2020-06-30', '2020-07-31', '2020-08-31',\n               '2020-09-30', '2020-10-31', '2020-11-30', '2020-12-31',\n               '2021-01-31', '2021-02-28', '2021-03-31', '2021-04-30',\n               '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31',\n               '2021-09-30', '2021-10-31', '2021-11-30', '2021-12-31',\n               '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-30',\n               '2022-05-31', '2022-06-30', '2022-07-31', '2022-08-31',\n               '2022-09-30'],\n              dtype='datetime64[ns]', name='datetime', freq=None))Attributes: (4)long_name :Representative DCA soil moisture measurement for the Earth based grid cell.units :cm**3/cm**3valid_max :0.5valid_min :0.019999999552965164\n\n\n\n[!NOTE] This is now a fully materialized data array - when we reprojected we triggered an implicit compute.\n\n\nsomo_reprojected.hvplot(\n    x=\"x\",\n    y=\"y\",\n    groupby=\"datetime\",\n    coastline=True,\n    rasterize=True,\n    aggregator=\"mean\",\n    frame_height=400,\n    widget_location=\"bottom\",\n)"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#strategy-2-coarsen-spatial-resolution-of-the-data",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#strategy-2-coarsen-spatial-resolution-of-the-data",
    "title": "Downsample zarr",
    "section": "Strategy 2: Coarsen spatial resolution of the data",
    "text": "Strategy 2: Coarsen spatial resolution of the data\nBelow, we coarsen the spatial resolution of the data by a factor of 4 in the x and 2 in the y. These values were chosen because they can be used with the exact boundary argument as the dimensions size is a multiple of these values.\nYou can also coarsen by datetime, using the same strategy as below but replacing easting_m and northing_m with datetime. If {datetime: n} is the value given to the dim argument, this would create a mean of the soil moisture average for n days.\nOnce the data has been coarsened, again it is reprojected for map visualization and then visualized.\n\ncoarsened = soil_moisture.coarsen(dim={\"easting_m\": 4, \"northing_m\": 2}).mean()\n\ncoarsened = coarsened.transpose(\"datetime\", \"northing_m\", \"easting_m\")\ncoarsened = coarsened.rio.set_spatial_dims(x_dim=\"easting_m\", y_dim=\"northing_m\")\ncoarsened = coarsened.rio.write_crs(\"epsg:6933\")\ncoarsened_reprojected = coarsened.rio.reproject(\"EPSG:4326\")\ncoarsened_reprojected\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'soil_moisture' (datetime: 1679, y: 315, x: 667)&gt; Size: 1GB\narray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]],\n      shape=(1679, 315, 667), dtype=float32)\nCoordinates:\n  * x            (x) float64 5kB -179.7 -179.2 -178.7 ... 178.6 179.2 179.7\n  * y            (y) float64 3kB 84.77 84.23 83.7 83.16 ... -83.64 -84.18 -84.72\n  * datetime     (datetime) datetime64[ns] 13kB 2018-01-01 ... 2022-09-09\n    spatial_ref  int64 8B 0\nAttributes:\n    long_name:   Representative DCA soil moisture measurement for the Earth b...\n    units:       cm**3/cm**3\n    valid_max:   0.5\n    valid_min:   0.019999999552965164\n    _FillValue:  nanxarray.DataArray'soil_moisture'datetime: 1679y: 315x: 667nan nan nan nan nan nan nan nan ... nan nan nan nan nan nan nan nanarray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]],\n      shape=(1679, 315, 667), dtype=float32)Coordinates: (4)x(x)float64-179.7 -179.2 ... 179.2 179.7axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([-179.729872, -179.190164, -178.650456, ...,  178.636044,  179.175751,\n        179.715459], shape=(667,))y(y)float6484.77 84.23 83.7 ... -84.18 -84.72axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([ 84.774672,  84.234883,  83.695095, ..., -83.639381, -84.17917 ,\n       -84.718958], shape=(315,))datetime(datetime)datetime64[ns]2018-01-01 ... 2022-09-09array(['2018-01-01T00:00:00.000000000', '2018-01-02T00:00:00.000000000',\n       '2018-01-03T00:00:00.000000000', ..., '2022-09-07T00:00:00.000000000',\n       '2022-09-08T00:00:00.000000000', '2022-09-09T00:00:00.000000000'],\n      shape=(1679,), dtype='datetime64[ns]')spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-179.99972539195164 0.5397077035841558 0.0 85.04456635019838 0.0 -0.5397886314149526array(0)Indexes: (3)xPandasIndexPandasIndex(Index([-179.72987154015956,  -179.1901638365754, -178.65045613299125,\n        -178.1107484294071, -177.57104072582294, -177.03133302223878,\n       -176.49162531865463, -175.95191761507047, -175.41220991148631,\n       -174.87250220790216,\n       ...\n        174.85808971463078,  175.39779741821494,   175.9375051217991,\n        176.47721282538325,   177.0169205289674,  177.55662823255156,\n        178.09633593613572,  178.63604363971987,  179.17575134330403,\n        179.71545904688818],\n      dtype='float64', name='x', length=667))yPandasIndexPandasIndex(Index([  84.7746720344909,  84.23488340307595,    83.695094771661,\n        83.15530614024604,  82.61551750883109,  82.07572887741614,\n        81.53594024600119,  80.99615161458624,  80.45636298317129,\n        79.91657435175634,\n       ...\n       -79.86086054706963, -80.40064917848458, -80.94043780989954,\n       -81.48022644131449, -82.02001507272944, -82.55980370414439,\n       -83.09959233555936, -83.63938096697431, -84.17916959838927,\n       -84.71895822980422],\n      dtype='float64', name='y', length=315))datetimePandasIndexPandasIndex(DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n               '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08',\n               '2018-01-09', '2018-01-10',\n               ...\n               '2022-08-31', '2022-09-01', '2022-09-02', '2022-09-03',\n               '2022-09-04', '2022-09-05', '2022-09-06', '2022-09-07',\n               '2022-09-08', '2022-09-09'],\n              dtype='datetime64[ns]', name='datetime', length=1679, freq=None))Attributes: (5)long_name :Representative DCA soil moisture measurement for the Earth based grid cell.units :cm**3/cm**3valid_max :0.5valid_min :0.019999999552965164_FillValue :nan\n\n\n\ncoarsened_reprojected.hvplot(\n    x=\"x\",\n    y=\"y\",\n    groupby=\"datetime\",\n    coastline=True,\n    rasterize=True,\n    aggregator=\"mean\",\n    frame_height=400,\n    widget_location=\"bottom\",\n)"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#cleanup",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#cleanup",
    "title": "Downsample zarr",
    "section": "Cleanup",
    "text": "Cleanup\nWhen using a remote Dask cluster it is recommented to explicitly close the cluster.\nclient.shutdown()"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/no2-map-plot.html",
    "href": "user-guide/notebooks/quickstarts/no2-map-plot.html",
    "title": "Get map from COGs - NO2",
    "section": "",
    "text": "You can launch this notbook using mybinder, by clicking the button below."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/no2-map-plot.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/no2-map-plot.html#run-this-notebook",
    "title": "Get map from COGs - NO2",
    "section": "",
    "text": "You can launch this notbook using mybinder, by clicking the button below."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/no2-map-plot.html#approach",
    "href": "user-guide/notebooks/quickstarts/no2-map-plot.html#approach",
    "title": "Get map from COGs - NO2",
    "section": "Approach",
    "text": "Approach\n\nFetch STAC item for a particular date and collection - NO2\nPass STAC item in to the raster API /stac/tilejson.json endpoint\nVisualize tiles using folium\n\n\nimport requests\nimport folium"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/no2-map-plot.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/no2-map-plot.html#declare-your-collection-of-interest",
    "title": "Get map from COGs - NO2",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac\"\nRASTER_API_URL = \"https://openveda.cloud/api/raster\"\n\ncollection_id = \"no2-monthly\""
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/no2-map-plot.html#fetch-stac-collection",
    "href": "user-guide/notebooks/quickstarts/no2-map-plot.html#fetch-stac-collection",
    "title": "Get map from COGs - NO2",
    "section": "Fetch STAC collection",
    "text": "Fetch STAC collection\nWe will use requests to fetch all the metadata about the collection of interest from STAC.\n\nresponse = requests.get(f\"{STAC_API_URL}/collections/{collection_id}\")\n    \nassert response.ok, response.text\n\ncollection = response.json()\ncollection\n\n{'id': 'no2-monthly',\n 'type': 'Collection',\n 'links': [{'rel': 'items',\n   'type': 'application/geo+json',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly/items'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/'},\n  {'rel': 'self',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly'},\n  {'rel': 'http://www.opengis.net/def/rel/ogc/1.0/queryables',\n   'type': 'application/schema+json',\n   'title': 'Queryables',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly/queryables'}],\n 'title': 'NO₂',\n 'assets': {'thumbnail': {'href': 'https://thumbnails.openveda.cloud/no2--dataset-cover.jpg',\n   'type': 'image/jpeg',\n   'roles': ['thumbnail'],\n   'title': 'Thumbnail',\n   'description': 'Photo by [Mick Truyts](https://unsplash.com/photos/x6WQeNYJC1w) (Power plant shooting steam at the sky)'}},\n 'extent': {'spatial': {'bbox': [[-180.0, -90.0, 180.0, 90.0]]},\n  'temporal': {'interval': [['2016-01-01T00:00:00+00:00',\n     '2022-12-31T00:00:00+00:00']]}},\n 'license': 'MIT',\n 'renders': {'dashboard': {'bidx': [1],\n   'title': 'VEDA Dashboard Render Parameters',\n   'assets': ['cog_default'],\n   'rescale': [[0, 15000000000000000]],\n   'resampling': 'bilinear',\n   'color_formula': 'gamma r 1.05',\n   'colormap_name': 'rdbu_r'}},\n 'providers': [{'url': 'https://disc.gsfc.nasa.gov/',\n   'name': 'NASA Goddard Earth Sciences Data and Information Services Center',\n   'roles': ['producer', 'processor']},\n  {'url': 'https://www.earthdata.nasa.gov/dashboard/',\n   'name': 'NASA VEDA',\n   'roles': ['host']}],\n 'summaries': {'datetime': ['2016-01-01T00:00:00Z', '2023-09-30T00:00:00Z']},\n 'description': 'Darker colors indicate higher nitrogen dioxide (NO₂) levels and more activity. Lighter colors indicate lower levels of NO₂ and less activity. Missing pixels indicate areas of no data most likely associated with cloud cover or snow.',\n 'item_assets': {'cog_default': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': 'Default COG Layer',\n   'description': 'Cloud optimized default layer to display on map'}},\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/item-assets/v1.0.0/schema.json',\n  'https://stac-extensions.github.io/render/v1.0.0/schema.json'],\n 'dashboard:is_periodic': True,\n 'dashboard:time_density': 'month'}"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/no2-map-plot.html#fetch-stac-item-for-a-particular-time",
    "href": "user-guide/notebooks/quickstarts/no2-map-plot.html#fetch-stac-item-for-a-particular-time",
    "title": "Get map from COGs - NO2",
    "section": "Fetch STAC item for a particular time",
    "text": "Fetch STAC item for a particular time\nWe can use the search API to find the item that matches exactly our time of interest.\n\nresponse = requests.post(\n    f\"{STAC_API_URL}/search\",\n    json={\n        \"collections\": [collection_id],\n        \"query\": {\"datetime\": {\"eq\": \"2021-01-01T00:00:00\"}},\n        \"limit\": 100,\n    },\n)\n\nassert response.ok, response.text\n\nitems = response.json()[\"features\"]\nlen(items)\n\n1\n\n\nLet’s take a look at that one item.\n\nitem = items[0]\nitem\n\n{'id': 'OMI_trno2_0.10x0.10_202101_Col3_V4.nc',\n 'bbox': [-180.0, -90.0, 180.0, 90.0],\n 'type': 'Feature',\n 'links': [{'rel': 'collection',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://openveda.cloud/api/stac/'},\n  {'rel': 'self',\n   'type': 'application/geo+json',\n   'href': 'https://openveda.cloud/api/stac/collections/no2-monthly/items/OMI_trno2_0.10x0.10_202101_Col3_V4.nc'},\n  {'title': 'Map of Item',\n   'href': 'https://openveda.cloud/api/raster/collections/no2-monthly/items/OMI_trno2_0.10x0.10_202101_Col3_V4.nc/map?bidx=1&assets=cog_default&rescale=0%2C15000000000000000&resampling=bilinear&color_formula=gamma+r+1.05&colormap_name=rdbu_r',\n   'rel': 'preview',\n   'type': 'text/html'}],\n 'assets': {'cog_default': {'href': 's3://veda-data-store/no2-monthly/OMI_trno2_0.10x0.10_202101_Col3_V4.nc.tif',\n   'type': 'image/tiff; application=geotiff',\n   'roles': ['data', 'layer'],\n   'title': 'Default COG Layer',\n   'proj:bbox': [-180.0, -90.0, 180.0, 90.0],\n   'proj:epsg': 4326,\n   'proj:wkt2': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n   'proj:shape': [1800, 3600],\n   'description': 'Cloud optimized default layer to display on map',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -1.2676506002282294e+30,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 35781585143857150,\n      'min': -4107596126486528.0,\n      'count': 11,\n      'buckets': [7437, 432387, 2866, 699, 356, 207, 76, 27, 7, 1]},\n     'statistics': {'mean': 367152773066762.6,\n      'stddev': 961254458662885.4,\n      'maximum': 35781585143857150,\n      'minimum': -4107596126486528.0,\n      'valid_percent': 84.69829559326172}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [180.0, -90.0],\n      [180.0, 90.0],\n      [-180.0, 90.0],\n      [-180.0, -90.0]]]},\n   'proj:projjson': {'id': {'code': 4326, 'authority': 'EPSG'},\n    'name': 'WGS 84',\n    'type': 'GeographicCRS',\n    'datum': {'name': 'World Geodetic System 1984',\n     'type': 'GeodeticReferenceFrame',\n     'ellipsoid': {'name': 'WGS 84',\n      'semi_major_axis': 6378137,\n      'inverse_flattening': 298.257223563}},\n    '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json',\n    'coordinate_system': {'axis': [{'name': 'Geodetic latitude',\n       'unit': 'degree',\n       'direction': 'north',\n       'abbreviation': 'Lat'},\n      {'name': 'Geodetic longitude',\n       'unit': 'degree',\n       'direction': 'east',\n       'abbreviation': 'Lon'}],\n     'subtype': 'ellipsoidal'}},\n   'proj:transform': [0.1, 0.0, -180.0, 0.0, -0.1, 90.0, 0.0, 0.0, 1.0]},\n  'rendered_preview': {'title': 'Rendered preview',\n   'href': 'https://openveda.cloud/api/raster/collections/no2-monthly/items/OMI_trno2_0.10x0.10_202101_Col3_V4.nc/preview.png?bidx=1&assets=cog_default&rescale=0%2C15000000000000000&resampling=bilinear&color_formula=gamma+r+1.05&colormap_name=rdbu_r',\n   'rel': 'preview',\n   'roles': ['overview'],\n   'type': 'image/png'}},\n 'geometry': {'type': 'Polygon',\n  'coordinates': [[[-180, -90],\n    [180, -90],\n    [180, 90],\n    [-180, 90],\n    [-180, -90]]]},\n 'collection': 'no2-monthly',\n 'properties': {'end_datetime': '2021-01-31T00:00:00+00:00',\n  'start_datetime': '2021-01-01T00:00:00+00:00'},\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/raster/v1.1.0/schema.json',\n  'https://stac-extensions.github.io/projection/v1.1.0/schema.json']}\n\n\n\nitem_stats = item['assets']['cog_default']['raster:bands'][0]['statistics']\nrescale_values = item_stats['minimum'], item_stats['maximum']"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/no2-map-plot.html#use-stactilejson.json-to-get-tiles",
    "href": "user-guide/notebooks/quickstarts/no2-map-plot.html#use-stactilejson.json-to-get-tiles",
    "title": "Get map from COGs - NO2",
    "section": "Use /stac/tilejson.json to get tiles",
    "text": "Use /stac/tilejson.json to get tiles\nWe pass the, item id, collection name, and the rescale_values in to the RASTER API endpoint and get back a tile.\n\ntile_matrix_set_id = \"WebMercatorQuad\"\nasset = \"cog_default\"\ncolor_formula = \"gamma+r+1.05\"\ncolormap_name = \"rdbu_r\"\n\nresponse = requests.get(\n    f\"{RASTER_API_URL}/collections/{collection_id}/items/{item['id']}/{tile_matrix_set_id}/tilejson.json?\"\n    f\"assets={asset}\"\n    f\"&color_formula={color_formula}&colormap_name={colormap_name}\"\n    f\"&rescale={rescale_values[0]},{rescale_values[1]}\",\n)\n\nassert response.ok, response.text\n\ntiles = response.json()\ntiles\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://openveda.cloud/api/raster/collections/no2-monthly/items/OMI_trno2_0.10x0.10_202101_Col3_V4.nc/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?assets=cog_default&color_formula=gamma+r+1.05&colormap_name=rdbu_r&rescale=-4107596126486528.0%2C35781585143857150'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}\n\n\nWith that tile url in hand we can create a simple visualization using folium.\n\nfolium.Map(\n    tiles=tiles[\"tiles\"][0],\n    min_zoom=3,\n    attr=\"VEDA\",\n)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html",
    "title": "Open and plot COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#run-this-notebook",
    "title": "Open and plot COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#approach",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#approach",
    "title": "Open and plot COGs",
    "section": "Approach",
    "text": "Approach\n\nUse pystac_client to open the STAC catalog and retrieve the items in the collection\nOpen the collection with xarray and stackstac\nPlot the data using hvplot"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#about-the-data",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#about-the-data",
    "title": "Open and plot COGs",
    "section": "About the data",
    "text": "About the data\nCDC’s Social Vulnerability Index (SVI) uses 15 variables at the census tract level. The data comes from the U.S. decennial census for the years 2000 & 2010, and the American Community Survey (ACS) for the years 2014, 2016, and 2018. It is a hierarchical additive index (Tate, 2013), with the component elements of CDC’s SVI including the following for 4 themes: Socioeconomic Status, Household Composition & Disability, Minority Status & Language, and Housing Type & Transportation.\nSVI indicates the relative vulnerability of every U.S. Census tract–subdivisions of counties for which the Census collects statistical data. SVI ranks the tracts on 15 social factors, including unemployment, minority status, and disability, and further groups them into four related themes. Thus, each tract receives a ranking for each Census variable and for each of the four themes, as well as an overall ranking.\n\nScientific research\nThe SVI Overall Score provides the overall, summed social vulnerability score for a given tract. The Overall Score SVI Grid is part of the U.S. Census Grids collection, and displays the Center for Disease Control & Prevention (CDC) SVI score. Funding for the final development, processing and dissemination of this data set by the Socioeconomic Data and Applications Center (SEDAC) was provided under the U.S. National Aeronautics and Space Administration (NASA)¹.\nThe Overall SVI Score describes the vulnerability in a given county tract based on the combined percentile ranking of the four SVI scores (Socioeconomic Status, Household Composition & Disability, Minority Status & Language, and Housing Type & Transportation). The summed percentile ranking from the four themes is ordered, and then used to calculate an overall percentile ranking, ranging from 0 (less vulnerable) to 1 (more vulnerable)². Tracts with higher Overall SVI Scores typically rank high in other SVI domains, and reveal communities that may require extra support, resources, and preventative care in order to better prepare for and manage emergency situations.\n\n\nInterpreting the data\nThe Overall SVI Score describes the vulnerability in a given county tract based on the combined percentile ranking of the four SVI scores (Socioeconomic Status, Household Composition & Disability, Minority Status & Language, and Housing Type & Transportation). The summed percentile ranking from the four themes is ordered, and then used to calculate an overall percentile ranking, ranging from 0 (less vulnerable) to 1 (more vulnerable)². Tracts with higher Overall SVI Scores typically rank high in other SVI domains, and reveal communities that may require extra support, resources, and preventative care in order to better prepare for and manage emergency situations.\n\n\nCredits\n\nCenter for International Earth Science Information Network, (CIESIN), Columbia University. 2021. Documentation for the U.S. Social Vulnerability Index Grids. Palisades, NY: NASA Socioeconomic Data and Applications Center (SEDAC). https://doi.org/10.7927/fjr9-a973. Accessed 13 May 2022.\nCenters for Disease Control and Prevention/ Agency for Toxic Substances and Disease Registry/ Geospatial Research, Analysis, and Services Program. CDC/ATSDR Social Vulnerability Index Database. https://www.atsdr.cdc.gov/placeandhealth/svi/documentation/pdf/SVI2018Documentation_01192022_1.pdf\n\n\nfrom pystac_client import Client\nimport stackstac\n\nimport hvplot.xarray  # noqa"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#declare-your-collection-of-interest",
    "title": "Open and plot COGs",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac/\"\ncollection = \"social-vulnerability-index-overall-nopop\""
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#find-items-in-collection",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#find-items-in-collection",
    "title": "Open and plot COGs",
    "section": "Find items in collection",
    "text": "Find items in collection\nUse pystac_client to search the STAC collection.\n\ncatalog = Client.open(STAC_API_URL)\nsearch = catalog.search(collections=[collection])\n\nitem_collection = search.item_collection()\nprint(f\"Found {len(item_collection)} items\")\n\nFound 5 items"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#read-data",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#read-data",
    "title": "Open and plot COGs",
    "section": "Read data",
    "text": "Read data\nRead in data using xarray using a combination of xpystac, stackstac, and rasterio.\n\n%%time\nda = stackstac.stack(item_collection, epsg=4326)\nda = da.assign_coords({\"time\": da.start_datetime}).squeeze()\nda.name = collection\nda\n\nCPU times: user 89.8 ms, sys: 3.86 ms, total: 93.7 ms\nWall time: 94.6 ms\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'social-vulnerability-index-overall-nopop' (time: 5, y: 6298,\n                                                              x: 13354)&gt; Size: 3GB\ndask.array&lt;getitem, shape=(5, 6298, 13354), dtype=float64, chunksize=(1, 1024, 1024), chunktype=numpy.ndarray&gt;\nCoordinates: (12/17)\n    id              (time) &lt;U38 760B 'svi_2018_tract_overall_wgs84_nopop_cog'...\n    band            &lt;U11 44B 'cog_default'\n  * x               (x) float64 107kB -178.2 -178.2 -178.2 ... -66.97 -66.97\n  * y               (y) float64 50kB 71.38 71.37 71.37 ... 18.92 18.92 18.91\n    start_datetime  (time) &lt;U25 500B '2018-01-01T00:00:00+00:00' ... '2000-01...\n    end_datetime    (time) &lt;U25 500B '2018-12-31T00:00:00+00:00' ... '2000-12...\n    ...              ...\n    description     &lt;U47 188B 'Cloud optimized default layer to display on map'\n    proj:geometry   object 8B {'type': 'Polygon', 'coordinates': [[[-178.2333...\n    proj:bbox       object 8B {-178.23333334, 18.908332897999998, -66.9583337...\n    title           &lt;U17 68B 'Default COG Layer'\n    epsg            int64 8B 4326\n  * time            (time) &lt;U25 500B '2018-01-01T00:00:00+00:00' ... '2000-01...\nAttributes:\n    spec:           RasterSpec(epsg=4326, bounds=(-178.24166595386018, 18.899...\n    crs:            epsg:4326\n    transform:      | 0.01, 0.00,-178.24|\\n| 0.00,-0.01, 71.38|\\n| 0.00, 0.00...\n    resolution_xy:  (0.00833333330000749, 0.00833333329998412)xarray.DataArray'social-vulnerability-index-overall-nopop'time: 5y: 6298x: 13354dask.array&lt;chunksize=(1, 1024, 1024), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n3.13 GiB\n8.00 MiB\n\n\nShape\n(5, 6298, 13354)\n(1, 1024, 1024)\n\n\nDask graph\n490 chunks in 4 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (17)id(time)&lt;U38'svi_2018_tract_overall_wgs84_no...array(['svi_2018_tract_overall_wgs84_nopop_cog',\n       'svi_2016_tract_overall_wgs84_nopop_cog',\n       'svi_2014_tract_overall_wgs84_nopop_cog',\n       'svi_2010_tract_overall_wgs84_nopop_cog',\n       'svi_2000_tract_overall_wgs84_nopop_cog'], dtype='&lt;U38')band()&lt;U11'cog_default'array('cog_default', dtype='&lt;U11')x(x)float64-178.2 -178.2 ... -66.97 -66.97array([-178.241666, -178.233333, -178.224999, ...,  -66.983333,  -66.975   ,\n        -66.966666], shape=(13354,))y(y)float6471.38 71.37 71.37 ... 18.92 18.91array([71.383333, 71.375   , 71.366666, ..., 18.925   , 18.916667, 18.908333],\n      shape=(6298,))start_datetime(time)&lt;U25'2018-01-01T00:00:00+00:00' ... ...array(['2018-01-01T00:00:00+00:00', '2016-01-01T00:00:00+00:00',\n       '2014-01-01T00:00:00+00:00', '2010-01-01T00:00:00+00:00',\n       '2000-01-01T00:00:00+00:00'], dtype='&lt;U25')end_datetime(time)&lt;U25'2018-12-31T00:00:00+00:00' ... ...array(['2018-12-31T00:00:00+00:00', '2016-12-31T00:00:00+00:00',\n       '2014-12-31T00:00:00+00:00', '2010-12-31T00:00:00+00:00',\n       '2000-12-31T00:00:00+00:00'], dtype='&lt;U25')proj:wkt2()&lt;U277'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984...array('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n      dtype='&lt;U277')proj:shape()object{6297, 13353}array({6297, 13353}, dtype=object)proj:code()&lt;U9'EPSG:4326'array('EPSG:4326', dtype='&lt;U9')proj:transform()object{0.00833333330000749, 0.0, 1.0, ...array({0.00833333330000749, 0.0, 1.0, -0.00833333329998412, 71.383332688, -178.23333334},\n      dtype=object)proj:projjson()object{'id': {'code': 4326, 'authority...array({'id': {'code': 4326, 'authority': 'EPSG'}, 'name': 'WGS 84', 'type': 'GeographicCRS', 'datum': {'name': 'World Geodetic System 1984', 'type': 'GeodeticReferenceFrame', 'ellipsoid': {'name': 'WGS 84', 'semi_major_axis': 6378137, 'inverse_flattening': 298.257223563}}, '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json', 'coordinate_system': {'axis': [{'name': 'Geodetic latitude', 'unit': 'degree', 'direction': 'north', 'abbreviation': 'Lat'}, {'name': 'Geodetic longitude', 'unit': 'degree', 'direction': 'east', 'abbreviation': 'Lon'}], 'subtype': 'ellipsoidal'}},\n      dtype=object)description()&lt;U47'Cloud optimized default layer t...array('Cloud optimized default layer to display on map', dtype='&lt;U47')proj:geometry()object{'type': 'Polygon', 'coordinates...array({'type': 'Polygon', 'coordinates': [[[-178.23333334, 18.908332897999998], [-66.958333785, 18.908332897999998], [-66.958333785, 71.383332688], [-178.23333334, 71.383332688], [-178.23333334, 18.908332897999998]]]},\n      dtype=object)proj:bbox()object{-178.23333334, 18.9083328979999...array({-178.23333334, 18.908332897999998, -66.958333785, 71.383332688},\n      dtype=object)title()&lt;U17'Default COG Layer'array('Default COG Layer', dtype='&lt;U17')epsg()int644326array(4326)time(time)&lt;U25'2018-01-01T00:00:00+00:00' ... ...array(['2018-01-01T00:00:00+00:00', '2016-01-01T00:00:00+00:00',\n       '2014-01-01T00:00:00+00:00', '2010-01-01T00:00:00+00:00',\n       '2000-01-01T00:00:00+00:00'], dtype='&lt;U25')Indexes: (3)xPandasIndexPandasIndex(Index([-178.24166595386018, -178.23333262056016, -178.22499928726018,\n       -178.21666595396016, -178.20833262066014, -178.19999928736013,\n       -178.19166595406014, -178.18333262076013,  -178.1749992874601,\n       -178.16666595416012,\n       ...\n        -67.04166639856027,  -67.03333306526025,  -67.02499973196025,\n        -67.01666639866023,  -67.00833306536023,  -66.99999973206023,\n        -66.99166639876022,  -66.98333306546022,   -66.9749997321602,\n         -66.9666663988602],\n      dtype='float64', name='x', length=13354))yPandasIndexPandasIndex(Index([ 71.38333304766397,  71.37499971436398,    71.366666381064,\n        71.35833304776402,  71.34999971446403,  71.34166638116405,\n        71.33333304786406,  71.32499971456407,   71.3166663812641,\n        71.30833304796411,\n       ...\n       18.983333257363824, 18.974999924063845, 18.966666590763857,\n        18.95833325746387,  18.94999992416389, 18.941666590863903,\n       18.933333257563923, 18.924999924263936, 18.916666590963956,\n        18.90833325766397],\n      dtype='float64', name='y', length=6298))timePandasIndexPandasIndex(Index(['2018-01-01T00:00:00+00:00', '2016-01-01T00:00:00+00:00',\n       '2014-01-01T00:00:00+00:00', '2010-01-01T00:00:00+00:00',\n       '2000-01-01T00:00:00+00:00'],\n      dtype='object', name='time'))Attributes: (4)spec :RasterSpec(epsg=4326, bounds=(-178.24166595386018, 18.899999924363982, -66.95833306556018, 71.38333304766397), resolutions_xy=(0.00833333330000749, 0.00833333329998412))crs :epsg:4326transform :| 0.01, 0.00,-178.24|\n| 0.00,-0.01, 71.38|\n| 0.00, 0.00, 1.00|resolution_xy :(0.00833333330000749, 0.00833333329998412)\n\n\nThere are 5 items representing the 5 years of data in the collection (2000, 2010, 2014, 2016, and 2018)."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#plot-data",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#plot-data",
    "title": "Open and plot COGs",
    "section": "Plot data",
    "text": "Plot data\nPlot data using hvplot. By using rasterize=True we tell hvplot to use datashader behind the scenes to make the plot render more quickly and re-render on zoom.\n\n%%time\nda.compute().hvplot(x=\"x\", y=\"y\", rasterize=True, clim=(0, 1), coastline=True, cmap=\"viridis\", widget_location=\"bottom\")\n\nCPU times: user 32.7 s, sys: 2.39 s, total: 35.1 s\nWall time: 18.4 s"
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "",
    "text": "You can launch this notebook in the US GHG Center JupyterHub by clicking the link below.\nLaunch in the US GHG Center JupyterHub (requires access)"
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#run-this-notebook",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#run-this-notebook",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "",
    "text": "You can launch this notebook in the US GHG Center JupyterHub by clicking the link below.\nLaunch in the US GHG Center JupyterHub (requires access)"
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#approach",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#approach",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Approach",
    "text": "Approach\n\nIdentify available dates and temporal frequency of observations for the given collection using the GHGC API /stac endpoint. The collection processed in this notebook is the Wetland Methane Emissions, LPJ-EOSIM Model data product.\nPass the STAC item into the raster API /collections/{collection_id}/items/{item_id}/tilejson.json endpoint.\nUsing folium.plugins.DualMap, visualize two tiles (side-by-side), allowing time point comparison.\nAfter the visualization, perform zonal statistics for a given polygon."
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#about-the-data",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#about-the-data",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "About the Data",
    "text": "About the Data\nMethane (CH₄) emissions from vegetated wetlands are estimated to be the largest natural source of methane in the global CH₄ budget, contributing to roughly one third of the total of natural and anthropogenic emissions. Wetland CH₄ is produced by microbes breaking down organic matter in the oxygen deprived environment of inundated soils. Due to limited data availability, the details of the role of wetland CH₄ emissions have thus far been underrepresented. Using the Earth Observation SIMulator version (LPJ-EOSIM) of the Lund-Potsdam-Jena Dynamic Global Vegetation Model (LPJ-DGVM) global CH₄ emissions from wetlands are estimated at 0.5° x 0.5 degree spatial resolution. By simulating wetland extent and using characteristics of inundated areas, such as wetland soil moisture, temperature, and carbon content, the model provides estimates of CH₄ quantities emitted into the atmosphere. This dataset shows concentrated methane sources from tropical and high latitude ecosystems. The LPJ-EOSIM Wetland Methane Emissions dataset consists of global daily model estimates of terrestrial wetland methane emissions from 1990 to the present, with data added bimonthly. The estimates are regularly used in conjunction with NASA’s Goddard Earth Observing System (GEOS) model to simulate the impact of wetlands and other methane sources on atmospheric methane concentrations, to compare against satellite and airborne data, and to improve understanding and prediction of wetland emissions.\nFor more information regarding this dataset, please visit the U.S. Greenhouse Gas Center."
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#query-the-stac-api",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#query-the-stac-api",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Query the STAC API",
    "text": "Query the STAC API\nFirst, we are going to import the required libraries. Once imported, they allow better executing a query in the GHG Center Spatio Temporal Asset Catalog (STAC) Application Programming Interface (API) where the granules for this collection are stored.\n\n# Import the following libraries\nimport requests\nimport folium\nimport folium.plugins\nfrom folium import Map, TileLayer\nfrom pystac_client import Client\nimport branca\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n/Users/rrimal/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n  warnings.warn(\n\n\n\n# Provide the STAC and RASTER API endpoints\n# The endpoint is referring to a location within the API that executes a request on a data collection nesting on the server.\n\n# The STAC API is a catalog of all the existing data collections that are stored in the GHG Center.\nSTAC_API_URL = \"https://earth.gov/ghgcenter/api/stac\"\n\n# The RASTER API is used to fetch collections for visualization\nRASTER_API_URL = \"https://earth.gov/ghgcenter/api/raster\"\n\n# The collection name is used to fetch the dataset from the STAC API. First, we define the collection name as a variable\n# Name of the collection for the wetland methane emissions LPJ-EOSIM Model\ncollection_name = \"lpjeosim-wetlandch4-daygrid-v1\"\n\n# Next, we need to specify the asset name for this collection\n# The asset name is referring to the raster band containing the pixel values for the parameter of interest\nasset_name = \"ensemble-mean-ch4-wetlands-emissions\"\n\n\n# Fetch the collection from the STAC API using the appropriate endpoint\n# The 'requests' library allows a HTTP request possible\ncollection = requests.get(f\"{STAC_API_URL}/collections/{collection_name}\").json()\n\n# Print the properties of the collection to the console\ncollection\n\n{'id': 'lpjeosim-wetlandch4-daygrid-v2',\n 'type': 'Collection',\n 'links': [{'rel': 'items',\n   'type': 'application/geo+json',\n   'href': 'https://earth.gov/ghgcenter/api/stac/collections/lpjeosim-wetlandch4-daygrid-v2/items'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://earth.gov/ghgcenter/api/stac/'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://earth.gov/ghgcenter/api/stac/'},\n  {'rel': 'self',\n   'type': 'application/json',\n   'href': 'https://earth.gov/ghgcenter/api/stac/collections/lpjeosim-wetlandch4-daygrid-v2'}],\n 'title': '(Daily) Wetland Methane Emissions, LPJ-EOSIM Model v2',\n 'extent': {'spatial': {'bbox': [[-180, -90, 180, 90]]},\n  'temporal': {'interval': [['1990-01-01 00:00:00+00',\n     '2024-05-31 00:00:00+00']]}},\n 'license': 'CC0-1.0',\n 'renders': {'dashboard': {'assets': ['ensemble-mean-ch4-wetlands-emissions'],\n   'rescale': [[0, 3e-09]],\n   'colormap_name': 'magma'},\n  'era5-ch4-wetlands-emissions': {'assets': ['era5-ch4-wetlands-emissions'],\n   'rescale': [[0, 3e-09]],\n   'colormap_name': 'magma'},\n  'merra2-ch4-wetlands-emissions': {'assets': ['merra2-ch4-wetlands-emissions'],\n   'rescale': [[0, 3e-09]],\n   'colormap_name': 'magma'},\n  'ensemble-mean-ch4-wetlands-emissions': {'assets': ['ensemble-mean-ch4-wetlands-emissions'],\n   'rescale': [[0, 3e-09]],\n   'colormap_name': 'magma'}},\n 'providers': [{'name': 'NASA'}],\n 'summaries': {'datetime': ['1990-01-01T00:00:00Z', '2024-05-31T00:00:00Z']},\n 'description': 'Global, daily estimates of methane (CH₄) emissions from terrestrial wetlands at 0.5 x 0.5 degree spatial resolution using the Earth Observation SIMulator version (LPJ-EOSIM) of the Lund-Potsdam-Jena Dynamic Global Vegetation Model (LPJ-DGVM). Methane emissions from vegetated wetlands are estimated to be the largest natural source of methane in the global CH₄ budget, contributing to roughly one third of the total of natural and anthropogenic emissions. Wetland CH₄ is produced by microbes breaking down organic matter in the oxygen deprived environment of inundated soils. Due to limited data availability, the details of the role of wetland CH₄ emissions have thus far been underrepresented. The LPJ-EOSIM model estimates wetland methane emissions by simulating wetland extent and using characteristics of these inundated areas such as soil moisture, temperature, and carbon content to estimate CH₄ quantities emitted into the atmosphere. Input climate forcing data comes from Modern-Era Retrospective analysis for Research and Applications Version 2 (MERRA-2) data and ECMWF Re-Analysis data (ERA5). An ensemble layer provides the result of the mean of the MERRA-2 and ERA5 layers. The source data can be found at https://doi.org/10.5067/Community/LPJ-EOSIM/LPJ_EOSIM_L2_DCH4E.001 and https://doi.org/10.5067/Community/LPJ-EOSIM/LPJ_EOSIM_L2_DCH4E_LL.001.',\n 'item_assets': {'era5-ch4-wetlands-emissions': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': '(Daily) Wetland Methane Emissions, ERA5 LPJ-EOSIM Model v2',\n   'description': 'Methane emissions from wetlands in units of kilograms of methane per meter squared per second. ECMWF Re-Analysis (ERA5) as input to LPJ-EOSIM model.'},\n  'merra2-ch4-wetlands-emissions': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': '(Daily) Wetland Methane Emissions, MERRA-2 LPJ-EOSIM Model v2',\n   'description': 'Methane emissions from wetlands in units of kilograms of methane per meter squared per second. Modern-Era Retrospective analysis for Research and Applications Version 2 (MERRA-2) data as input to LPJ-EOSIM model.'},\n  'ensemble-mean-ch4-wetlands-emissions': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': '(Daily) Wetland Methane Emissions, Ensemble Mean LPJ-EOSIM Model v2',\n   'description': 'Methane emissions from wetlands in units of kilograms of methane per meter squared per second. Ensemble of multiple climate forcing data sources input to LPJ-EOSIM model.'}},\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/render/v1.0.0/schema.json',\n  'https://stac-extensions.github.io/item-assets/v1.0.0/schema.json'],\n 'dashboard:is_periodic': True,\n 'dashboard:time_density': 'day'}\n\n\nExamining the contents of our collection under summaries, we see that the data is available from January 1990 to December 2024. By looking at dashboard: time density, we can see that these observations are collected monthly.\n\n# Create a function that would search for a data collection in the US GHG Center STAC API\n\n# First, we need to define the function\n# The name of the function = \"get_item_count\"\n# The argument that will be passed through the defined function = \"collection_id\"\n\ndef get_item_count(collection_id):\n\n    # Set a counter for the number of items existing in the collection\n    count = 0\n\n    # Define the path to retrieve the granules (items) of the collection of interest in the STAC API\n    items_url = f\"{STAC_API_URL}/collections/{collection_id}/items\"\n\n    # Run a while loop to make HTTP requests until there are no more URLs associated with the collection in the STAC API\n    while True:\n\n        # Retrieve information about the granules by sending a \"get\" request to the STAC API using the defined collection path\n        response = requests.get(items_url)\n\n        # If the items do not exist, print an error message and quit the loop\n        if not response.ok:\n            print(\"error getting items\")\n            exit()\n\n        # Return the results of the HTTP response as JSON\n        stac = response.json()\n\n        # Increase the \"count\" by the number of items (granules) returned in the response\n        count += int(stac[\"context\"].get(\"returned\", 0))\n\n        # Retrieve information about the next URL associated with the collection in the STAC API (if applicable)\n        next = [link for link in stac[\"links\"] if link[\"rel\"] == \"next\"]\n\n        # Exit the loop if there are no other URLs\n        if not next:\n            break\n        \n        # Ensure the information gathered by other STAC API links associated with the collection are added to the original path\n        # \"href\" is the identifier for each of the tiles stored in the STAC API\n        items_url = next[0][\"href\"]\n        # temp = items_url.split('/')\n        # temp.insert(3, 'ghgcenter')\n        # temp.insert(4, 'api')\n        # temp.insert(5, 'stac')\n        # items_url = '/'.join(temp)\n\n    # Return the information about the total number of granules found associated with the collection\n    return count\n\n\n# Apply the function created above \"get_item_count\" to the data collection\nnumber_of_items = get_item_count(collection_name)\n\n# Get the information about the number of granules found in the collection\nitems = requests.get(f\"{STAC_API_URL}/collections/{collection_name}/items?limit=800\"\n).json()[\"features\"]\n\n# Print the total number of items (granules) found\nprint(f\"Found {len(items)} items\")\n\nFound 800 items\n\n\n\n# Examine the first item in the collection\n# Keep in mind that a list starts from 0, 1, 2... therefore items[0] is referring to the first item in the list/collection\nitems[0]\n\n{'id': 'lpjeosim-wetlandch4-daygrid-v2-20240531',\n 'bbox': [-180.0, -90.0, 180.0, 90.0],\n 'type': 'Feature',\n 'links': [{'rel': 'collection',\n   'type': 'application/json',\n   'href': 'https://earth.gov/ghgcenter/api/stac/collections/lpjeosim-wetlandch4-daygrid-v2'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://earth.gov/ghgcenter/api/stac/collections/lpjeosim-wetlandch4-daygrid-v2'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://earth.gov/ghgcenter/api/stac/'},\n  {'rel': 'self',\n   'type': 'application/geo+json',\n   'href': 'https://earth.gov/ghgcenter/api/stac/collections/lpjeosim-wetlandch4-daygrid-v2/items/lpjeosim-wetlandch4-daygrid-v2-20240531'},\n  {'title': 'Map of Item',\n   'href': 'https://earth.gov/ghgcenter/api/raster/collections/lpjeosim-wetlandch4-daygrid-v2/items/lpjeosim-wetlandch4-daygrid-v2-20240531/map?assets=ensemble-mean-ch4-wetlands-emissions&rescale=0%2C3e-09&colormap_name=magma',\n   'rel': 'preview',\n   'type': 'text/html'}],\n 'assets': {'era5-ch4-wetlands-emissions': {'href': 's3://lp-prod-protected/LPJ_EOSIM_L2_DCH4E_LL.001/LPJ_EOSIM_L2_DCH4E_LL_001_20240531/LPJ_EOSIM_L2_DCH4E_LL_ERA5_001_20240531.tif',\n   'type': 'image/tiff; application=geotiff',\n   'roles': ['data', 'layer'],\n   'title': '(Daily) Wetland Methane Emissions, ERA5 LPJ-EOSIM Model v2',\n   'proj:bbox': [-180.0, -90.0, 180.0, 90.0],\n   'proj:epsg': 4326,\n   'proj:wkt2': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n   'proj:shape': [360, 720],\n   'description': 'Methane emissions from wetlands in units of grams of methane per meter squared per second. ECMWF Re-Analysis (ERA5) as input to LPJ-EOSIM model.',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -99999.0,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 3.1533866629018803e-09,\n      'min': 0.0,\n      'count': 11,\n      'buckets': [60696, 1228, 228, 119, 78, 51, 35, 24, 2, 2]},\n     'statistics': {'mean': 3.818678323370309e-11,\n      'stddev': 1.385319732851768e-10,\n      'maximum': 3.1533866629018803e-09,\n      'minimum': 0.0,\n      'valid_percent': 24.09837962962963}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [180.0, -90.0],\n      [180.0, 90.0],\n      [-180.0, 90.0],\n      [-180.0, -90.0]]]},\n   'proj:projjson': {'id': {'code': 4326, 'authority': 'EPSG'},\n    'name': 'WGS 84',\n    'type': 'GeographicCRS',\n    'datum': {'name': 'World Geodetic System 1984',\n     'type': 'GeodeticReferenceFrame',\n     'ellipsoid': {'name': 'WGS 84',\n      'semi_major_axis': 6378137,\n      'inverse_flattening': 298.257223563}},\n    '$schema': 'https://proj.org/schemas/v0.7/projjson.schema.json',\n    'coordinate_system': {'axis': [{'name': 'Geodetic latitude',\n       'unit': 'degree',\n       'direction': 'north',\n       'abbreviation': 'Lat'},\n      {'name': 'Geodetic longitude',\n       'unit': 'degree',\n       'direction': 'east',\n       'abbreviation': 'Lon'}],\n     'subtype': 'ellipsoidal'}},\n   'proj:transform': [0.5, 0.0, -180.0, 0.0, -0.5, 90.0, 0.0, 0.0, 1.0]},\n  'merra2-ch4-wetlands-emissions': {'href': 's3://lp-prod-protected/LPJ_EOSIM_L2_DCH4E_LL.001/LPJ_EOSIM_L2_DCH4E_LL_001_20240531/LPJ_EOSIM_L2_DCH4E_LL_MERRA2_001_20240531.tif',\n   'type': 'image/tiff; application=geotiff',\n   'roles': ['data', 'layer'],\n   'title': '(Daily) Wetland Methane Emissions, MERRA-2 LPJ-EOSIM Model v2',\n   'proj:bbox': [-180.0, -90.0, 180.0, 90.0],\n   'proj:epsg': 4326,\n   'proj:wkt2': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n   'proj:shape': [360, 720],\n   'description': 'Methane emissions from wetlands in units of grams of methane per meter squared per second. Modern-Era Retrospective analysis for Research and Applications Version 2 (MERRA-2) data as input to LPJ-EOSIM model.',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -99999.0,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 5.284403581384822e-09,\n      'min': 0.0,\n      'count': 11,\n      'buckets': [61618, 503, 152, 101, 53, 21, 5, 6, 0, 1]},\n     'statistics': {'mean': 4.2160033887186084e-11,\n      'stddev': 1.6741675825683113e-10,\n      'maximum': 5.284403581384822e-09,\n      'minimum': 0.0,\n      'valid_percent': 24.09722222222222}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [180.0, -90.0],\n      [180.0, 90.0],\n      [-180.0, 90.0],\n      [-180.0, -90.0]]]},\n   'proj:projjson': {'id': {'code': 4326, 'authority': 'EPSG'},\n    'name': 'WGS 84',\n    'type': 'GeographicCRS',\n    'datum': {'name': 'World Geodetic System 1984',\n     'type': 'GeodeticReferenceFrame',\n     'ellipsoid': {'name': 'WGS 84',\n      'semi_major_axis': 6378137,\n      'inverse_flattening': 298.257223563}},\n    '$schema': 'https://proj.org/schemas/v0.7/projjson.schema.json',\n    'coordinate_system': {'axis': [{'name': 'Geodetic latitude',\n       'unit': 'degree',\n       'direction': 'north',\n       'abbreviation': 'Lat'},\n      {'name': 'Geodetic longitude',\n       'unit': 'degree',\n       'direction': 'east',\n       'abbreviation': 'Lon'}],\n     'subtype': 'ellipsoidal'}},\n   'proj:transform': [0.5, 0.0, -180.0, 0.0, -0.5, 90.0, 0.0, 0.0, 1.0]},\n  'ensemble-mean-ch4-wetlands-emissions': {'href': 's3://lp-prod-protected/LPJ_EOSIM_L2_DCH4E_LL.001/LPJ_EOSIM_L2_DCH4E_LL_001_20240531/LPJ_EOSIM_L2_DCH4E_LL_ensemble_mean_001_20240531.tif',\n   'type': 'image/tiff; application=geotiff',\n   'roles': ['data', 'layer'],\n   'title': '(Daily) Wetland Methane Emissions, Ensemble Mean LPJ-EOSIM Model v2',\n   'proj:bbox': [-180.0, -90.0, 180.0, 90.0],\n   'proj:epsg': 4326,\n   'proj:wkt2': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n   'proj:shape': [360, 720],\n   'description': 'Methane emissions from wetlands in units of grams of methane per meter squared per second. Ensemble of multiple climate forcing data sources input to LPJ-EOSIM model.',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -99999.0,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 3.8867296048294975e-09,\n      'min': 0.0,\n      'count': 11,\n      'buckets': [61178, 819, 185, 124, 78, 46, 22, 7, 0, 1]},\n     'statistics': {'mean': 4.0174325630166816e-11,\n      'stddev': 1.493077090568075e-10,\n      'maximum': 3.8867296048294975e-09,\n      'minimum': 0.0,\n      'valid_percent': 24.09722222222222}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [180.0, -90.0],\n      [180.0, 90.0],\n      [-180.0, 90.0],\n      [-180.0, -90.0]]]},\n   'proj:projjson': {'id': {'code': 4326, 'authority': 'EPSG'},\n    'name': 'WGS 84',\n    'type': 'GeographicCRS',\n    'datum': {'name': 'World Geodetic System 1984',\n     'type': 'GeodeticReferenceFrame',\n     'ellipsoid': {'name': 'WGS 84',\n      'semi_major_axis': 6378137,\n      'inverse_flattening': 298.257223563}},\n    '$schema': 'https://proj.org/schemas/v0.7/projjson.schema.json',\n    'coordinate_system': {'axis': [{'name': 'Geodetic latitude',\n       'unit': 'degree',\n       'direction': 'north',\n       'abbreviation': 'Lat'},\n      {'name': 'Geodetic longitude',\n       'unit': 'degree',\n       'direction': 'east',\n       'abbreviation': 'Lon'}],\n     'subtype': 'ellipsoidal'}},\n   'proj:transform': [0.5, 0.0, -180.0, 0.0, -0.5, 90.0, 0.0, 0.0, 1.0]},\n  'rendered_preview': {'title': 'Rendered preview',\n   'href': 'https://earth.gov/ghgcenter/api/raster/collections/lpjeosim-wetlandch4-daygrid-v2/items/lpjeosim-wetlandch4-daygrid-v2-20240531/preview.png?assets=ensemble-mean-ch4-wetlands-emissions&rescale=0%2C3e-09&colormap_name=magma',\n   'rel': 'preview',\n   'roles': ['overview'],\n   'type': 'image/png'}},\n 'geometry': {'type': 'Polygon',\n  'coordinates': [[[-180, -90],\n    [180, -90],\n    [180, 90],\n    [-180, 90],\n    [-180, -90]]]},\n 'collection': 'lpjeosim-wetlandch4-daygrid-v2',\n 'properties': {'datetime': '2024-05-31T00:00:00+00:00'},\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/raster/v1.1.0/schema.json',\n  'https://stac-extensions.github.io/projection/v1.1.0/schema.json']}\n\n\nBelow, we are entering the minimum and maximum values to provide our upper and lower bounds in the rescale_values.\n\n# Fetch the minimum and maximum values for rescaling\nrescale_values = {'max': 0.0003, 'min': 0.0}"
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#explore-changes-in-methane-ch4-emission-levels-using-the-raster-api",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#explore-changes-in-methane-ch4-emission-levels-using-the-raster-api",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Explore Changes in Methane (CH4) Emission Levels Using the Raster API",
    "text": "Explore Changes in Methane (CH4) Emission Levels Using the Raster API\nIn this notebook, we will explore the temporal impacts of methane emissions. We will visualize the outputs on a map using folium.\n\n# Now we create a dictionary where the start datetime values for each granule is queried more explicitly by year and month (e.g., 2020-02)\nitems = {item[\"properties\"][\"datetime\"][:10]: item for item in items} \n\nNow, we will pass the item id, collection name, and rescaling_factor to the Raster API endpoint. We will do this twice, once for date 1 mentioned in the next cell and again for date 2, so we can visualize each event independently.\n\n# Choose a color for displaying the tiles\n# Please refer to matplotlib library if you'd prefer choosing a different color ramp.\n# For more information on Colormaps in Matplotlib, please visit https://matplotlib.org/stable/users/explain/colors/colormaps.html\ncolor_map = \"magma\" \n\n# Make a GET request to retrieve information for the date mentioned below\ndate1 = '2024-01-01'\ndate1_tile = requests.get(\n\n    # Pass the collection name, collection date, and its ID\n    # To change the year, month and date of the observed parameter, you can modify the date2 variable above\n    f\"{RASTER_API_URL}/collections/{items[date1]['collection']}/items/{items[date1]['id']}/tilejson.json?\"\n\n    # Pass the asset name\n    f\"&assets={asset_name}\"\n\n    # Pass the color formula and colormap for custom visualization\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n\n    # Pass the minimum and maximum values for rescaling\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n\n# Return response in JSON format\n).json()\n\n# Print the properties of the retrieved granule to the console\ndate1_tile\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://earth.gov/ghgcenter/api/raster/collections/lpjeosim-wetlandch4-daygrid-v2/items/lpjeosim-wetlandch4-daygrid-v2-20240101/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?assets=ensemble-mean-ch4-wetlands-emissions&color_formula=gamma+r+1.05&colormap_name=magma&rescale=0.0%2C0.0003'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}\n\n\n\n# Make a GET request to retrieve information for date mentioned below\ndate2 = '2024-01-30'\ndate2_tile = requests.get(\n\n    # Pass the collection name, collection date, and its ID\n    # To change the year, month and date of the observed parameter, you can modify the date2 variable above\n    f\"{RASTER_API_URL}/collections/{items[date2]['collection']}/items/{items[date2]['id']}/tilejson.json?\"\n\n    # Pass the asset name\n    f\"&assets={asset_name}\"\n\n    # Pass the color formula and colormap for custom visualization\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n\n    # Pass the minimum and maximum values for rescaling\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\",\n\n# Return response in JSON format \n).json()\n\n# Print the properties of the retrieved granule to the console\ndate2_tile\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://earth.gov/ghgcenter/api/raster/collections/lpjeosim-wetlandch4-daygrid-v2/items/lpjeosim-wetlandch4-daygrid-v2-20240130/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?assets=ensemble-mean-ch4-wetlands-emissions&color_formula=gamma+r+1.05&colormap_name=magma&rescale=0.0%2C0.0003'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}"
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#visualize-ch₄-emissions",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#visualize-ch₄-emissions",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Visualize CH₄ Emissions",
    "text": "Visualize CH₄ Emissions\n\n# For this study we are going to compare the CH₄ Emissions in date1 and date2 along the coast of California\n# To change the location, you can simply insert the latitude and longitude of the area of your interest in the \"location=(LAT, LONG)\" statement\n\n# Set initial zoom and center of map\n# 'folium.plugins' allows mapping side-by-side\nmap_ = folium.plugins.DualMap(location=(34, -118), zoom_start=6)\n\n# Define the first map layer for tile fetched for date 1\n# The TileLayer library helps in manipulating and displaying raster layers on a map\nmap_layer_date1 = TileLayer(\n    tiles=date1_tile[\"tiles\"][0], # Path to retrieve the tile\n    attr=\"GHG\", # Set the attribution\n    opacity=0.5, # Adjust the transparency of the layer\n)\n\n# Add the first layer to the Dual Map\nmap_layer_date1.add_to(map_.m1)\n\n\n# Define the second map layer for the tile fetched for date 2\nmap_layer_date2 = TileLayer(\n    tiles=date2_tile[\"tiles\"][0], # Path to retrieve the tile\n    attr=\"GHG\", # Set the attribution\n    opacity=0.5, # Adjust the transparency of the layer\n)\n\n# Add the second layer to the Dual Map\nmap_layer_date2.add_to(map_.m2)\n\n# Visualize the Dual Map\nmap_\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#visualize-the-data-as-a-time-series",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#visualize-the-data-as-a-time-series",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Visualize the Data as a Time Series",
    "text": "Visualize the Data as a Time Series\nWe can now explore the wetland methane emissions time series (January 1990 – December 2024) available for the Texas area of the U.S. We can plot the data set using the code below:\n\n# Determine the width and height of the plot using the 'matplotlib' library\n# Figure size: 20 representing the width, 10 representing the height\nfig = plt.figure(figsize=(20, 10))\n\n# Plot the time series\nplt.plot(\n    df[\"date\"], # X-axis: date\n    df[\"max\"], # Y-axis: CH₄ value\n    color=\"red\", # Line color\n    linestyle=\"-\", # Line style\n    linewidth=0.5, # Line width\n    label=\"Max daily CH₄ emissions\", # Legend label\n)\n\n# Display legend\nplt.legend()\n\n# Insert label for the X-axis\nplt.xlabel(\"Years\")\n\n# Insert label for the Y-axis\nplt.ylabel(\"Daily CH4 emissions g/m2\")\n\n# Insert title for the plot\nplt.title(\"Daily CH4 emission Values for Texas, January 2022- March 2024\")\n\nText(0.5, 1.0, 'Daily CH4 emission Values for Texas, January 2022- March 2024')\n\n\n\n\n\nTo take a closer look at the CH4 variability across this region, we are going to retrieve and display data collected during the February, 2024 observation.\n\n# The 2024-02-25 observation is the 3rd item in the list\n# Considering that a list starts with \"0\", we need to insert \"2\" in the \"items[2]\" statement\n# Print the start Date Time of the third granule in the collection\nprint(items[2][\"properties\"][\"datetime\"])\n\n2024-05-29T00:00:00+00:00\n\n\n\n# A GET request is made for the 3rd item in the collection\nobserved_tile = requests.get(\n\n    # Pass the collection name, the item number in the list, and its ID\n    f\"{RASTER_API_URL}/collections/{items[2]['collection']}/items/{items[2]['id']}/tilejson.json?&assets={asset_name}\"\n\n    # Pass the color formula and colormap for custom visualization\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n\n    # Pass the minimum and maximum values for rescaling\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\",\n\n# Return the response in JSON format\n).json()\n\n# Print the properties of the retrieved granule to the console\nobserved_tile\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://earth.gov/ghgcenter/api/raster/collections/lpjeosim-wetlandch4-daygrid-v2/items/lpjeosim-wetlandch4-daygrid-v2-20240529/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?assets=ensemble-mean-ch4-wetlands-emissions&color_formula=gamma+r+1.05&colormap_name=magma&rescale=0.0%2C0.0003'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}\n\n\n\n# Create a new map to display the CH4 variability for the Texas region for Observed tile timeframe\naoi_map_bbox = Map(\n\n    # Base map is set to OpenStreetMap\n    tiles=\"OpenStreetMap\",\n\n    # Set the center of the map\n    location=[\n        30,-100\n    ],\n\n    # Set the zoom value\n    zoom_start=8,\n)\n\n# Define the map layer\nmap_layer = TileLayer(\n    tiles=observed_tile[\"tiles\"][0], # Path to retrieve the tile\n    attr=\"GHG\", opacity = 0.5 # Set the attribution and transparency\n)\n\n# Add the layer to the map\nmap_layer.add_to(aoi_map_bbox)\n\n# Visualize the map\naoi_map_bbox\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#summary",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#summary",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Summary",
    "text": "Summary\nIn this notebook we have successfully completed the following steps for the STAC collection for the Daily Wetland Methane Emissions, LPJ-EOSIM Model data: 1. Install and import the necessary libraries 2. Fetch the collection from STAC collections using the appropriate endpoints 3. Count the number of existing granules within the collection 4. Map and compare the CH4 levels over the Texas region for two distinctive years 5. Create a table that displays the minimum, maximum, and sum of the CH4 levels for a specified region 6. Generate a time-series graph of the CH4 levels for a specified region\nIf you have any questions regarding this user notebook, please contact us using the feedback form."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/list-collections.html",
    "href": "user-guide/notebooks/quickstarts/list-collections.html",
    "title": "List STAC collections",
    "section": "",
    "text": "You can launch this notbook using mybinder, by clicking the button below."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/list-collections.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/list-collections.html#run-this-notebook",
    "title": "List STAC collections",
    "section": "",
    "text": "You can launch this notbook using mybinder, by clicking the button below."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/list-collections.html#approach",
    "href": "user-guide/notebooks/quickstarts/list-collections.html#approach",
    "title": "List STAC collections",
    "section": "Approach",
    "text": "Approach\n\nUse pystac_client to open the STAC catalog\nIterate over collections and print the title of each collection"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/list-collections.html#open-stac-catalog",
    "href": "user-guide/notebooks/quickstarts/list-collections.html#open-stac-catalog",
    "title": "List STAC collections",
    "section": "Open STAC catalog",
    "text": "Open STAC catalog\n\nfrom pystac_client import Client\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac/\"\ncatalog = Client.open(STAC_API_URL)"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/list-collections.html#list-collections",
    "href": "user-guide/notebooks/quickstarts/list-collections.html#list-collections",
    "title": "List STAC collections",
    "section": "List collections",
    "text": "List collections\n\ncollections = list(catalog.get_collections())\nfor collection in sorted(collections, key=lambda x: x.title or x.id):\n    print(collection.title or collection.id)\n\n0-100 cm Volumetric Soil Moisture (%)\nAB/SK/MB Clipper Snowfall Footprint\nASSR Parcel Damage - Eaton and Palisades Fires (2025)\nAerosol Optical Depth (AOD)\nAnnual LAI maps for 2003 and 2021 (Bangladesh)\nAnnual land cover maps for 2001 and 2020\nBlack Marble High Definition Nightlights 1 band Dataset\nBlack Marble High Definition Nightlights Monthly Dataset\nBlack Marble Night Lights (Greenville OH Tornado Damage)\nBlack Marble Night Lights (Houston, TX 2021 Deep Freeze)\nBlack Marble Night Lights (Lakeview OH Tornado Damage; Difference)\nBlack Marble Night Lights - 2025 Burma Earthquake\nBlizzard Alley\nBlizzard Count 1950-2021\nBrightness Temperature (Band 31)\nBrightness Temperature (Band I5)\nBurn Area Reflectance Classification for Thomas Fire\nCLIMDEX ACCESS CM2 SSP125 tmaxXF\nCLIMDEX ACCESS CM2 SSP245 tmaxXF\nCLIMDEX ACCESS CM2 SSP370 tmaxXF\nCLIMDEX ACCESS CM2 SSP585 tmaxXF\nCMIP6 Daily GISS-E2-1-G TAS Kerchunk (DEMO)\nCO₂ (Avg)\nCO₂ (Diff)\nCaldor Fire Behavior\nCaldor Fire Burn Severity\nCamp Fire Domain: Land Cover\nCamp Fire Domain: MODIS LST Day Difference\nCamp Fire Domain: MODIS LST Night Difference\nCamp Fire Domain: MODIS NDVI Difference\nCamp Fire Domain: MODIS WSA Albedo Difference\nChange in ET for 2020 fires using LIS outputs\nChange in transpiration for 2020 fires using LIS outputs\nColorado Low Snowfall Footprint\nDOW7 Correlation Coefficient (Greenfield, IA)\nDOW7 Correlation Coefficient (Harlan, IA)\nDOW7 Differential Reflectivity (Greenfield, IA)\nDOW7 Differential Reflectivity (Harlan, IA)\nDOW7 Reflectivity (Greenfield, IA)\nDOW7 Reflectivity (Harlan, IA)\nDOW7 Spectrum Width (Greenfield, IA)\nDOW7 Spectrum Width (Harlan, IA)\nDOW7 Velocity (Ground; Greenfield, IA)\nDOW7 Velocity (Ground; Harlan, IA)\nDamage Probability Derived from UCONN GERs Lab After Hurricane Ian\nDerived Maximum Velocity (Greenfield, IA; DOW7)\nECCO sea-surface height change from 1992 to 2017\nEMIT Landfill Plumes\nERA5 Reanalysis – 10 Meter Wind (Select Events)\nERA5 Reanalysis – 2 Meter Temperature (Select Events)\nERA5 Reanalysis – Cloud Fraction (Select Events)\nERA5 Reanalysis – Mean Sea Level Pressure (Select Events)\nEaton and Palisades Fires (2025) Above Groud Biomass\nEaton and Palisades Fires (2025) Fire Radiative Power\nEaton and Palisades Fires (2025) Slope\nEvapotranspiration - LIS 10km Global DA\nFLDAS Surface Soil Moisture Anomalies\nFalse Color Pre and Post Flood\nFire Perimeters\nGEOGLAM Crop Monitor\nGOES Imagery - Bombogenesis (Select Event)\nGPM IMERG data of 2023 Medicane Daniel\nGPM_3IMERGDF\nGRDI BUILT Constituent Raster\nGRDI CDR Constituent Raster\nGRDI Filled Missing Values Count\nGRDI IMR Constituent Raster\nGRDI SHDI Constituent Raster\nGRDI V1 raster\nGRDI VNL Constituent Raster\nGRDI VNL Slope Constituent Raster\nGlobal TWS Non-Stationarity Index\nGridded 2012 EPA Methane Emissions - Abandoned Coal Mines\nGridded 2012 EPA Methane Emissions - Composting\nGridded 2012 EPA Methane Emissions - Domestic Wastewater Treatment\nGridded 2012 EPA Methane Emissions - Enteric Fermentation\nGridded 2012 EPA Methane Emissions - Ferroalloy Production\nGridded 2012 EPA Methane Emissions - Field Burning\nGridded 2012 EPA Methane Emissions - Field Burning (monthly)\nGridded 2012 EPA Methane Emissions - Forest Fires\nGridded 2012 EPA Methane Emissions - Forest Fires (daily)\nGridded 2012 EPA Methane Emissions - Industrial Landfills\nGridded 2012 EPA Methane Emissions - Industrial Wastewater Treatment\nGridded 2012 EPA Methane Emissions - Manure Management\nGridded 2012 EPA Methane Emissions - Manure Management (monthly)\nGridded 2012 EPA Methane Emissions - Mobile Combustion\nGridded 2012 EPA Methane Emissions - Municipal Landfills\nGridded 2012 EPA Methane Emissions - Natural Gas Distribution\nGridded 2012 EPA Methane Emissions - Natural Gas Processing\nGridded 2012 EPA Methane Emissions - Natural Gas Production\nGridded 2012 EPA Methane Emissions - Natural Gas Production (monthly)\nGridded 2012 EPA Methane Emissions - Natural Gas Transmission\nGridded 2012 EPA Methane Emissions - Petrochemical Production\nGridded 2012 EPA Methane Emissions - Petroleum\nGridded 2012 EPA Methane Emissions - Petroleum (monthly)\nGridded 2012 EPA Methane Emissions - Rice Cultivation\nGridded 2012 EPA Methane Emissions - Rice Cultivation (monthly)\nGridded 2012 EPA Methane Emissions - Stationary Combustion\nGridded 2012 EPA Methane Emissions - Stationary Combustion (monthly)\nGridded 2012 EPA Methane Emissions - Surface Coal Mines\nGridded 2012 EPA Methane Emissions - Underground Coal Mines\nGridded Daily OCO-2 Carbon Dioxide assimilated dataset\nGross Primary Productivity - LIS 10km Global DA\nGross Primary Productivity Trend - LIS 10km Global DA\nGroundwater Storage - LIS 10km Global DA\nHLS Disturbance Product - Hurricane Helene\nHLS False Color Imagery (2025 LA fires)\nHLS SWIR FalseColor Composite\nHLS-calculated BAIS2 burned area\nHLS-derived NDVI difference for Assessing Impacts from Hurricane Iann\nHLS-derived entropy difference for Assessing impacts from Hurricane Ian\nHLSL30.002 Environmental Justice Events\nHLSS30.002 Environmental Justice Events\nHRRR 10 Meter Wind Gusts (2025 LA Fires)\nHouston AOD: Difference Between 2000-2009 & 2010-2019\nHouston LST (Diff)\nHouston Land Cover\nHouston NDVI: decadal average\nHouston land surface temperature at night time - decadal average\nHouston land surface temperature during daytime - decadal average\nHurricane Ida - Blue Tarps PlanetScope Image\nHurricane Ida - Detected Blue Tarps\nICESat-2 L4 Monthly Gridded Sea Ice Thickness (COGs)\nIMERG Total Precipitation - 2025 Texas Flood\nIMERG Total Precipitation - Hurricane Helene\nISRIC World Soil Texture Classification\nImpactful Landslides Kernel Density - Hurricane Helene\nLA County Significant Ecological Areas (SEA)\nLandsat 8 Nighttime Thermal Imagery\nMAXAR Commercial Satellite Imagery (2025 Eaton Fire)\nMAXAR Commercial Satellite Imagery (2025 Texas Flood - Post)\nMAXAR Commercial Satellite Imagery (2025 Texas Flood - Pre)\nMERRA2 Reanalysis – 10 Meter Wind (Select Events)\nMERRA2 Reanalysis – 2 Meter Temperature (Select Events)\nMERRA2 Reanalysis – Cloud Fraction (Select Events)\nMERRA2 Reanalysis – Mean Sea Level Pressure (Select Events)\nMODIS Aersol Optical Depth (AOD) for May 12, 2022\nMODIS LST for Texas on June 23, 2023\nMO_NPP_npp_vgpm\nMTBS Burn Severity\nMaximum Fire Radiative Power for Thomas Fire\nMiller A Snowfall Footprint\nMiller B Snowfall Footprint\nNC DHHS Flood Extent - Hurricane Helene\nNCEI Wind Gusts for 05/12/2022\nNCEO Africa Aboveground Woody Biomass 2017\nNDVI Difference for Pre and Post-Hurricane Ida from PlanetScope\nNDVI for Pre and Post-Hurricane Ida from PlanetScope\nNDWI Difference for Pre and Post-Hurricane Ida from PlanetScope\nNDWI for Pre and Post-Hurricane Ida from PlanetScope\nNLCD Land Use Land Cover Classifications\nNLCD Urbanization\nNLDAS-2 Precipitation Forcing Dataset\nNLDAS-3 Precipitation Forcing Dataset\nNO₂\nNO₂ (Diff)\nNWS Tornado Tracks (May 12, 2022)\nNWS Tornado Tracks (Paths) from MAM 2024\nNWS Tornado Tracks from MAM 2024\nNew Urbanization from 2001-2019 (NLCD)\nNormalized difference vegetation index from HLS\nNor’easter Snowfall Footprint\nOMI/Aura Sulfur Dioxide (SO2) Total Column L3 1 day Best Pixel in 0.25 degree x 0.25 degree V3 as Cloud-Optimized GeoTIFFs (COGs)\nOMI_trno2 - 0.10 x 0.10 Annual as Cloud-Optimized GeoTIFFs (COGs)\nPACE - North Atlantic Chlorophyll-a for 2024-2025\nPanhandle Hooker Snowfall Footprint\nPlanet TrueColor Satellite Imagery (Barnsdall OK Tornado Damage)\nPlanet TrueColor Satellite Imagery (Greenfield IA Tornado Damage - Post)\nPlanet TrueColor Satellite Imagery (Greenfield IA Tornado Damage - Pre)\nPlanet TrueColor Satellite Imagery (Hartington NE Derecho Damage)\nPlanet TrueColor Satellite Imagery (Portage MI Tornado Damage)\nPlanet TrueColor Satellite Imagery (Rock Valley IA Derecho Damage)\nPlanet TrueColor Satellite Imagery (Winchester IN, Lakeview OH Tornado Damage)\nPlanet TrueColor Satellite Imagery Difference (Greenfield IA Tornado Damage)\nPlanetScope Satellite Imagery (2025 Burma Earthquake - Post)\nPlanetScope Satellite Imagery (2025 Burma Earthquake - Pre)\nPlanetScope Satellite Imagery (2025 Eaton Fire)\nPlanetScope Satellite Imagery (Asheville NC - Hurricane Helene - During)\nPlanetScope Satellite Imagery (NC Hurricane Helene - Pre)\nPlanetScope Satellite Imagery (NC/TN Hurricane Helene - Post)\nPopulation Density Maps using satellite imagery built by Meta\nProjected changes to winter (January, February, and March) average daily air temperature\nProjected changes to winter (January, February, and March) average daily air temperature\nProjected changes to winter (January, February, and March) cumulative daily precipitation\nProjected changes to winter (January, February, and March) cumulative daily precipitation\nProjections of Snow Water Equivalent (SWE) - SSP2-4.5\nProjections of Snow Water Equivalent (SWE) - SSP5-8.5\nProjections of Snow Water Equivalent (SWE) Losses - SSP2-4.5\nProjections of Snow Water Equivalent (SWE) Losses - SSP5-8.5\nRecovery Proxy Maps\nRegional Snowfall Index Accumulated Snowfall (Select Events)\nS2 East-West Deformation - 2025 Burma Earthquake\nS2 NDVI Difference - Hurricane Helene\nS2 North-South Deformation - 2025 Burma Earthquake\nSPORT Sea Surface Temperature (K)\nSalt Marsh Classification Pre-Ida (Southern Louisiana)\nSalt Marshes Difference for Pre and Post-Hurricane Ida\nSelected Landsat 7 through 9 Surface Reflectance Scenes for Lake Balaton\nSelected Landsat 7 through 9 Surface Reflectance Scenes for Lake Biwa\nSelected Landsat 7 through 9 Surface Reflectance Scenes for Tonlé Sap\nSelected Landsat 7 through 9 Surface Reflectance Scenes for Vänern\nSelected Landsat 7 through 9 Surface Reflectance Scenes for the Aral Sea\nSelected Landsat 7 through 9 Surface Reflectance Scenes for the Pine Island Glacier\nSelected Landsat 7 through 9 Surface Reflectance Scenes for the Thwaites Glacier\nSlowdown Proxy Maps\nSnow Water Equivalent - LIS 10km Global DA\nSocial Vulnerability Index (Household)\nSocial Vulnerability Index (Household) (Masked)\nSocial Vulnerability Index (Housing)\nSocial Vulnerability Index (Housing) (Masked)\nSocial Vulnerability Index (Minority)\nSocial Vulnerability Index (Minority) (Masked)\nSocial Vulnerability Index (Overall)\nSocial Vulnerability Index (Overall) (Masked)\nSocial Vulnerability Index (SocioEconomic)\nSocial Vulnerability Index (SocioEconomic) (Masked)\nStream network across the Contiguous United States\nStreamflow - LIS 10km Global DA\nSubsurface Runoff - LIS 10km Global DA\nSurface runoff - LIS 10km Global DA\nTerrestrial Water Storage (TWS) Anomalies\nTerrestrial Water Storage - LIS 10km Global DA\nTerrestrial Water Storage Trend - LIS 10km Global DA\nTexas Water Development Board Cursory Floodplain Dataset (10 Year Recurrence)- 2025 Texas Flood AOI\nTexas Water Development Board Cursory Floodplain Dataset (100 Year Recurrence)- 2025 Texas Flood AOI\nTexas Water Development Board Cursory Floodplain Dataset (500 Year Recurrence)- 2025 Texas Flood AOI\nTogo Agriculture\nTotal Precipitation - LIS 10km Global DA\nTrend in Terrestrial Water Storage (TWS) Anomalies\nUSGS Landslide Hazard Estimate Model - Hurricane Helene\nUSGS Landslides Inventory - Hurricane Helene\nVIIRS Night Lights Derecho\nWLDAS Soil Moisture Content (0-10cm)\ndisalexi-etsuppression"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/list-collections.html#alternate-approachs",
    "href": "user-guide/notebooks/quickstarts/list-collections.html#alternate-approachs",
    "title": "List STAC collections",
    "section": "Alternate approachs",
    "text": "Alternate approachs\nInstead of exploring STAC catalog programatically, you can discover available collections the following ways:\n\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: http://openveda.cloud"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html",
    "title": "Visualize zarr",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailing aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#run-this-notebook",
    "title": "Visualize zarr",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailing aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#approach",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#approach",
    "title": "Visualize zarr",
    "section": "Approach",
    "text": "Approach\n\nUse pystac to open a STAC collection\nUse xarray and dask to lazily read in the data\nPlot the data using hvplot"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#about-the-data",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#about-the-data",
    "title": "Visualize zarr",
    "section": "About the data",
    "text": "About the data\nThis is the Gridded Daily OCO-2 Carbon Dioxide assimilated dataset. More information can be found at: OCO-2 GEOS Level 3 daily, 0.5x0.625 assimilated CO2 V10r (OCO2_GEOS_L3CO2_DAY)\nThe data has been converted to zarr format and published to the development version of the VEDA STAC Catalog.\n\nimport pystac\nimport xarray as xr\n\nimport hvplot.xarray  # noqa"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#declare-your-collection-of-interest",
    "title": "Visualize zarr",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac\"\ncollection_id = \"oco2-geos-l3-daily\""
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#get-stac-collection",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#get-stac-collection",
    "title": "Visualize zarr",
    "section": "Get STAC collection",
    "text": "Get STAC collection\nUse pystac to access the STAC collection.\n\ncollection = pystac.Collection.from_file(f\"{STAC_API_URL}/collections/{collection_id}\")\ncollection\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Collection\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"oco2-geos-l3-daily\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"The OCO-2 mission provides the highest quality space-based XCO2 retrievals to date. However, the instrument data are characterized by large gaps in coverage due to OCO-2’s narrow 10-km ground track and an inability to see through clouds and thick aerosols. This global gridded dataset is produced using a data assimilation technique commonly referred to as state estimation within the geophysical literature. Data assimilation synthesizes simulations and observations, adjusting the state of atmospheric constituents like CO2 to reflect observed values, thus gap-filling observations when and where they are unavailable based on previous observations and short transport simulations by GEOS. Compared to other methods, data assimilation has the advantage that it makes estimates based on our collective scientific understanding, notably of the Earth's carbon cycle and atmospheric transport. OCO-2 GEOS (Goddard Earth Observing System) Level 3 data are produced by ingesting OCO-2 L2 retrievals every 6 hours with GEOS CoDAS, a modeling and data assimilation system maintained by NASA's Global Modeling and Assimilation Office (GMAO). GEOS CoDAS uses a high-performance computing implementation of the Gridpoint Statistical Interpolation approach for solving the state estimation problem. GSI finds the analyzed state that minimizes the three-dimensional variational (3D-Var) cost function formulation of the state estimation problem.\"\n        \n    \n                \n            \n                \n                    \n        links[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/collections/oco2-geos-l3-daily\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"items\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/collections/oco2-geos-l3-daily/items\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"external\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://catalog.data.gov/dataset/oco-2-geos-level-3-daily-0-5x0-625-assimilated-co2-v10r-oco2-geos-l3co2-day-at-ges-disc-72b15\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OCO-2 GEOS Level 3 daily, 0.5x0.625 assimilated CO2 V10r (OCO2_GEOS_L3CO2_DAY) at GES DISC\"\n        \n    \n            \n        \n            \n                \n        \n            label:assets\n            None\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/collections/oco2-geos-l3-daily/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        stac_extensions[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/datacube/v2.2.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            cube:variables\n            \n        \n            \n                \n        \n            XCO2\n            \n        \n            \n                \n        \n            type\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            unit\n            \"mol CO2/mol dry\"\n        \n    \n            \n        \n            \n                \n        \n            attrs\n            \n        \n            \n                \n        \n            units\n            \"mol CO2/mol dry\"\n        \n    \n            \n        \n            \n                \n        \n            long_name\n            \"Assimilated dry-air column average CO2 daily mean\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        shape[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            2500\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            361\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            576\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        chunks[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            100\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            100\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            100\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        dimensions[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \"time\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"lat\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"lon\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Assimilated dry-air column average CO2 daily mean\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            XCO2PREC\n            \n        \n            \n                \n        \n            type\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            unit\n            \"mol CO2/mol dry\"\n        \n    \n            \n        \n            \n                \n        \n            attrs\n            \n        \n            \n                \n        \n            units\n            \"mol CO2/mol dry\"\n        \n    \n            \n        \n            \n                \n        \n            long_name\n            \"Precision of dry-air column average CO2 daily mean from Desroziers et al. (2005) diagnostic\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        shape[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            2500\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            361\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            576\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        chunks[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            100\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            100\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            100\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        dimensions[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \"time\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"lat\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"lon\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Precision of dry-air column average CO2 daily mean from Desroziers et al. (2005) diagnostic\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            cube:dimensions\n            \n        \n            \n                \n        \n            lat\n            \n        \n            \n                \n        \n            axis\n            \"y\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"spatial\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -90.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            90.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"latitude\"\n        \n    \n            \n        \n            \n                \n        \n            reference_system\n            4326\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            lon\n            \n        \n            \n                \n        \n            axis\n            \"x\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"spatial\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -180.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            179.375\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"longitude\"\n        \n    \n            \n        \n            \n                \n        \n            reference_system\n            4326\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            time\n            \n        \n            \n                \n        \n            step\n            \"P1DT0H0M0S\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"temporal\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"2015-01-01T12:00:00Z\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"2021-11-04T12:00:00Z\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"time\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            dashboard:is_periodic\n            True\n        \n    \n                \n            \n                \n                    \n        \n            dashboard:time_density\n            \"day\"\n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"Gridded Daily OCO-2 Carbon Dioxide assimilated dataset\"\n        \n    \n                \n            \n                \n                    \n        \n            extent\n            \n        \n            \n                \n        \n            spatial\n            \n        \n            \n                \n        bbox[] 1 items\n        \n            \n        \n            \n                \n        0[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -180.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            -90.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            180.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            90.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            temporal\n            \n        \n            \n                \n        interval[] 1 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            None\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            None\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            license\n            \"CC0-1.0\"\n        \n    \n                \n            \n                \n                    \n        providers[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"NASA VEDA\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"host\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.earthdata.nasa.gov/dashboard/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            assets\n            \n        \n            \n                \n        \n            zarr\n            \n        \n            \n                \n        \n            href\n            \"s3://veda-data-store/oco2-geos-l3-daily/OCO2_GEOS_L3CO2_day.zarr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/vnd+zarr\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"zarr\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n        \n    \n\n\n\nWe can see that there is one zarr asset:\n\ncollection.get_assets(media_type=\"application/vnd+zarr\")\n\n{'zarr': &lt;Asset href=s3://veda-data-store/oco2-geos-l3-daily/OCO2_GEOS_L3CO2_day.zarr&gt;}"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#read-from-zarr-to-xarray",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#read-from-zarr-to-xarray",
    "title": "Visualize zarr",
    "section": "Read from zarr to xarray",
    "text": "Read from zarr to xarray\nWith the url pointing to the Zarr store, you can create an xarray dataset backed by a dask array.\n\nurl = collection.assets[\"zarr\"].href\n\nds = xr.open_dataset(url, engine=\"zarr\", chunks=\"auto\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 8GB\nDimensions:   (time: 2500, lat: 361, lon: 576)\nCoordinates:\n  * lat       (lat) float64 3kB -90.0 -89.5 -89.0 -88.5 ... 88.5 89.0 89.5 90.0\n  * lon       (lon) float64 5kB -180.0 -179.4 -178.8 ... 178.1 178.8 179.4\n  * time      (time) datetime64[ns] 20kB 2015-01-01T12:00:00 ... 2021-11-04T1...\nData variables:\n    XCO2      (time, lat, lon) float64 4GB dask.array&lt;chunksize=(200, 200, 200), meta=np.ndarray&gt;\n    XCO2PREC  (time, lat, lon) float64 4GB dask.array&lt;chunksize=(200, 200, 200), meta=np.ndarray&gt;\nAttributes: (12/25)\n    BuildId:                        B10.2.06\n    Contact:                        Brad Weir (brad.weir@nasa.gov)\n    Conventions:                    CF-1\n    DataResolution:                 0.5x0.625\n    EastBoundingCoordinate:         179.375\n    Format:                         NetCDF-4/HDF-5\n    ...                             ...\n    ShortName:                      OCO2_GEOS_L3CO2_DAY_10r\n    SouthBoundingCoordinate:        -90.0\n    SpatialCoverage:                global\n    Title:                          OCO-2 GEOS Level 3 daily, 0.5x0.625 assim...\n    VersionID:                      V10r\n    WestBoundingCoordinate:         -180.0xarray.DatasetDimensions:time: 2500lat: 361lon: 576Coordinates: (3)lat(lat)float64-90.0 -89.5 -89.0 ... 89.5 90.0long_name :latitudeunits :degrees_northarray([-90. , -89.5, -89. , ...,  89. ,  89.5,  90. ], shape=(361,))lon(lon)float64-180.0 -179.4 ... 178.8 179.4long_name :longitudeunits :degrees_eastarray([-180.   , -179.375, -178.75 , ...,  178.125,  178.75 ,  179.375],\n      shape=(576,))time(time)datetime64[ns]2015-01-01T12:00:00 ... 2021-11-...begin_date :20170801begin_time :120000long_name :timearray(['2015-01-01T12:00:00.000000000', '2015-01-02T12:00:00.000000000',\n       '2015-01-03T12:00:00.000000000', ..., '2021-11-02T12:00:00.000000000',\n       '2021-11-03T12:00:00.000000000', '2021-11-04T12:00:00.000000000'],\n      shape=(2500,), dtype='datetime64[ns]')Data variables: (2)XCO2(time, lat, lon)float64dask.array&lt;chunksize=(200, 200, 200), meta=np.ndarray&gt;long_name :Assimilated dry-air column average CO2 daily meanunits :mol CO2/mol dry\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n3.87 GiB\n61.04 MiB\n\n\nShape\n(2500, 361, 576)\n(200, 200, 200)\n\n\nDask graph\n78 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\n\nXCO2PREC\n\n\n(time, lat, lon)\n\n\nfloat64\n\n\ndask.array&lt;chunksize=(200, 200, 200), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nPrecision of dry-air column average CO2 daily mean from Desroziers et al. (2005) diagnostic\n\nunits :\n\nmol CO2/mol dry\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n3.87 GiB\n61.04 MiB\n\n\nShape\n(2500, 361, 576)\n(200, 200, 200)\n\n\nDask graph\n78 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\n\nIndexes: (3)latPandasIndexPandasIndex(Index([-90.0, -89.5, -89.0, -88.5, -88.0, -87.5, -87.0, -86.5, -86.0, -85.5,\n       ...\n        85.5,  86.0,  86.5,  87.0,  87.5,  88.0,  88.5,  89.0,  89.5,  90.0],\n      dtype='float64', name='lat', length=361))lonPandasIndexPandasIndex(Index([  -180.0, -179.375,  -178.75, -178.125,   -177.5, -176.875,  -176.25,\n       -175.625,   -175.0, -174.375,\n       ...\n         173.75,  174.375,    175.0,  175.625,   176.25,  176.875,    177.5,\n        178.125,   178.75,  179.375],\n      dtype='float64', name='lon', length=576))timePandasIndexPandasIndex(DatetimeIndex(['2015-01-01 12:00:00', '2015-01-02 12:00:00',\n               '2015-01-03 12:00:00', '2015-01-04 12:00:00',\n               '2015-01-05 12:00:00', '2015-01-06 12:00:00',\n               '2015-01-07 12:00:00', '2015-01-08 12:00:00',\n               '2015-01-09 12:00:00', '2015-01-10 12:00:00',\n               ...\n               '2021-10-26 12:00:00', '2021-10-27 12:00:00',\n               '2021-10-28 12:00:00', '2021-10-29 12:00:00',\n               '2021-10-30 12:00:00', '2021-10-31 12:00:00',\n               '2021-11-01 12:00:00', '2021-11-02 12:00:00',\n               '2021-11-03 12:00:00', '2021-11-04 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=2500, freq=None))Attributes: (25)BuildId :B10.2.06Contact :Brad Weir (brad.weir@nasa.gov)Conventions :CF-1DataResolution :0.5x0.625EastBoundingCoordinate :179.375Format :NetCDF-4/HDF-5History :Original file generated: Tue Mar 15 12:02:48 2022 GMTIdentifierProductDOI :10.5067/Y9M4NM9MPCGHIdentifierProductDOIAuthority :http://doi.org/Institution :NASA GSFC Global Modeling and Assimilation Office and OCO-2 Project, Jet Propulsion LaboratoryLatitudeResolution :0.5LongName :OCO-2 GEOS Level 3 daily, 0.5x0.625 assimilated CO2LongitudeResolution :0.625NorthBoundingCoordinate :90.0ProductionDateTime :2022-03-15T12:02:48ZRangeBeginningDate :2017-08-01RangeBeginningTime :00:00:00.000000RangeEndingDate :2017-08-01RangeEndingTime :23:59:99.999999ShortName :OCO2_GEOS_L3CO2_DAY_10rSouthBoundingCoordinate :-90.0SpatialCoverage :globalTitle :OCO-2 GEOS Level 3 daily, 0.5x0.625 assimilated CO2VersionID :V10rWestBoundingCoordinate :-180.0\n\n\nIn xarray you can inspect just one data variable using dot notation:\n\nds.XCO2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'XCO2' (time: 2500, lat: 361, lon: 576)&gt; Size: 4GB\ndask.array&lt;open_dataset-XCO2, shape=(2500, 361, 576), dtype=float64, chunksize=(200, 200, 200), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * lat      (lat) float64 3kB -90.0 -89.5 -89.0 -88.5 ... 88.5 89.0 89.5 90.0\n  * lon      (lon) float64 5kB -180.0 -179.4 -178.8 -178.1 ... 178.1 178.8 179.4\n  * time     (time) datetime64[ns] 20kB 2015-01-01T12:00:00 ... 2021-11-04T12...\nAttributes:\n    long_name:  Assimilated dry-air column average CO2 daily mean\n    units:      mol CO2/mol dryxarray.DataArray'XCO2'time: 2500lat: 361lon: 576dask.array&lt;chunksize=(200, 200, 200), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n3.87 GiB\n61.04 MiB\n\n\nShape\n(2500, 361, 576)\n(200, 200, 200)\n\n\nDask graph\n78 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (3)lat(lat)float64-90.0 -89.5 -89.0 ... 89.5 90.0long_name :latitudeunits :degrees_northarray([-90. , -89.5, -89. , ...,  89. ,  89.5,  90. ], shape=(361,))lon(lon)float64-180.0 -179.4 ... 178.8 179.4long_name :longitudeunits :degrees_eastarray([-180.   , -179.375, -178.75 , ...,  178.125,  178.75 ,  179.375],\n      shape=(576,))time(time)datetime64[ns]2015-01-01T12:00:00 ... 2021-11-...begin_date :20170801begin_time :120000long_name :timearray(['2015-01-01T12:00:00.000000000', '2015-01-02T12:00:00.000000000',\n       '2015-01-03T12:00:00.000000000', ..., '2021-11-02T12:00:00.000000000',\n       '2021-11-03T12:00:00.000000000', '2021-11-04T12:00:00.000000000'],\n      shape=(2500,), dtype='datetime64[ns]')Indexes: (3)latPandasIndexPandasIndex(Index([-90.0, -89.5, -89.0, -88.5, -88.0, -87.5, -87.0, -86.5, -86.0, -85.5,\n       ...\n        85.5,  86.0,  86.5,  87.0,  87.5,  88.0,  88.5,  89.0,  89.5,  90.0],\n      dtype='float64', name='lat', length=361))lonPandasIndexPandasIndex(Index([  -180.0, -179.375,  -178.75, -178.125,   -177.5, -176.875,  -176.25,\n       -175.625,   -175.0, -174.375,\n       ...\n         173.75,  174.375,    175.0,  175.625,   176.25,  176.875,    177.5,\n        178.125,   178.75,  179.375],\n      dtype='float64', name='lon', length=576))timePandasIndexPandasIndex(DatetimeIndex(['2015-01-01 12:00:00', '2015-01-02 12:00:00',\n               '2015-01-03 12:00:00', '2015-01-04 12:00:00',\n               '2015-01-05 12:00:00', '2015-01-06 12:00:00',\n               '2015-01-07 12:00:00', '2015-01-08 12:00:00',\n               '2015-01-09 12:00:00', '2015-01-10 12:00:00',\n               ...\n               '2021-10-26 12:00:00', '2021-10-27 12:00:00',\n               '2021-10-28 12:00:00', '2021-10-29 12:00:00',\n               '2021-10-30 12:00:00', '2021-10-31 12:00:00',\n               '2021-11-01 12:00:00', '2021-11-02 12:00:00',\n               '2021-11-03 12:00:00', '2021-11-04 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=2500, freq=None))Attributes: (2)long_name :Assimilated dry-air column average CO2 daily meanunits :mol CO2/mol dry"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#plot-data",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#plot-data",
    "title": "Visualize zarr",
    "section": "Plot data",
    "text": "Plot data\nWe can plot the XCO2 variable as an interactive map (with date slider) using hvplot.\n\nds.XCO2.hvplot(\n    x=\"lon\",\n    y=\"lat\",\n    groupby=\"time\",\n    coastline=True,\n    rasterize=True,\n    aggregator=\"mean\",\n    widget_location=\"bottom\",\n    frame_width=600,\n)\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\nThe time slider will only work when running in the notebook. When rendered on a static website the slider has no impact."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html",
    "href": "user-guide/notebooks/quickstarts/download-assets.html",
    "title": "Download STAC assets",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/download-assets.html#run-this-notebook",
    "title": "Download STAC assets",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html#approach",
    "href": "user-guide/notebooks/quickstarts/download-assets.html#approach",
    "title": "Download STAC assets",
    "section": "Approach",
    "text": "Approach\nThis notebook shows how to download data for local use.\nThis is generally not the recommended approach. Whenever possible it is better to not transfer large volumes of data out of the original physical storage location. Instead users should practice data-proximate computing by processing in the same cloud and region. That is why the data for VEDA are hosted in the same region as this VEDA JupyterHub instance.\nHowever, sometimes you do need to download assets. This might be because the assets cannot be accessed directly from remote storage, or you don’t have access to an environment running in the same cloud/region.\nFor these special cases, this is how you go about downloading data:\n\nUse pystac_client to open and search the STAC catalog\nUse stac-asset to download the assets related to that search\nIf you need the file on your local machine, zip and download the output directory\n\nNote that the default examples environment is missing the stac-asset package. We can pip install that before trying to import.\n\n!pip install -q stac-asset\n\n\nimport stac_asset\nfrom pystac_client import Client"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/download-assets.html#declare-your-collection-of-interest",
    "title": "Download STAC assets",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac/\"\ncollection = \"caldor-fire-burn-severity\"\n\n\ncatalog = Client.open(STAC_API_URL)\nsearch = catalog.search(collections=[collection])\n\nprint(f\"Found {len(search.item_collection())} items\")\n\nFound 1 items"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html#download-the-assets",
    "href": "user-guide/notebooks/quickstarts/download-assets.html#download-the-assets",
    "title": "Download STAC assets",
    "section": "Download the assets",
    "text": "Download the assets\nOnce you have identified the items that you are interested in, use stac_asset to download the related assets.\n\nawait stac_asset.download_item_collection(\n    search.item_collection(), \n    directory=\"data\", \n    config=stac_asset.Config(make_directory=True, s3_requester_pays=True)\n)\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"FeatureCollection\"\n        \n    \n                \n            \n                \n                    \n        features[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        \n            id\n            \"bs_to_save\"\n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            end_datetime\n            \"2021-10-21T12:00:00+00:00\"\n        \n    \n            \n        \n            \n                \n        \n            start_datetime\n            \"2021-08-15T00:00:00+00:00\"\n        \n    \n            \n        \n            \n                \n        \n            datetime\n            None\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 5 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        links[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/collections/caldor-fire-burn-severity\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/collections/caldor-fire-burn-severity\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"VEDA (Visualization, Exploration, and Data Analysis) STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/raster/collections/caldor-fire-burn-severity/items/bs_to_save/map?assets=cog_default&rescale=0%2C5&colormap_name=inferno_r\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of Item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            cog_default\n            \n        \n            \n                \n        \n            href\n            \"/home/jovyan/veda-docs/user-guide/notebooks/quickstarts/data/bs_to_save/bs_to_save.tif\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Default COG Layer\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Cloud optimized default layer to display on map\"\n        \n    \n            \n        \n            \n                \n        proj:bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            4326\n        \n    \n            \n        \n            \n                \n        \n            proj:wkt2\n            \"GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]\"\n        \n    \n            \n        \n            \n                \n        proj:shape[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            1103\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            2149\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        raster:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            scale\n            1.0\n        \n    \n            \n        \n            \n                \n        \n            nodata\n            -100.0\n        \n    \n            \n        \n            \n                \n        \n            offset\n            0.0\n        \n    \n            \n        \n            \n                \n        \n            sampling\n            \"area\"\n        \n    \n            \n        \n            \n                \n        \n            data_type\n            \"float64\"\n        \n    \n            \n        \n            \n                \n        \n            histogram\n            \n        \n            \n                \n        \n            max\n            4.0\n        \n    \n            \n        \n            \n                \n        \n            min\n            1.0\n        \n    \n            \n        \n            \n                \n        \n            count\n            11\n        \n    \n            \n        \n            \n                \n        buckets[] 10 items\n        \n            \n        \n            \n                \n        \n            0\n            10233\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            67409\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            71518\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            24232\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            statistics\n            \n        \n            \n                \n        \n            mean\n            2.63295307741995\n        \n    \n            \n        \n            \n                \n        \n            stddev\n            0.7936384596443959\n        \n    \n            \n        \n            \n                \n        \n            maximum\n            4.0\n        \n    \n            \n        \n            \n                \n        \n            minimum\n            1.0\n        \n    \n            \n        \n            \n                \n        \n            valid_percent\n            32.191658745247146\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 5 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:projjson\n            \n        \n            \n                \n        \n            id\n            \n        \n            \n                \n        \n            code\n            4326\n        \n    \n            \n        \n            \n                \n        \n            authority\n            \"EPSG\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            name\n            \"WGS 84\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"GeographicCRS\"\n        \n    \n            \n        \n            \n                \n        \n            datum\n            \n        \n            \n                \n        \n            name\n            \"World Geodetic System 1984\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"GeodeticReferenceFrame\"\n        \n    \n            \n        \n            \n                \n        \n            ellipsoid\n            \n        \n            \n                \n        \n            name\n            \"WGS 84\"\n        \n    \n            \n        \n            \n                \n        \n            semi_major_axis\n            6378137\n        \n    \n            \n        \n            \n                \n        \n            inverse_flattening\n            298.257223563\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            $schema\n            \"https://proj.org/schemas/v0.4/projjson.schema.json\"\n        \n    \n            \n        \n            \n                \n        \n            coordinate_system\n            \n        \n            \n                \n        axis[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Geodetic latitude\"\n        \n    \n            \n        \n            \n                \n        \n            unit\n            \"degree\"\n        \n    \n            \n        \n            \n                \n        \n            direction\n            \"north\"\n        \n    \n            \n        \n            \n                \n        \n            abbreviation\n            \"Lat\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Geodetic longitude\"\n        \n    \n            \n        \n            \n                \n        \n            unit\n            \"degree\"\n        \n    \n            \n        \n            \n                \n        \n            direction\n            \"east\"\n        \n    \n            \n        \n            \n                \n        \n            abbreviation\n            \"Lon\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            subtype\n            \"ellipsoidal\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        proj:transform[] 9 items\n        \n            \n        \n            \n                \n        \n            0\n            0.0003230948999417961\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -0.00032309489994179427\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        roles[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"layer\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"/home/jovyan/veda-docs/user-guide/notebooks/quickstarts/data/bs_to_save/preview.png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        stac_extensions[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"caldor-fire-burn-severity\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n        \n    \n\n\n\nNote: For downloading just one item use stac_asset.download_item."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html#download-from-jupyterhub",
    "href": "user-guide/notebooks/quickstarts/download-assets.html#download-from-jupyterhub",
    "title": "Download STAC assets",
    "section": "Download from JupyterHub",
    "text": "Download from JupyterHub\nIf you want to further download from this JupyterHub to your local machine you can zip the data directory:\n\n!zip -r data.zip data\n\nupdating: data/ (stored 0%)\nupdating: data/item-collection.json (deflated 74%)\nupdating: data/bs_to_save/ (stored 0%)\nupdating: data/bs_to_save/bs_to_save.tif (deflated 16%)\nupdating: data/bs_to_save/preview.png (deflated 3%)\n\n\nThen right click on the the zipped file in the Jupyter file browser and select “Download”\n\n\n\nRight click on zip file to see options that include “Download”"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html",
    "title": "Calculate timeseries from COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#run-this-notebook",
    "title": "Calculate timeseries from COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#approach",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#approach",
    "title": "Calculate timeseries from COGs",
    "section": "Approach",
    "text": "Approach\n\nUse pystac_client to open the STAC catalog and retrieve the items in the collection\nUse stackstac to create an xarray dataset containing all the items cropped to AOI\nCalculate the mean for each timestep over the AOI\n\n\nfrom pystac_client import Client\nimport pandas as pd\nimport stackstac\n\nimport rioxarray  # noqa\nimport hvplot.xarray  # noqa"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#declare-your-collection-of-interest",
    "title": "Calculate timeseries from COGs",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac/\"\ncollection = \"no2-monthly\""
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#discover-items-in-collection-for-region-and-time-of-interest",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#discover-items-in-collection-for-region-and-time-of-interest",
    "title": "Calculate timeseries from COGs",
    "section": "Discover items in collection for region and time of interest",
    "text": "Discover items in collection for region and time of interest\nUse pystac_client to search the STAC collection for a particular area of interest within specified datetime bounds.\n\nchina_bbox = [\n    73.675,\n    18.198,\n    135.026,\n    53.459,\n]\ndatetime = \"2000-01-01/2025-07-25\"\n\n\ncatalog = Client.open(STAC_API_URL)\nsearch = catalog.search(\n    bbox=china_bbox, datetime=datetime, collections=[collection], limit=1000\n)\nitem_collection = search.item_collection()\nprint(f\"Found {len(item_collection)} items\")\n\nFound 93 items"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#read-data",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#read-data",
    "title": "Calculate timeseries from COGs",
    "section": "Read data",
    "text": "Read data\nRead in data using xarray using a combination of xpystac, stackstac, and rasterio.\n\nda = stackstac.stack(item_collection, epsg=4326)\nda = da.assign_coords({\"time\": pd.to_datetime(da.start_datetime)}).squeeze()\nda\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'stackstac-707c2fec3a4bde6be0d838dc97f60ec1' (time: 93,\n                                                                y: 1800, x: 3600)&gt; Size: 5GB\ndask.array&lt;getitem, shape=(93, 1800, 3600), dtype=float64, chunksize=(1, 1024, 1024), chunktype=numpy.ndarray&gt;\nCoordinates: (12/17)\n    id              (time) &lt;U37 14kB 'OMI_trno2_0.10x0.10_202309_Col3_V4.nc' ...\n    band            &lt;U11 44B 'cog_default'\n  * x               (x) float64 29kB -180.0 -179.9 -179.8 ... 179.7 179.8 179.9\n  * y               (y) float64 14kB 90.0 89.9 89.8 89.7 ... -89.7 -89.8 -89.9\n    start_datetime  (time) &lt;U25 9kB '2023-09-01T00:00:00+00:00' ... '2016-01-...\n    end_datetime    (time) &lt;U25 9kB '2023-09-30T00:00:00+00:00' ... '2016-01-...\n    ...              ...\n    proj:code       &lt;U9 36B 'EPSG:4326'\n    title           &lt;U17 68B 'Default COG Layer'\n    proj:shape      object 8B {1800, 3600}\n    description     &lt;U47 188B 'Cloud optimized default layer to display on map'\n    epsg            int64 8B 4326\n  * time            (time) datetime64[ns, UTC] 744B 2023-09-01T00:00:00+00:00...\nAttributes:\n    spec:        RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), r...\n    crs:         epsg:4326\n    transform:   | 0.10, 0.00,-180.00|\\n| 0.00,-0.10, 90.00|\\n| 0.00, 0.00, 1...\n    resolution:  0.1xarray.DataArray'stackstac-707c2fec3a4bde6be0d838dc97f60ec1'time: 93y: 1800x: 3600dask.array&lt;chunksize=(1, 1024, 1024), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n4.49 GiB\n8.00 MiB\n\n\nShape\n(93, 1800, 3600)\n(1, 1024, 1024)\n\n\nDask graph\n744 chunks in 4 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (17)id(time)&lt;U37'OMI_trno2_0.10x0.10_202309_Col3...array(['OMI_trno2_0.10x0.10_202309_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202308_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202307_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202306_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202305_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202304_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202303_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202302_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202301_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202212_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202211_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202210_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202209_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202208_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202207_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202206_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202205_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202204_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202203_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202202_Col3_V4.nc',\n...\n       'OMI_trno2_0.10x0.10_201708_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201707_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201706_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201705_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201704_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201703_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201702_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201701_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201612_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201611_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201610_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201609_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201608_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201607_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201606_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201605_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201604_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201603_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201602_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201601_Col3_V4.nc'], dtype='&lt;U37')band()&lt;U11'cog_default'array('cog_default', dtype='&lt;U11')x(x)float64-180.0 -179.9 ... 179.8 179.9array([-180. , -179.9, -179.8, ...,  179.7,  179.8,  179.9], shape=(3600,))y(y)float6490.0 89.9 89.8 ... -89.8 -89.9array([ 90. ,  89.9,  89.8, ..., -89.7, -89.8, -89.9], shape=(1800,))start_datetime(time)&lt;U25'2023-09-01T00:00:00+00:00' ... ...array(['2023-09-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n...\n       '2019-03-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-01-01T00:00:00+00:00'], dtype='&lt;U25')end_datetime(time)&lt;U25'2023-09-30T00:00:00+00:00' ... ...array(['2023-09-30T00:00:00+00:00', '2023-08-31T00:00:00+00:00',\n       '2023-07-31T00:00:00+00:00', '2023-06-30T00:00:00+00:00',\n       '2023-05-31T00:00:00+00:00', '2023-04-30T00:00:00+00:00',\n       '2023-03-31T00:00:00+00:00', '2023-02-28T00:00:00+00:00',\n       '2023-01-31T00:00:00+00:00', '2022-12-31T00:00:00+00:00',\n       '2022-11-30T00:00:00+00:00', '2022-10-31T00:00:00+00:00',\n       '2022-09-30T00:00:00+00:00', '2022-08-31T00:00:00+00:00',\n       '2022-07-31T00:00:00+00:00', '2022-06-30T00:00:00+00:00',\n       '2022-05-31T00:00:00+00:00', '2022-04-30T00:00:00+00:00',\n       '2022-03-31T00:00:00+00:00', '2022-02-28T00:00:00+00:00',\n       '2022-01-31T00:00:00+00:00', '2021-12-31T00:00:00+00:00',\n       '2021-11-30T00:00:00+00:00', '2021-10-31T00:00:00+00:00',\n       '2021-09-30T00:00:00+00:00', '2021-08-31T00:00:00+00:00',\n       '2021-07-31T00:00:00+00:00', '2021-06-30T00:00:00+00:00',\n       '2021-05-31T00:00:00+00:00', '2021-04-30T00:00:00+00:00',\n       '2021-03-31T00:00:00+00:00', '2021-02-28T00:00:00+00:00',\n       '2021-01-31T00:00:00+00:00', '2020-12-31T00:00:00+00:00',\n       '2020-11-30T00:00:00+00:00', '2020-10-31T00:00:00+00:00',\n       '2020-09-30T00:00:00+00:00', '2020-08-31T00:00:00+00:00',\n       '2020-07-31T00:00:00+00:00', '2020-06-30T00:00:00+00:00',\n...\n       '2019-03-31T00:00:00+00:00', '2019-02-28T00:00:00+00:00',\n       '2019-01-31T00:00:00+00:00', '2018-12-31T00:00:00+00:00',\n       '2018-11-30T00:00:00+00:00', '2018-10-31T00:00:00+00:00',\n       '2018-09-30T00:00:00+00:00', '2018-08-31T00:00:00+00:00',\n       '2018-07-31T00:00:00+00:00', '2018-06-30T00:00:00+00:00',\n       '2018-05-31T00:00:00+00:00', '2018-04-30T00:00:00+00:00',\n       '2018-03-31T00:00:00+00:00', '2018-02-28T00:00:00+00:00',\n       '2018-01-31T00:00:00+00:00', '2017-12-31T00:00:00+00:00',\n       '2017-11-30T00:00:00+00:00', '2017-10-31T00:00:00+00:00',\n       '2017-09-30T00:00:00+00:00', '2017-08-31T00:00:00+00:00',\n       '2017-07-31T00:00:00+00:00', '2017-06-30T00:00:00+00:00',\n       '2017-05-31T00:00:00+00:00', '2017-04-30T00:00:00+00:00',\n       '2017-03-31T00:00:00+00:00', '2017-02-28T00:00:00+00:00',\n       '2017-01-31T00:00:00+00:00', '2016-12-31T00:00:00+00:00',\n       '2016-11-30T00:00:00+00:00', '2016-10-31T00:00:00+00:00',\n       '2016-09-30T00:00:00+00:00', '2016-08-31T00:00:00+00:00',\n       '2016-07-31T00:00:00+00:00', '2016-06-30T00:00:00+00:00',\n       '2016-05-31T00:00:00+00:00', '2016-04-30T00:00:00+00:00',\n       '2016-03-31T00:00:00+00:00', '2016-02-29T00:00:00+00:00',\n       '2016-01-31T00:00:00+00:00'], dtype='&lt;U25')proj:wkt2()&lt;U277'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984...array('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n      dtype='&lt;U277')proj:transform()object{0.1, 0.0, 1.0, -0.1, -180.0, 90.0}array({0.1, 0.0, 1.0, -0.1, -180.0, 90.0}, dtype=object)proj:projjson()object{'id': {'code': 4326, 'authority...array({'id': {'code': 4326, 'authority': 'EPSG'}, 'name': 'WGS 84', 'type': 'GeographicCRS', 'datum': {'name': 'World Geodetic System 1984', 'type': 'GeodeticReferenceFrame', 'ellipsoid': {'name': 'WGS 84', 'semi_major_axis': 6378137, 'inverse_flattening': 298.257223563}}, '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json', 'coordinate_system': {'axis': [{'name': 'Geodetic latitude', 'unit': 'degree', 'direction': 'north', 'abbreviation': 'Lat'}, {'name': 'Geodetic longitude', 'unit': 'degree', 'direction': 'east', 'abbreviation': 'Lon'}], 'subtype': 'ellipsoidal'}},\n      dtype=object)proj:bbox()object{90.0, 180.0, -90.0, -180.0}array({90.0, 180.0, -90.0, -180.0}, dtype=object)proj:geometry()object{'type': 'Polygon', 'coordinates...array({'type': 'Polygon', 'coordinates': [[[-180.0, -90.0], [180.0, -90.0], [180.0, 90.0], [-180.0, 90.0], [-180.0, -90.0]]]},\n      dtype=object)proj:code()&lt;U9'EPSG:4326'array('EPSG:4326', dtype='&lt;U9')title()&lt;U17'Default COG Layer'array('Default COG Layer', dtype='&lt;U17')proj:shape()object{1800, 3600}array({1800, 3600}, dtype=object)description()&lt;U47'Cloud optimized default layer t...array('Cloud optimized default layer to display on map', dtype='&lt;U47')epsg()int644326array(4326)time(time)datetime64[ns, UTC]2023-09-01T00:00:00+00:00 ... 20...&lt;DatetimeArray&gt;\n['2023-09-01 00:00:00+00:00', '2023-08-01 00:00:00+00:00',\n '2023-07-01 00:00:00+00:00', '2023-06-01 00:00:00+00:00',\n '2023-05-01 00:00:00+00:00', '2023-04-01 00:00:00+00:00',\n '2023-03-01 00:00:00+00:00', '2023-02-01 00:00:00+00:00',\n '2023-01-01 00:00:00+00:00', '2022-12-01 00:00:00+00:00',\n '2022-11-01 00:00:00+00:00', '2022-10-01 00:00:00+00:00',\n '2022-09-01 00:00:00+00:00', '2022-08-01 00:00:00+00:00',\n '2022-07-01 00:00:00+00:00', '2022-06-01 00:00:00+00:00',\n '2022-05-01 00:00:00+00:00', '2022-04-01 00:00:00+00:00',\n '2022-03-01 00:00:00+00:00', '2022-02-01 00:00:00+00:00',\n '2022-01-01 00:00:00+00:00', '2021-12-01 00:00:00+00:00',\n '2021-11-01 00:00:00+00:00', '2021-10-01 00:00:00+00:00',\n '2021-09-01 00:00:00+00:00', '2021-08-01 00:00:00+00:00',\n '2021-07-01 00:00:00+00:00', '2021-06-01 00:00:00+00:00',\n '2021-05-01 00:00:00+00:00', '2021-04-01 00:00:00+00:00',\n '2021-03-01 00:00:00+00:00', '2021-02-01 00:00:00+00:00',\n '2021-01-01 00:00:00+00:00', '2020-12-01 00:00:00+00:00',\n '2020-11-01 00:00:00+00:00', '2020-10-01 00:00:00+00:00',\n '2020-09-01 00:00:00+00:00', '2020-08-01 00:00:00+00:00',\n '2020-07-01 00:00:00+00:00', '2020-06-01 00:00:00+00:00',\n '2020-05-01 00:00:00+00:00', '2020-04-01 00:00:00+00:00',\n '2020-03-01 00:00:00+00:00', '2020-02-01 00:00:00+00:00',\n '2020-01-01 00:00:00+00:00', '2019-12-01 00:00:00+00:00',\n '2019-11-01 00:00:00+00:00', '2019-10-01 00:00:00+00:00',\n '2019-09-01 00:00:00+00:00', '2019-08-01 00:00:00+00:00',\n '2019-07-01 00:00:00+00:00', '2019-06-01 00:00:00+00:00',\n '2019-05-01 00:00:00+00:00', '2019-04-01 00:00:00+00:00',\n '2019-03-01 00:00:00+00:00', '2019-02-01 00:00:00+00:00',\n '2019-01-01 00:00:00+00:00', '2018-12-01 00:00:00+00:00',\n '2018-11-01 00:00:00+00:00', '2018-10-01 00:00:00+00:00',\n '2018-09-01 00:00:00+00:00', '2018-08-01 00:00:00+00:00',\n '2018-07-01 00:00:00+00:00', '2018-06-01 00:00:00+00:00',\n '2018-05-01 00:00:00+00:00', '2018-04-01 00:00:00+00:00',\n '2018-03-01 00:00:00+00:00', '2018-02-01 00:00:00+00:00',\n '2018-01-01 00:00:00+00:00', '2017-12-01 00:00:00+00:00',\n '2017-11-01 00:00:00+00:00', '2017-10-01 00:00:00+00:00',\n '2017-09-01 00:00:00+00:00', '2017-08-01 00:00:00+00:00',\n '2017-07-01 00:00:00+00:00', '2017-06-01 00:00:00+00:00',\n '2017-05-01 00:00:00+00:00', '2017-04-01 00:00:00+00:00',\n '2017-03-01 00:00:00+00:00', '2017-02-01 00:00:00+00:00',\n '2017-01-01 00:00:00+00:00', '2016-12-01 00:00:00+00:00',\n '2016-11-01 00:00:00+00:00', '2016-10-01 00:00:00+00:00',\n '2016-09-01 00:00:00+00:00', '2016-08-01 00:00:00+00:00',\n '2016-07-01 00:00:00+00:00', '2016-06-01 00:00:00+00:00',\n '2016-05-01 00:00:00+00:00', '2016-04-01 00:00:00+00:00',\n '2016-03-01 00:00:00+00:00', '2016-02-01 00:00:00+00:00',\n '2016-01-01 00:00:00+00:00']\nLength: 93, dtype: datetime64[ns, UTC]Indexes: (3)xPandasIndexPandasIndex(Index([            -180.0,             -179.9,             -179.8,\n                   -179.7,             -179.6,             -179.5,\n                   -179.4,             -179.3,             -179.2,\n                   -179.1,\n       ...\n                    179.0, 179.10000000000002, 179.20000000000005,\n                    179.3, 179.40000000000003,              179.5,\n       179.60000000000002, 179.70000000000005,              179.8,\n       179.90000000000003],\n      dtype='float64', name='x', length=3600))yPandasIndexPandasIndex(Index([              90.0,               89.9,               89.8,\n                     89.7,               89.6,               89.5,\n                     89.4,               89.3,               89.2,\n                     89.1,\n       ...\n                    -89.0, -89.10000000000002, -89.20000000000002,\n       -89.30000000000001,              -89.4,              -89.5,\n       -89.60000000000002, -89.70000000000002, -89.80000000000001,\n                    -89.9],\n      dtype='float64', name='y', length=1800))timePandasIndexPandasIndex(DatetimeIndex(['2023-09-01 00:00:00+00:00', '2023-08-01 00:00:00+00:00',\n               '2023-07-01 00:00:00+00:00', '2023-06-01 00:00:00+00:00',\n               '2023-05-01 00:00:00+00:00', '2023-04-01 00:00:00+00:00',\n               '2023-03-01 00:00:00+00:00', '2023-02-01 00:00:00+00:00',\n               '2023-01-01 00:00:00+00:00', '2022-12-01 00:00:00+00:00',\n               '2022-11-01 00:00:00+00:00', '2022-10-01 00:00:00+00:00',\n               '2022-09-01 00:00:00+00:00', '2022-08-01 00:00:00+00:00',\n               '2022-07-01 00:00:00+00:00', '2022-06-01 00:00:00+00:00',\n               '2022-05-01 00:00:00+00:00', '2022-04-01 00:00:00+00:00',\n               '2022-03-01 00:00:00+00:00', '2022-02-01 00:00:00+00:00',\n               '2022-01-01 00:00:00+00:00', '2021-12-01 00:00:00+00:00',\n               '2021-11-01 00:00:00+00:00', '2021-10-01 00:00:00+00:00',\n               '2021-09-01 00:00:00+00:00', '2021-08-01 00:00:00+00:00',\n               '2021-07-01 00:00:00+00:00', '2021-06-01 00:00:00+00:00',\n               '2021-05-01 00:00:00+00:00', '2021-04-01 00:00:00+00:00',\n               '2021-03-01 00:00:00+00:00', '2021-02-01 00:00:00+00:00',\n               '2021-01-01 00:00:00+00:00', '2020-12-01 00:00:00+00:00',\n               '2020-11-01 00:00:00+00:00', '2020-10-01 00:00:00+00:00',\n               '2020-09-01 00:00:00+00:00', '2020-08-01 00:00:00+00:00',\n               '2020-07-01 00:00:00+00:00', '2020-06-01 00:00:00+00:00',\n               '2020-05-01 00:00:00+00:00', '2020-04-01 00:00:00+00:00',\n               '2020-03-01 00:00:00+00:00', '2020-02-01 00:00:00+00:00',\n               '2020-01-01 00:00:00+00:00', '2019-12-01 00:00:00+00:00',\n               '2019-11-01 00:00:00+00:00', '2019-10-01 00:00:00+00:00',\n               '2019-09-01 00:00:00+00:00', '2019-08-01 00:00:00+00:00',\n               '2019-07-01 00:00:00+00:00', '2019-06-01 00:00:00+00:00',\n               '2019-05-01 00:00:00+00:00', '2019-04-01 00:00:00+00:00',\n               '2019-03-01 00:00:00+00:00', '2019-02-01 00:00:00+00:00',\n               '2019-01-01 00:00:00+00:00', '2018-12-01 00:00:00+00:00',\n               '2018-11-01 00:00:00+00:00', '2018-10-01 00:00:00+00:00',\n               '2018-09-01 00:00:00+00:00', '2018-08-01 00:00:00+00:00',\n               '2018-07-01 00:00:00+00:00', '2018-06-01 00:00:00+00:00',\n               '2018-05-01 00:00:00+00:00', '2018-04-01 00:00:00+00:00',\n               '2018-03-01 00:00:00+00:00', '2018-02-01 00:00:00+00:00',\n               '2018-01-01 00:00:00+00:00', '2017-12-01 00:00:00+00:00',\n               '2017-11-01 00:00:00+00:00', '2017-10-01 00:00:00+00:00',\n               '2017-09-01 00:00:00+00:00', '2017-08-01 00:00:00+00:00',\n               '2017-07-01 00:00:00+00:00', '2017-06-01 00:00:00+00:00',\n               '2017-05-01 00:00:00+00:00', '2017-04-01 00:00:00+00:00',\n               '2017-03-01 00:00:00+00:00', '2017-02-01 00:00:00+00:00',\n               '2017-01-01 00:00:00+00:00', '2016-12-01 00:00:00+00:00',\n               '2016-11-01 00:00:00+00:00', '2016-10-01 00:00:00+00:00',\n               '2016-09-01 00:00:00+00:00', '2016-08-01 00:00:00+00:00',\n               '2016-07-01 00:00:00+00:00', '2016-06-01 00:00:00+00:00',\n               '2016-05-01 00:00:00+00:00', '2016-04-01 00:00:00+00:00',\n               '2016-03-01 00:00:00+00:00', '2016-02-01 00:00:00+00:00',\n               '2016-01-01 00:00:00+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None))Attributes: (4)spec :RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), resolutions_xy=(0.1, 0.1))crs :epsg:4326transform :| 0.10, 0.00,-180.00|\n| 0.00,-0.10, 90.00|\n| 0.00, 0.00, 1.00|resolution :0.1"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#clip-the-data-to-the-bounding-box-for-china",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#clip-the-data-to-the-bounding-box-for-china",
    "title": "Calculate timeseries from COGs",
    "section": "Clip the data to the bounding box for China",
    "text": "Clip the data to the bounding box for China\n\n# Subset to Bounding Box for China\nsubset = da.rio.clip_box(*china_bbox)\nsubset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'stackstac-707c2fec3a4bde6be0d838dc97f60ec1' (time: 93,\n                                                                y: 354, x: 614)&gt; Size: 162MB\ndask.array&lt;getitem, shape=(93, 354, 614), dtype=float64, chunksize=(1, 354, 535), chunktype=numpy.ndarray&gt;\nCoordinates: (12/18)\n    id              (time) &lt;U37 14kB 'OMI_trno2_0.10x0.10_202309_Col3_V4.nc' ...\n    band            &lt;U11 44B 'cog_default'\n  * x               (x) float64 5kB 73.7 73.8 73.9 74.0 ... 134.8 134.9 135.0\n  * y               (y) float64 3kB 53.5 53.4 53.3 53.2 ... 18.5 18.4 18.3 18.2\n    start_datetime  (time) &lt;U25 9kB '2023-09-01T00:00:00+00:00' ... '2016-01-...\n    end_datetime    (time) &lt;U25 9kB '2023-09-30T00:00:00+00:00' ... '2016-01-...\n    ...              ...\n    title           &lt;U17 68B 'Default COG Layer'\n    proj:shape      object 8B {1800, 3600}\n    description     &lt;U47 188B 'Cloud optimized default layer to display on map'\n    epsg            int64 8B 4326\n  * time            (time) datetime64[ns, UTC] 744B 2023-09-01T00:00:00+00:00...\n    spatial_ref     int64 8B 0\nAttributes:\n    spec:        RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), r...\n    resolution:  0.1xarray.DataArray'stackstac-707c2fec3a4bde6be0d838dc97f60ec1'time: 93y: 354x: 614dask.array&lt;chunksize=(1, 354, 535), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n154.22 MiB\n1.44 MiB\n\n\nShape\n(93, 354, 614)\n(1, 354, 535)\n\n\nDask graph\n186 chunks in 5 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (18)id(time)&lt;U37'OMI_trno2_0.10x0.10_202309_Col3...array(['OMI_trno2_0.10x0.10_202309_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202308_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202307_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202306_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202305_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202304_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202303_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202302_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202301_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202212_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202211_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202210_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202209_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202208_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202207_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202206_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202205_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202204_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202203_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202202_Col3_V4.nc',\n...\n       'OMI_trno2_0.10x0.10_201708_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201707_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201706_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201705_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201704_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201703_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201702_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201701_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201612_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201611_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201610_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201609_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201608_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201607_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201606_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201605_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201604_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201603_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201602_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201601_Col3_V4.nc'], dtype='&lt;U37')band()&lt;U11'cog_default'array('cog_default', dtype='&lt;U11')x(x)float6473.7 73.8 73.9 ... 134.9 135.0axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([ 73.7,  73.8,  73.9, ..., 134.8, 134.9, 135. ], shape=(614,))y(y)float6453.5 53.4 53.3 ... 18.4 18.3 18.2axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([53.5, 53.4, 53.3, ..., 18.4, 18.3, 18.2], shape=(354,))start_datetime(time)&lt;U25'2023-09-01T00:00:00+00:00' ... ...array(['2023-09-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n...\n       '2019-03-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-01-01T00:00:00+00:00'], dtype='&lt;U25')end_datetime(time)&lt;U25'2023-09-30T00:00:00+00:00' ... ...array(['2023-09-30T00:00:00+00:00', '2023-08-31T00:00:00+00:00',\n       '2023-07-31T00:00:00+00:00', '2023-06-30T00:00:00+00:00',\n       '2023-05-31T00:00:00+00:00', '2023-04-30T00:00:00+00:00',\n       '2023-03-31T00:00:00+00:00', '2023-02-28T00:00:00+00:00',\n       '2023-01-31T00:00:00+00:00', '2022-12-31T00:00:00+00:00',\n       '2022-11-30T00:00:00+00:00', '2022-10-31T00:00:00+00:00',\n       '2022-09-30T00:00:00+00:00', '2022-08-31T00:00:00+00:00',\n       '2022-07-31T00:00:00+00:00', '2022-06-30T00:00:00+00:00',\n       '2022-05-31T00:00:00+00:00', '2022-04-30T00:00:00+00:00',\n       '2022-03-31T00:00:00+00:00', '2022-02-28T00:00:00+00:00',\n       '2022-01-31T00:00:00+00:00', '2021-12-31T00:00:00+00:00',\n       '2021-11-30T00:00:00+00:00', '2021-10-31T00:00:00+00:00',\n       '2021-09-30T00:00:00+00:00', '2021-08-31T00:00:00+00:00',\n       '2021-07-31T00:00:00+00:00', '2021-06-30T00:00:00+00:00',\n       '2021-05-31T00:00:00+00:00', '2021-04-30T00:00:00+00:00',\n       '2021-03-31T00:00:00+00:00', '2021-02-28T00:00:00+00:00',\n       '2021-01-31T00:00:00+00:00', '2020-12-31T00:00:00+00:00',\n       '2020-11-30T00:00:00+00:00', '2020-10-31T00:00:00+00:00',\n       '2020-09-30T00:00:00+00:00', '2020-08-31T00:00:00+00:00',\n       '2020-07-31T00:00:00+00:00', '2020-06-30T00:00:00+00:00',\n...\n       '2019-03-31T00:00:00+00:00', '2019-02-28T00:00:00+00:00',\n       '2019-01-31T00:00:00+00:00', '2018-12-31T00:00:00+00:00',\n       '2018-11-30T00:00:00+00:00', '2018-10-31T00:00:00+00:00',\n       '2018-09-30T00:00:00+00:00', '2018-08-31T00:00:00+00:00',\n       '2018-07-31T00:00:00+00:00', '2018-06-30T00:00:00+00:00',\n       '2018-05-31T00:00:00+00:00', '2018-04-30T00:00:00+00:00',\n       '2018-03-31T00:00:00+00:00', '2018-02-28T00:00:00+00:00',\n       '2018-01-31T00:00:00+00:00', '2017-12-31T00:00:00+00:00',\n       '2017-11-30T00:00:00+00:00', '2017-10-31T00:00:00+00:00',\n       '2017-09-30T00:00:00+00:00', '2017-08-31T00:00:00+00:00',\n       '2017-07-31T00:00:00+00:00', '2017-06-30T00:00:00+00:00',\n       '2017-05-31T00:00:00+00:00', '2017-04-30T00:00:00+00:00',\n       '2017-03-31T00:00:00+00:00', '2017-02-28T00:00:00+00:00',\n       '2017-01-31T00:00:00+00:00', '2016-12-31T00:00:00+00:00',\n       '2016-11-30T00:00:00+00:00', '2016-10-31T00:00:00+00:00',\n       '2016-09-30T00:00:00+00:00', '2016-08-31T00:00:00+00:00',\n       '2016-07-31T00:00:00+00:00', '2016-06-30T00:00:00+00:00',\n       '2016-05-31T00:00:00+00:00', '2016-04-30T00:00:00+00:00',\n       '2016-03-31T00:00:00+00:00', '2016-02-29T00:00:00+00:00',\n       '2016-01-31T00:00:00+00:00'], dtype='&lt;U25')proj:wkt2()&lt;U277'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984...array('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n      dtype='&lt;U277')proj:transform()object{0.1, 0.0, 1.0, -0.1, -180.0, 90.0}array({0.1, 0.0, 1.0, -0.1, -180.0, 90.0}, dtype=object)proj:projjson()object{'id': {'code': 4326, 'authority...array({'id': {'code': 4326, 'authority': 'EPSG'}, 'name': 'WGS 84', 'type': 'GeographicCRS', 'datum': {'name': 'World Geodetic System 1984', 'type': 'GeodeticReferenceFrame', 'ellipsoid': {'name': 'WGS 84', 'semi_major_axis': 6378137, 'inverse_flattening': 298.257223563}}, '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json', 'coordinate_system': {'axis': [{'name': 'Geodetic latitude', 'unit': 'degree', 'direction': 'north', 'abbreviation': 'Lat'}, {'name': 'Geodetic longitude', 'unit': 'degree', 'direction': 'east', 'abbreviation': 'Lon'}], 'subtype': 'ellipsoidal'}},\n      dtype=object)proj:bbox()object{90.0, 180.0, -90.0, -180.0}array({90.0, 180.0, -90.0, -180.0}, dtype=object)proj:geometry()object{'type': 'Polygon', 'coordinates...array({'type': 'Polygon', 'coordinates': [[[-180.0, -90.0], [180.0, -90.0], [180.0, 90.0], [-180.0, 90.0], [-180.0, -90.0]]]},\n      dtype=object)proj:code()&lt;U9'EPSG:4326'array('EPSG:4326', dtype='&lt;U9')title()&lt;U17'Default COG Layer'array('Default COG Layer', dtype='&lt;U17')proj:shape()object{1800, 3600}array({1800, 3600}, dtype=object)description()&lt;U47'Cloud optimized default layer t...array('Cloud optimized default layer to display on map', dtype='&lt;U47')epsg()int644326array(4326)time(time)datetime64[ns, UTC]2023-09-01T00:00:00+00:00 ... 20...&lt;DatetimeArray&gt;\n['2023-09-01 00:00:00+00:00', '2023-08-01 00:00:00+00:00',\n '2023-07-01 00:00:00+00:00', '2023-06-01 00:00:00+00:00',\n '2023-05-01 00:00:00+00:00', '2023-04-01 00:00:00+00:00',\n '2023-03-01 00:00:00+00:00', '2023-02-01 00:00:00+00:00',\n '2023-01-01 00:00:00+00:00', '2022-12-01 00:00:00+00:00',\n '2022-11-01 00:00:00+00:00', '2022-10-01 00:00:00+00:00',\n '2022-09-01 00:00:00+00:00', '2022-08-01 00:00:00+00:00',\n '2022-07-01 00:00:00+00:00', '2022-06-01 00:00:00+00:00',\n '2022-05-01 00:00:00+00:00', '2022-04-01 00:00:00+00:00',\n '2022-03-01 00:00:00+00:00', '2022-02-01 00:00:00+00:00',\n '2022-01-01 00:00:00+00:00', '2021-12-01 00:00:00+00:00',\n '2021-11-01 00:00:00+00:00', '2021-10-01 00:00:00+00:00',\n '2021-09-01 00:00:00+00:00', '2021-08-01 00:00:00+00:00',\n '2021-07-01 00:00:00+00:00', '2021-06-01 00:00:00+00:00',\n '2021-05-01 00:00:00+00:00', '2021-04-01 00:00:00+00:00',\n '2021-03-01 00:00:00+00:00', '2021-02-01 00:00:00+00:00',\n '2021-01-01 00:00:00+00:00', '2020-12-01 00:00:00+00:00',\n '2020-11-01 00:00:00+00:00', '2020-10-01 00:00:00+00:00',\n '2020-09-01 00:00:00+00:00', '2020-08-01 00:00:00+00:00',\n '2020-07-01 00:00:00+00:00', '2020-06-01 00:00:00+00:00',\n '2020-05-01 00:00:00+00:00', '2020-04-01 00:00:00+00:00',\n '2020-03-01 00:00:00+00:00', '2020-02-01 00:00:00+00:00',\n '2020-01-01 00:00:00+00:00', '2019-12-01 00:00:00+00:00',\n '2019-11-01 00:00:00+00:00', '2019-10-01 00:00:00+00:00',\n '2019-09-01 00:00:00+00:00', '2019-08-01 00:00:00+00:00',\n '2019-07-01 00:00:00+00:00', '2019-06-01 00:00:00+00:00',\n '2019-05-01 00:00:00+00:00', '2019-04-01 00:00:00+00:00',\n '2019-03-01 00:00:00+00:00', '2019-02-01 00:00:00+00:00',\n '2019-01-01 00:00:00+00:00', '2018-12-01 00:00:00+00:00',\n '2018-11-01 00:00:00+00:00', '2018-10-01 00:00:00+00:00',\n '2018-09-01 00:00:00+00:00', '2018-08-01 00:00:00+00:00',\n '2018-07-01 00:00:00+00:00', '2018-06-01 00:00:00+00:00',\n '2018-05-01 00:00:00+00:00', '2018-04-01 00:00:00+00:00',\n '2018-03-01 00:00:00+00:00', '2018-02-01 00:00:00+00:00',\n '2018-01-01 00:00:00+00:00', '2017-12-01 00:00:00+00:00',\n '2017-11-01 00:00:00+00:00', '2017-10-01 00:00:00+00:00',\n '2017-09-01 00:00:00+00:00', '2017-08-01 00:00:00+00:00',\n '2017-07-01 00:00:00+00:00', '2017-06-01 00:00:00+00:00',\n '2017-05-01 00:00:00+00:00', '2017-04-01 00:00:00+00:00',\n '2017-03-01 00:00:00+00:00', '2017-02-01 00:00:00+00:00',\n '2017-01-01 00:00:00+00:00', '2016-12-01 00:00:00+00:00',\n '2016-11-01 00:00:00+00:00', '2016-10-01 00:00:00+00:00',\n '2016-09-01 00:00:00+00:00', '2016-08-01 00:00:00+00:00',\n '2016-07-01 00:00:00+00:00', '2016-06-01 00:00:00+00:00',\n '2016-05-01 00:00:00+00:00', '2016-04-01 00:00:00+00:00',\n '2016-03-01 00:00:00+00:00', '2016-02-01 00:00:00+00:00',\n '2016-01-01 00:00:00+00:00']\nLength: 93, dtype: datetime64[ns, UTC]spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :73.65000000000002 0.09999999999999998 0.0 53.55 0.0 -0.09999999999999999array(0)Indexes: (3)xPandasIndexPandasIndex(Index([ 73.70000000000002,  73.80000000000001,               73.9,\n                     74.0,  74.10000000000002,  74.20000000000002,\n        74.30000000000001,               74.4,               74.5,\n        74.60000000000002,\n       ...\n       134.10000000000002, 134.20000000000005,              134.3,\n       134.40000000000003,              134.5, 134.60000000000002,\n       134.70000000000005,              134.8, 134.90000000000003,\n                    135.0],\n      dtype='float64', name='x', length=614))yPandasIndexPandasIndex(Index([              53.5,               53.4,               53.3,\n       53.199999999999996,               53.1,               53.0,\n                     52.9,               52.8, 52.699999999999996,\n                     52.6,\n       ...\n       19.099999999999994,               19.0,  18.89999999999999,\n       18.799999999999997, 18.700000000000003, 18.599999999999994,\n                     18.5,  18.39999999999999, 18.299999999999997,\n       18.200000000000003],\n      dtype='float64', name='y', length=354))timePandasIndexPandasIndex(DatetimeIndex(['2023-09-01 00:00:00+00:00', '2023-08-01 00:00:00+00:00',\n               '2023-07-01 00:00:00+00:00', '2023-06-01 00:00:00+00:00',\n               '2023-05-01 00:00:00+00:00', '2023-04-01 00:00:00+00:00',\n               '2023-03-01 00:00:00+00:00', '2023-02-01 00:00:00+00:00',\n               '2023-01-01 00:00:00+00:00', '2022-12-01 00:00:00+00:00',\n               '2022-11-01 00:00:00+00:00', '2022-10-01 00:00:00+00:00',\n               '2022-09-01 00:00:00+00:00', '2022-08-01 00:00:00+00:00',\n               '2022-07-01 00:00:00+00:00', '2022-06-01 00:00:00+00:00',\n               '2022-05-01 00:00:00+00:00', '2022-04-01 00:00:00+00:00',\n               '2022-03-01 00:00:00+00:00', '2022-02-01 00:00:00+00:00',\n               '2022-01-01 00:00:00+00:00', '2021-12-01 00:00:00+00:00',\n               '2021-11-01 00:00:00+00:00', '2021-10-01 00:00:00+00:00',\n               '2021-09-01 00:00:00+00:00', '2021-08-01 00:00:00+00:00',\n               '2021-07-01 00:00:00+00:00', '2021-06-01 00:00:00+00:00',\n               '2021-05-01 00:00:00+00:00', '2021-04-01 00:00:00+00:00',\n               '2021-03-01 00:00:00+00:00', '2021-02-01 00:00:00+00:00',\n               '2021-01-01 00:00:00+00:00', '2020-12-01 00:00:00+00:00',\n               '2020-11-01 00:00:00+00:00', '2020-10-01 00:00:00+00:00',\n               '2020-09-01 00:00:00+00:00', '2020-08-01 00:00:00+00:00',\n               '2020-07-01 00:00:00+00:00', '2020-06-01 00:00:00+00:00',\n               '2020-05-01 00:00:00+00:00', '2020-04-01 00:00:00+00:00',\n               '2020-03-01 00:00:00+00:00', '2020-02-01 00:00:00+00:00',\n               '2020-01-01 00:00:00+00:00', '2019-12-01 00:00:00+00:00',\n               '2019-11-01 00:00:00+00:00', '2019-10-01 00:00:00+00:00',\n               '2019-09-01 00:00:00+00:00', '2019-08-01 00:00:00+00:00',\n               '2019-07-01 00:00:00+00:00', '2019-06-01 00:00:00+00:00',\n               '2019-05-01 00:00:00+00:00', '2019-04-01 00:00:00+00:00',\n               '2019-03-01 00:00:00+00:00', '2019-02-01 00:00:00+00:00',\n               '2019-01-01 00:00:00+00:00', '2018-12-01 00:00:00+00:00',\n               '2018-11-01 00:00:00+00:00', '2018-10-01 00:00:00+00:00',\n               '2018-09-01 00:00:00+00:00', '2018-08-01 00:00:00+00:00',\n               '2018-07-01 00:00:00+00:00', '2018-06-01 00:00:00+00:00',\n               '2018-05-01 00:00:00+00:00', '2018-04-01 00:00:00+00:00',\n               '2018-03-01 00:00:00+00:00', '2018-02-01 00:00:00+00:00',\n               '2018-01-01 00:00:00+00:00', '2017-12-01 00:00:00+00:00',\n               '2017-11-01 00:00:00+00:00', '2017-10-01 00:00:00+00:00',\n               '2017-09-01 00:00:00+00:00', '2017-08-01 00:00:00+00:00',\n               '2017-07-01 00:00:00+00:00', '2017-06-01 00:00:00+00:00',\n               '2017-05-01 00:00:00+00:00', '2017-04-01 00:00:00+00:00',\n               '2017-03-01 00:00:00+00:00', '2017-02-01 00:00:00+00:00',\n               '2017-01-01 00:00:00+00:00', '2016-12-01 00:00:00+00:00',\n               '2016-11-01 00:00:00+00:00', '2016-10-01 00:00:00+00:00',\n               '2016-09-01 00:00:00+00:00', '2016-08-01 00:00:00+00:00',\n               '2016-07-01 00:00:00+00:00', '2016-06-01 00:00:00+00:00',\n               '2016-05-01 00:00:00+00:00', '2016-04-01 00:00:00+00:00',\n               '2016-03-01 00:00:00+00:00', '2016-02-01 00:00:00+00:00',\n               '2016-01-01 00:00:00+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None))Attributes: (2)spec :RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), resolutions_xy=(0.1, 0.1))resolution :0.1"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#aggregate-the-data",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#aggregate-the-data",
    "title": "Calculate timeseries from COGs",
    "section": "Aggregate the data",
    "text": "Aggregate the data\nCalculate the mean at each time across regional data. Note this is the first time that the data is actually loaded.\n\nmeans = subset.mean(dim=(\"x\", \"y\")).compute()\n\nPlot the mean monthly NO2 using hvplot\n\nmeans.hvplot.line(x=\"time\", ylabel=\"NO2\", title=\"Mean Monthly NO2 in China\")"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html",
    "title": "Open and visualize COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#run-this-notebook",
    "title": "Open and visualize COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#approach",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#approach",
    "title": "Open and visualize COGs",
    "section": "Approach",
    "text": "Approach\n\nUse pystac_client to open the STAC catalog and retrieve the items in the collection\nUse stackstac to create an xarray dataset containing all the items\nUse rioxarray to crop data to AOI\nUse hvplot to render the COG at every timestep\n\n\nimport requests\nfrom pystac_client import Client\nimport pandas as pd\nimport stackstac\n\nimport rioxarray  # noqa\nimport hvplot.xarray  # noqa"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#declare-your-collection-of-interest",
    "title": "Open and visualize COGs",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac\"\ncollection_id = \"no2-monthly\""
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#discover-items-in-collection-for-region-and-time-of-interest",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#discover-items-in-collection-for-region-and-time-of-interest",
    "title": "Open and visualize COGs",
    "section": "Discover items in collection for region and time of interest",
    "text": "Discover items in collection for region and time of interest\nUse pystac_client to search the STAC collection for a particular area of interest within specified datetime bounds.\n\ncatalog = Client.open(STAC_API_URL)\nsearch = catalog.search(collections=[collection_id], sortby=\"start_datetime\")\n\nitem_collection = search.item_collection()\nprint(f\"Found {len(item_collection)} items\")\n\nFound 93 items"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#define-an-aoi",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#define-an-aoi",
    "title": "Open and visualize COGs",
    "section": "Define an AOI",
    "text": "Define an AOI\nWe can fetch GeoJSON for metropolitan France and Corsica (excluding overseas territories) from an authoritative online source (https://gadm.org/download_country.html).\n\nresponse = requests.get(\n    \"https://geodata.ucdavis.edu/gadm/gadm4.1/json/gadm41_FRA_0.json\"\n)\n\n# If anything goes wrong with this request output error contents\nassert response.ok, response.text\n\nresult = response.json()\nprint(f\"There are {len(result['features'])} features in this collection\")\n\nThere are 1 features in this collection\n\n\nThat is the geojson for a feature collection, but since there is only one feature in it we can grab just that.\n\nfrance_aoi = result[\"features\"][0]"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#read-data",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#read-data",
    "title": "Open and visualize COGs",
    "section": "Read data",
    "text": "Read data\nCreate an xarray.DataArray using stackstac\n\nda = stackstac.stack(item_collection, epsg=4326)\nda = da.assign_coords({\"time\": da.start_datetime}).squeeze()\nda\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'stackstac-732215043b0b95a370dc66f3493b95b0' (time: 93,\n                                                                y: 1800, x: 3600)&gt; Size: 5GB\ndask.array&lt;getitem, shape=(93, 1800, 3600), dtype=float64, chunksize=(1, 1024, 1024), chunktype=numpy.ndarray&gt;\nCoordinates: (12/17)\n    id              (time) &lt;U37 14kB 'OMI_trno2_0.10x0.10_201601_Col3_V4.nc' ...\n    band            &lt;U11 44B 'cog_default'\n  * x               (x) float64 29kB -180.0 -179.9 -179.8 ... 179.7 179.8 179.9\n  * y               (y) float64 14kB 90.0 89.9 89.8 89.7 ... -89.7 -89.8 -89.9\n    end_datetime    (time) &lt;U25 9kB '2016-01-31T00:00:00+00:00' ... '2023-09-...\n    start_datetime  (time) &lt;U25 9kB '2016-01-01T00:00:00+00:00' ... '2023-09-...\n    ...              ...\n    proj:geometry   object 8B {'type': 'Polygon', 'coordinates': [[[-180.0, -...\n    proj:code       &lt;U9 36B 'EPSG:4326'\n    proj:transform  object 8B {0.1, 0.0, 1.0, -0.1, -180.0, 90.0}\n    title           &lt;U17 68B 'Default COG Layer'\n    epsg            int64 8B 4326\n  * time            (time) &lt;U25 9kB '2016-01-01T00:00:00+00:00' ... '2023-09-...\nAttributes:\n    spec:        RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), r...\n    crs:         epsg:4326\n    transform:   | 0.10, 0.00,-180.00|\\n| 0.00,-0.10, 90.00|\\n| 0.00, 0.00, 1...\n    resolution:  0.1xarray.DataArray'stackstac-732215043b0b95a370dc66f3493b95b0'time: 93y: 1800x: 3600dask.array&lt;chunksize=(1, 1024, 1024), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n4.49 GiB\n8.00 MiB\n\n\nShape\n(93, 1800, 3600)\n(1, 1024, 1024)\n\n\nDask graph\n744 chunks in 4 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (17)id(time)&lt;U37'OMI_trno2_0.10x0.10_201601_Col3...array(['OMI_trno2_0.10x0.10_201601_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201602_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201603_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201604_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201605_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201606_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201607_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201608_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201609_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201610_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201611_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201612_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201701_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201702_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201703_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201704_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201705_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201706_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201707_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201708_Col3_V4.nc',\n...\n       'OMI_trno2_0.10x0.10_202202_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202203_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202204_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202205_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202206_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202207_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202208_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202209_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202210_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202211_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202212_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202301_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202302_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202303_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202304_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202305_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202306_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202307_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202308_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202309_Col3_V4.nc'], dtype='&lt;U37')band()&lt;U11'cog_default'array('cog_default', dtype='&lt;U11')x(x)float64-180.0 -179.9 ... 179.8 179.9array([-180. , -179.9, -179.8, ...,  179.7,  179.8,  179.9], shape=(3600,))y(y)float6490.0 89.9 89.8 ... -89.8 -89.9array([ 90. ,  89.9,  89.8, ..., -89.7, -89.8, -89.9], shape=(1800,))end_datetime(time)&lt;U25'2016-01-31T00:00:00+00:00' ... ...array(['2016-01-31T00:00:00+00:00', '2016-02-29T00:00:00+00:00',\n       '2016-03-31T00:00:00+00:00', '2016-04-30T00:00:00+00:00',\n       '2016-05-31T00:00:00+00:00', '2016-06-30T00:00:00+00:00',\n       '2016-07-31T00:00:00+00:00', '2016-08-31T00:00:00+00:00',\n       '2016-09-30T00:00:00+00:00', '2016-10-31T00:00:00+00:00',\n       '2016-11-30T00:00:00+00:00', '2016-12-31T00:00:00+00:00',\n       '2017-01-31T00:00:00+00:00', '2017-02-28T00:00:00+00:00',\n       '2017-03-31T00:00:00+00:00', '2017-04-30T00:00:00+00:00',\n       '2017-05-31T00:00:00+00:00', '2017-06-30T00:00:00+00:00',\n       '2017-07-31T00:00:00+00:00', '2017-08-31T00:00:00+00:00',\n       '2017-09-30T00:00:00+00:00', '2017-10-31T00:00:00+00:00',\n       '2017-11-30T00:00:00+00:00', '2017-12-31T00:00:00+00:00',\n       '2018-01-31T00:00:00+00:00', '2018-02-28T00:00:00+00:00',\n       '2018-03-31T00:00:00+00:00', '2018-04-30T00:00:00+00:00',\n       '2018-05-31T00:00:00+00:00', '2018-06-30T00:00:00+00:00',\n       '2018-07-31T00:00:00+00:00', '2018-08-31T00:00:00+00:00',\n       '2018-09-30T00:00:00+00:00', '2018-10-31T00:00:00+00:00',\n       '2018-11-30T00:00:00+00:00', '2018-12-31T00:00:00+00:00',\n       '2019-01-31T00:00:00+00:00', '2019-02-28T00:00:00+00:00',\n       '2019-03-31T00:00:00+00:00', '2019-04-30T00:00:00+00:00',\n...\n       '2020-07-31T00:00:00+00:00', '2020-08-31T00:00:00+00:00',\n       '2020-09-30T00:00:00+00:00', '2020-10-31T00:00:00+00:00',\n       '2020-11-30T00:00:00+00:00', '2020-12-31T00:00:00+00:00',\n       '2021-01-31T00:00:00+00:00', '2021-02-28T00:00:00+00:00',\n       '2021-03-31T00:00:00+00:00', '2021-04-30T00:00:00+00:00',\n       '2021-05-31T00:00:00+00:00', '2021-06-30T00:00:00+00:00',\n       '2021-07-31T00:00:00+00:00', '2021-08-31T00:00:00+00:00',\n       '2021-09-30T00:00:00+00:00', '2021-10-31T00:00:00+00:00',\n       '2021-11-30T00:00:00+00:00', '2021-12-31T00:00:00+00:00',\n       '2022-01-31T00:00:00+00:00', '2022-02-28T00:00:00+00:00',\n       '2022-03-31T00:00:00+00:00', '2022-04-30T00:00:00+00:00',\n       '2022-05-31T00:00:00+00:00', '2022-06-30T00:00:00+00:00',\n       '2022-07-31T00:00:00+00:00', '2022-08-31T00:00:00+00:00',\n       '2022-09-30T00:00:00+00:00', '2022-10-31T00:00:00+00:00',\n       '2022-11-30T00:00:00+00:00', '2022-12-31T00:00:00+00:00',\n       '2023-01-31T00:00:00+00:00', '2023-02-28T00:00:00+00:00',\n       '2023-03-31T00:00:00+00:00', '2023-04-30T00:00:00+00:00',\n       '2023-05-31T00:00:00+00:00', '2023-06-30T00:00:00+00:00',\n       '2023-07-31T00:00:00+00:00', '2023-08-31T00:00:00+00:00',\n       '2023-09-30T00:00:00+00:00'], dtype='&lt;U25')start_datetime(time)&lt;U25'2016-01-01T00:00:00+00:00' ... ...array(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n...\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'], dtype='&lt;U25')proj:bbox()object{90.0, 180.0, -90.0, -180.0}array({90.0, 180.0, -90.0, -180.0}, dtype=object)proj:shape()object{1800, 3600}array({1800, 3600}, dtype=object)proj:projjson()object{'id': {'code': 4326, 'authority...array({'id': {'code': 4326, 'authority': 'EPSG'}, 'name': 'WGS 84', 'type': 'GeographicCRS', 'datum': {'name': 'World Geodetic System 1984', 'type': 'GeodeticReferenceFrame', 'ellipsoid': {'name': 'WGS 84', 'semi_major_axis': 6378137, 'inverse_flattening': 298.257223563}}, '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json', 'coordinate_system': {'axis': [{'name': 'Geodetic latitude', 'unit': 'degree', 'direction': 'north', 'abbreviation': 'Lat'}, {'name': 'Geodetic longitude', 'unit': 'degree', 'direction': 'east', 'abbreviation': 'Lon'}], 'subtype': 'ellipsoidal'}},\n      dtype=object)proj:wkt2()&lt;U277'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984...array('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n      dtype='&lt;U277')description()&lt;U47'Cloud optimized default layer t...array('Cloud optimized default layer to display on map', dtype='&lt;U47')proj:geometry()object{'type': 'Polygon', 'coordinates...array({'type': 'Polygon', 'coordinates': [[[-180.0, -90.0], [180.0, -90.0], [180.0, 90.0], [-180.0, 90.0], [-180.0, -90.0]]]},\n      dtype=object)proj:code()&lt;U9'EPSG:4326'array('EPSG:4326', dtype='&lt;U9')proj:transform()object{0.1, 0.0, 1.0, -0.1, -180.0, 90.0}array({0.1, 0.0, 1.0, -0.1, -180.0, 90.0}, dtype=object)title()&lt;U17'Default COG Layer'array('Default COG Layer', dtype='&lt;U17')epsg()int644326array(4326)time(time)&lt;U25'2016-01-01T00:00:00+00:00' ... ...array(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n       '2019-05-01T00:00:00+00:00', '2019-06-01T00:00:00+00:00',\n       '2019-07-01T00:00:00+00:00', '2019-08-01T00:00:00+00:00',\n       '2019-09-01T00:00:00+00:00', '2019-10-01T00:00:00+00:00',\n       '2019-11-01T00:00:00+00:00', '2019-12-01T00:00:00+00:00',\n       '2020-01-01T00:00:00+00:00', '2020-02-01T00:00:00+00:00',\n       '2020-03-01T00:00:00+00:00', '2020-04-01T00:00:00+00:00',\n       '2020-05-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'], dtype='&lt;U25')Indexes: (3)xPandasIndexPandasIndex(Index([            -180.0,             -179.9,             -179.8,\n                   -179.7,             -179.6,             -179.5,\n                   -179.4,             -179.3,             -179.2,\n                   -179.1,\n       ...\n                    179.0, 179.10000000000002, 179.20000000000005,\n                    179.3, 179.40000000000003,              179.5,\n       179.60000000000002, 179.70000000000005,              179.8,\n       179.90000000000003],\n      dtype='float64', name='x', length=3600))yPandasIndexPandasIndex(Index([              90.0,               89.9,               89.8,\n                     89.7,               89.6,               89.5,\n                     89.4,               89.3,               89.2,\n                     89.1,\n       ...\n                    -89.0, -89.10000000000002, -89.20000000000002,\n       -89.30000000000001,              -89.4,              -89.5,\n       -89.60000000000002, -89.70000000000002, -89.80000000000001,\n                    -89.9],\n      dtype='float64', name='y', length=1800))timePandasIndexPandasIndex(Index(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n       '2019-05-01T00:00:00+00:00', '2019-06-01T00:00:00+00:00',\n       '2019-07-01T00:00:00+00:00', '2019-08-01T00:00:00+00:00',\n       '2019-09-01T00:00:00+00:00', '2019-10-01T00:00:00+00:00',\n       '2019-11-01T00:00:00+00:00', '2019-12-01T00:00:00+00:00',\n       '2020-01-01T00:00:00+00:00', '2020-02-01T00:00:00+00:00',\n       '2020-03-01T00:00:00+00:00', '2020-04-01T00:00:00+00:00',\n       '2020-05-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'],\n      dtype='object', name='time'))Attributes: (4)spec :RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), resolutions_xy=(0.1, 0.1))crs :epsg:4326transform :| 0.10, 0.00,-180.00|\n| 0.00,-0.10, 90.00|\n| 0.00, 0.00, 1.00|resolution :0.1"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#clip-the-data-to-aoi",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#clip-the-data-to-aoi",
    "title": "Open and visualize COGs",
    "section": "Clip the data to AOI",
    "text": "Clip the data to AOI\n\nsubset = da.rio.clip([france_aoi[\"geometry\"]])\nsubset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'stackstac-732215043b0b95a370dc66f3493b95b0' (time: 93,\n                                                                y: 97, x: 143)&gt; Size: 10MB\ndask.array&lt;getitem, shape=(93, 97, 143), dtype=float64, chunksize=(1, 97, 143), chunktype=numpy.ndarray&gt;\nCoordinates: (12/18)\n    id              (time) &lt;U37 14kB 'OMI_trno2_0.10x0.10_201601_Col3_V4.nc' ...\n    band            &lt;U11 44B 'cog_default'\n  * x               (x) float64 1kB -4.7 -4.6 -4.5 -4.4 -4.3 ... 9.2 9.3 9.4 9.5\n  * y               (y) float64 776B 51.0 50.9 50.8 50.7 ... 41.7 41.6 41.5 41.4\n    end_datetime    (time) &lt;U25 9kB '2016-01-31T00:00:00+00:00' ... '2023-09-...\n    start_datetime  (time) &lt;U25 9kB '2016-01-01T00:00:00+00:00' ... '2023-09-...\n    ...              ...\n    proj:code       &lt;U9 36B 'EPSG:4326'\n    proj:transform  object 8B {0.1, 0.0, 1.0, -0.1, -180.0, 90.0}\n    title           &lt;U17 68B 'Default COG Layer'\n    epsg            int64 8B 4326\n  * time            (time) &lt;U25 9kB '2016-01-01T00:00:00+00:00' ... '2023-09-...\n    spatial_ref     int64 8B 0\nAttributes:\n    spec:        RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), r...\n    resolution:  0.1xarray.DataArray'stackstac-732215043b0b95a370dc66f3493b95b0'time: 93y: 97x: 143dask.array&lt;chunksize=(1, 97, 143), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n9.84 MiB\n108.37 kiB\n\n\nShape\n(93, 97, 143)\n(1, 97, 143)\n\n\nDask graph\n93 chunks in 8 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (18)id(time)&lt;U37'OMI_trno2_0.10x0.10_201601_Col3...array(['OMI_trno2_0.10x0.10_201601_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201602_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201603_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201604_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201605_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201606_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201607_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201608_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201609_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201610_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201611_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201612_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201701_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201702_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201703_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201704_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201705_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201706_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201707_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201708_Col3_V4.nc',\n...\n       'OMI_trno2_0.10x0.10_202202_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202203_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202204_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202205_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202206_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202207_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202208_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202209_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202210_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202211_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202212_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202301_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202302_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202303_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202304_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202305_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202306_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202307_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202308_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202309_Col3_V4.nc'], dtype='&lt;U37')band()&lt;U11'cog_default'array('cog_default', dtype='&lt;U11')x(x)float64-4.7 -4.6 -4.5 -4.4 ... 9.3 9.4 9.5axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([-4.7, -4.6, -4.5, -4.4, -4.3, -4.2, -4.1, -4. , -3.9, -3.8, -3.7, -3.6,\n       -3.5, -3.4, -3.3, -3.2, -3.1, -3. , -2.9, -2.8, -2.7, -2.6, -2.5, -2.4,\n       -2.3, -2.2, -2.1, -2. , -1.9, -1.8, -1.7, -1.6, -1.5, -1.4, -1.3, -1.2,\n       -1.1, -1. , -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1,  0. ,\n        0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ,  1.1,  1.2,\n        1.3,  1.4,  1.5,  1.6,  1.7,  1.8,  1.9,  2. ,  2.1,  2.2,  2.3,  2.4,\n        2.5,  2.6,  2.7,  2.8,  2.9,  3. ,  3.1,  3.2,  3.3,  3.4,  3.5,  3.6,\n        3.7,  3.8,  3.9,  4. ,  4.1,  4.2,  4.3,  4.4,  4.5,  4.6,  4.7,  4.8,\n        4.9,  5. ,  5.1,  5.2,  5.3,  5.4,  5.5,  5.6,  5.7,  5.8,  5.9,  6. ,\n        6.1,  6.2,  6.3,  6.4,  6.5,  6.6,  6.7,  6.8,  6.9,  7. ,  7.1,  7.2,\n        7.3,  7.4,  7.5,  7.6,  7.7,  7.8,  7.9,  8. ,  8.1,  8.2,  8.3,  8.4,\n        8.5,  8.6,  8.7,  8.8,  8.9,  9. ,  9.1,  9.2,  9.3,  9.4,  9.5])y(y)float6451.0 50.9 50.8 ... 41.6 41.5 41.4axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([51. , 50.9, 50.8, 50.7, 50.6, 50.5, 50.4, 50.3, 50.2, 50.1, 50. , 49.9,\n       49.8, 49.7, 49.6, 49.5, 49.4, 49.3, 49.2, 49.1, 49. , 48.9, 48.8, 48.7,\n       48.6, 48.5, 48.4, 48.3, 48.2, 48.1, 48. , 47.9, 47.8, 47.7, 47.6, 47.5,\n       47.4, 47.3, 47.2, 47.1, 47. , 46.9, 46.8, 46.7, 46.6, 46.5, 46.4, 46.3,\n       46.2, 46.1, 46. , 45.9, 45.8, 45.7, 45.6, 45.5, 45.4, 45.3, 45.2, 45.1,\n       45. , 44.9, 44.8, 44.7, 44.6, 44.5, 44.4, 44.3, 44.2, 44.1, 44. , 43.9,\n       43.8, 43.7, 43.6, 43.5, 43.4, 43.3, 43.2, 43.1, 43. , 42.9, 42.8, 42.7,\n       42.6, 42.5, 42.4, 42.3, 42.2, 42.1, 42. , 41.9, 41.8, 41.7, 41.6, 41.5,\n       41.4])end_datetime(time)&lt;U25'2016-01-31T00:00:00+00:00' ... ...array(['2016-01-31T00:00:00+00:00', '2016-02-29T00:00:00+00:00',\n       '2016-03-31T00:00:00+00:00', '2016-04-30T00:00:00+00:00',\n       '2016-05-31T00:00:00+00:00', '2016-06-30T00:00:00+00:00',\n       '2016-07-31T00:00:00+00:00', '2016-08-31T00:00:00+00:00',\n       '2016-09-30T00:00:00+00:00', '2016-10-31T00:00:00+00:00',\n       '2016-11-30T00:00:00+00:00', '2016-12-31T00:00:00+00:00',\n       '2017-01-31T00:00:00+00:00', '2017-02-28T00:00:00+00:00',\n       '2017-03-31T00:00:00+00:00', '2017-04-30T00:00:00+00:00',\n       '2017-05-31T00:00:00+00:00', '2017-06-30T00:00:00+00:00',\n       '2017-07-31T00:00:00+00:00', '2017-08-31T00:00:00+00:00',\n       '2017-09-30T00:00:00+00:00', '2017-10-31T00:00:00+00:00',\n       '2017-11-30T00:00:00+00:00', '2017-12-31T00:00:00+00:00',\n       '2018-01-31T00:00:00+00:00', '2018-02-28T00:00:00+00:00',\n       '2018-03-31T00:00:00+00:00', '2018-04-30T00:00:00+00:00',\n       '2018-05-31T00:00:00+00:00', '2018-06-30T00:00:00+00:00',\n       '2018-07-31T00:00:00+00:00', '2018-08-31T00:00:00+00:00',\n       '2018-09-30T00:00:00+00:00', '2018-10-31T00:00:00+00:00',\n       '2018-11-30T00:00:00+00:00', '2018-12-31T00:00:00+00:00',\n       '2019-01-31T00:00:00+00:00', '2019-02-28T00:00:00+00:00',\n       '2019-03-31T00:00:00+00:00', '2019-04-30T00:00:00+00:00',\n...\n       '2020-07-31T00:00:00+00:00', '2020-08-31T00:00:00+00:00',\n       '2020-09-30T00:00:00+00:00', '2020-10-31T00:00:00+00:00',\n       '2020-11-30T00:00:00+00:00', '2020-12-31T00:00:00+00:00',\n       '2021-01-31T00:00:00+00:00', '2021-02-28T00:00:00+00:00',\n       '2021-03-31T00:00:00+00:00', '2021-04-30T00:00:00+00:00',\n       '2021-05-31T00:00:00+00:00', '2021-06-30T00:00:00+00:00',\n       '2021-07-31T00:00:00+00:00', '2021-08-31T00:00:00+00:00',\n       '2021-09-30T00:00:00+00:00', '2021-10-31T00:00:00+00:00',\n       '2021-11-30T00:00:00+00:00', '2021-12-31T00:00:00+00:00',\n       '2022-01-31T00:00:00+00:00', '2022-02-28T00:00:00+00:00',\n       '2022-03-31T00:00:00+00:00', '2022-04-30T00:00:00+00:00',\n       '2022-05-31T00:00:00+00:00', '2022-06-30T00:00:00+00:00',\n       '2022-07-31T00:00:00+00:00', '2022-08-31T00:00:00+00:00',\n       '2022-09-30T00:00:00+00:00', '2022-10-31T00:00:00+00:00',\n       '2022-11-30T00:00:00+00:00', '2022-12-31T00:00:00+00:00',\n       '2023-01-31T00:00:00+00:00', '2023-02-28T00:00:00+00:00',\n       '2023-03-31T00:00:00+00:00', '2023-04-30T00:00:00+00:00',\n       '2023-05-31T00:00:00+00:00', '2023-06-30T00:00:00+00:00',\n       '2023-07-31T00:00:00+00:00', '2023-08-31T00:00:00+00:00',\n       '2023-09-30T00:00:00+00:00'], dtype='&lt;U25')start_datetime(time)&lt;U25'2016-01-01T00:00:00+00:00' ... ...array(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n...\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'], dtype='&lt;U25')proj:bbox()object{90.0, 180.0, -90.0, -180.0}array({90.0, 180.0, -90.0, -180.0}, dtype=object)proj:shape()object{1800, 3600}array({1800, 3600}, dtype=object)proj:projjson()object{'id': {'code': 4326, 'authority...array({'id': {'code': 4326, 'authority': 'EPSG'}, 'name': 'WGS 84', 'type': 'GeographicCRS', 'datum': {'name': 'World Geodetic System 1984', 'type': 'GeodeticReferenceFrame', 'ellipsoid': {'name': 'WGS 84', 'semi_major_axis': 6378137, 'inverse_flattening': 298.257223563}}, '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json', 'coordinate_system': {'axis': [{'name': 'Geodetic latitude', 'unit': 'degree', 'direction': 'north', 'abbreviation': 'Lat'}, {'name': 'Geodetic longitude', 'unit': 'degree', 'direction': 'east', 'abbreviation': 'Lon'}], 'subtype': 'ellipsoidal'}},\n      dtype=object)proj:wkt2()&lt;U277'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984...array('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n      dtype='&lt;U277')description()&lt;U47'Cloud optimized default layer t...array('Cloud optimized default layer to display on map', dtype='&lt;U47')proj:geometry()object{'type': 'Polygon', 'coordinates...array({'type': 'Polygon', 'coordinates': [[[-180.0, -90.0], [180.0, -90.0], [180.0, 90.0], [-180.0, 90.0], [-180.0, -90.0]]]},\n      dtype=object)proj:code()&lt;U9'EPSG:4326'array('EPSG:4326', dtype='&lt;U9')proj:transform()object{0.1, 0.0, 1.0, -0.1, -180.0, 90.0}array({0.1, 0.0, 1.0, -0.1, -180.0, 90.0}, dtype=object)title()&lt;U17'Default COG Layer'array('Default COG Layer', dtype='&lt;U17')epsg()int644326array(4326)time(time)&lt;U25'2016-01-01T00:00:00+00:00' ... ...array(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n       '2019-05-01T00:00:00+00:00', '2019-06-01T00:00:00+00:00',\n       '2019-07-01T00:00:00+00:00', '2019-08-01T00:00:00+00:00',\n       '2019-09-01T00:00:00+00:00', '2019-10-01T00:00:00+00:00',\n       '2019-11-01T00:00:00+00:00', '2019-12-01T00:00:00+00:00',\n       '2020-01-01T00:00:00+00:00', '2020-02-01T00:00:00+00:00',\n       '2020-03-01T00:00:00+00:00', '2020-04-01T00:00:00+00:00',\n       '2020-05-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'], dtype='&lt;U25')spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-4.7499999999999885 0.09999999999999992 0.0 51.05 0.0 -0.10000000000000002array(0)Indexes: (3)xPandasIndexPandasIndex(Index([ -4.699999999999989,  -4.599999999999994,                -4.5,\n        -4.399999999999977,  -4.299999999999983,  -4.199999999999989,\n        -4.099999999999994,                -4.0, -3.8999999999999773,\n        -3.799999999999983,\n       ...\n         8.600000000000023,   8.700000000000017,   8.800000000000011,\n         8.900000000000006,                 9.0,   9.100000000000023,\n         9.200000000000017,   9.300000000000011,   9.400000000000006,\n                       9.5],\n      dtype='float64', name='x', length=143))yPandasIndexPandasIndex(Index([              51.0,               50.9,               50.8,\n       50.699999999999996, 50.599999999999994,               50.5,\n                     50.4,               50.3, 50.199999999999996,\n       50.099999999999994,               50.0,               49.9,\n                     49.8, 49.699999999999996, 49.599999999999994,\n                     49.5,               49.4,               49.3,\n       49.199999999999996, 49.099999999999994,               49.0,\n                     48.9,               48.8, 48.699999999999996,\n       48.599999999999994,               48.5,               48.4,\n                     48.3, 48.199999999999996, 48.099999999999994,\n                     48.0,               47.9,               47.8,\n       47.699999999999996, 47.599999999999994,               47.5,\n                     47.4,               47.3, 47.199999999999996,\n       47.099999999999994,               47.0,               46.9,\n                     46.8, 46.699999999999996, 46.599999999999994,\n                     46.5,               46.4,               46.3,\n       46.199999999999996, 46.099999999999994,               46.0,\n                     45.9,               45.8, 45.699999999999996,\n       45.599999999999994,               45.5,               45.4,\n                     45.3, 45.199999999999996, 45.099999999999994,\n                     45.0,               44.9,               44.8,\n       44.699999999999996, 44.599999999999994,               44.5,\n                     44.4,               44.3, 44.199999999999996,\n       44.099999999999994,               44.0,               43.9,\n                     43.8, 43.699999999999996, 43.599999999999994,\n                     43.5,               43.4,               43.3,\n       43.199999999999996, 43.099999999999994,               43.0,\n                     42.9,               42.8, 42.699999999999996,\n       42.599999999999994,               42.5,               42.4,\n                     42.3, 42.199999999999996, 42.099999999999994,\n                     42.0,               41.9,               41.8,\n       41.699999999999996, 41.599999999999994,               41.5,\n                     41.4],\n      dtype='float64', name='y'))timePandasIndexPandasIndex(Index(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n       '2019-05-01T00:00:00+00:00', '2019-06-01T00:00:00+00:00',\n       '2019-07-01T00:00:00+00:00', '2019-08-01T00:00:00+00:00',\n       '2019-09-01T00:00:00+00:00', '2019-10-01T00:00:00+00:00',\n       '2019-11-01T00:00:00+00:00', '2019-12-01T00:00:00+00:00',\n       '2020-01-01T00:00:00+00:00', '2020-02-01T00:00:00+00:00',\n       '2020-03-01T00:00:00+00:00', '2020-04-01T00:00:00+00:00',\n       '2020-05-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'],\n      dtype='object', name='time'))Attributes: (2)spec :RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), resolutions_xy=(0.1, 0.1))resolution :0.1"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#compute-and-plot",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#compute-and-plot",
    "title": "Open and visualize COGs",
    "section": "Compute and plot",
    "text": "Compute and plot\nSo far we have just been setting up a calculation lazily in Dask. Now we can trigger computation using .compute().\n\n%%time\n\nimage_stack = subset.compute()\n\nCPU times: user 3.02 s, sys: 440 ms, total: 3.46 s\nWall time: 6.63 s\n\n\n\n# get the 2% and 98% percentiles for min and max bounds of color\nvmin, vmax = image_stack.quantile(0.02).item(), image_stack.quantile(0.98).item()\n\nimage_stack.hvplot.quadmesh(\n    groupby=\"time\",\n    tiles=True,\n    colorbar=False,\n    clim=(vmin, vmax),\n    cmap=\"viridis\",\n    alpha=0.8,\n    frame_height=512,\n    widget_location=\"bottom\",\n    aspect=1,\n)"
  }
]
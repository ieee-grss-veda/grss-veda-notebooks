[
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html",
    "title": "Open and visualize COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#run-this-notebook",
    "title": "Open and visualize COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#approach",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#approach",
    "title": "Open and visualize COGs",
    "section": "Approach",
    "text": "Approach\n\nUse pystac_client to open the STAC catalog and retrieve the items in the collection\nUse stackstac to create an xarray dataset containing all the items\nUse rioxarray to crop data to AOI\nUse hvplot to render the COG at every timestep\n\n\nimport requests\nfrom pystac_client import Client\nimport pandas as pd\nimport stackstac\n\nimport rioxarray  # noqa\nimport hvplot.xarray  # noqa"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#declare-your-collection-of-interest",
    "title": "Open and visualize COGs",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac\"\ncollection_id = \"no2-monthly\""
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#discover-items-in-collection-for-region-and-time-of-interest",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#discover-items-in-collection-for-region-and-time-of-interest",
    "title": "Open and visualize COGs",
    "section": "Discover items in collection for region and time of interest",
    "text": "Discover items in collection for region and time of interest\nUse pystac_client to search the STAC collection for a particular area of interest within specified datetime bounds.\n\ncatalog = Client.open(STAC_API_URL)\nsearch = catalog.search(collections=[collection_id], sortby=\"start_datetime\")\n\nitem_collection = search.item_collection()\nprint(f\"Found {len(item_collection)} items\")\n\nFound 93 items"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#define-an-aoi",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#define-an-aoi",
    "title": "Open and visualize COGs",
    "section": "Define an AOI",
    "text": "Define an AOI\nWe can fetch GeoJSON for metropolitan France and Corsica (excluding overseas territories) from an authoritative online source (https://gadm.org/download_country.html).\n\nresponse = requests.get(\n    \"https://geodata.ucdavis.edu/gadm/gadm4.1/json/gadm41_FRA_0.json\"\n)\n\n# If anything goes wrong with this request output error contents\nassert response.ok, response.text\n\nresult = response.json()\nprint(f\"There are {len(result['features'])} features in this collection\")\n\nThere are 1 features in this collection\n\n\nThat is the geojson for a feature collection, but since there is only one feature in it we can grab just that.\n\nfrance_aoi = result[\"features\"][0]"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#read-data",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#read-data",
    "title": "Open and visualize COGs",
    "section": "Read data",
    "text": "Read data\nCreate an xarray.DataArray using stackstac\n\nda = stackstac.stack(item_collection, epsg=4326)\nda = da.assign_coords({\"time\": da.start_datetime}).squeeze()\nda\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'stackstac-732215043b0b95a370dc66f3493b95b0' (time: 93,\n                                                                y: 1800, x: 3600)&gt; Size: 5GB\ndask.array&lt;getitem, shape=(93, 1800, 3600), dtype=float64, chunksize=(1, 1024, 1024), chunktype=numpy.ndarray&gt;\nCoordinates: (12/17)\n    id              (time) &lt;U37 14kB 'OMI_trno2_0.10x0.10_201601_Col3_V4.nc' ...\n    band            &lt;U11 44B 'cog_default'\n  * x               (x) float64 29kB -180.0 -179.9 -179.8 ... 179.7 179.8 179.9\n  * y               (y) float64 14kB 90.0 89.9 89.8 89.7 ... -89.7 -89.8 -89.9\n    end_datetime    (time) &lt;U25 9kB '2016-01-31T00:00:00+00:00' ... '2023-09-...\n    start_datetime  (time) &lt;U25 9kB '2016-01-01T00:00:00+00:00' ... '2023-09-...\n    ...              ...\n    proj:geometry   object 8B {'type': 'Polygon', 'coordinates': [[[-180.0, -...\n    proj:code       &lt;U9 36B 'EPSG:4326'\n    proj:transform  object 8B {0.1, 0.0, 1.0, -0.1, -180.0, 90.0}\n    title           &lt;U17 68B 'Default COG Layer'\n    epsg            int64 8B 4326\n  * time            (time) &lt;U25 9kB '2016-01-01T00:00:00+00:00' ... '2023-09-...\nAttributes:\n    spec:        RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), r...\n    crs:         epsg:4326\n    transform:   | 0.10, 0.00,-180.00|\\n| 0.00,-0.10, 90.00|\\n| 0.00, 0.00, 1...\n    resolution:  0.1xarray.DataArray'stackstac-732215043b0b95a370dc66f3493b95b0'time: 93y: 1800x: 3600dask.array&lt;chunksize=(1, 1024, 1024), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n4.49 GiB\n8.00 MiB\n\n\nShape\n(93, 1800, 3600)\n(1, 1024, 1024)\n\n\nDask graph\n744 chunks in 4 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                                     3600 1800 93\n\n\n\n\nCoordinates: (17)id(time)&lt;U37'OMI_trno2_0.10x0.10_201601_Col3...array(['OMI_trno2_0.10x0.10_201601_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201602_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201603_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201604_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201605_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201606_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201607_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201608_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201609_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201610_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201611_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201612_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201701_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201702_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201703_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201704_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201705_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201706_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201707_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201708_Col3_V4.nc',\n...\n       'OMI_trno2_0.10x0.10_202202_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202203_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202204_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202205_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202206_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202207_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202208_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202209_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202210_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202211_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202212_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202301_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202302_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202303_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202304_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202305_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202306_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202307_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202308_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202309_Col3_V4.nc'], dtype='&lt;U37')band()&lt;U11'cog_default'array('cog_default', dtype='&lt;U11')x(x)float64-180.0 -179.9 ... 179.8 179.9array([-180. , -179.9, -179.8, ...,  179.7,  179.8,  179.9], shape=(3600,))y(y)float6490.0 89.9 89.8 ... -89.8 -89.9array([ 90. ,  89.9,  89.8, ..., -89.7, -89.8, -89.9], shape=(1800,))end_datetime(time)&lt;U25'2016-01-31T00:00:00+00:00' ... ...array(['2016-01-31T00:00:00+00:00', '2016-02-29T00:00:00+00:00',\n       '2016-03-31T00:00:00+00:00', '2016-04-30T00:00:00+00:00',\n       '2016-05-31T00:00:00+00:00', '2016-06-30T00:00:00+00:00',\n       '2016-07-31T00:00:00+00:00', '2016-08-31T00:00:00+00:00',\n       '2016-09-30T00:00:00+00:00', '2016-10-31T00:00:00+00:00',\n       '2016-11-30T00:00:00+00:00', '2016-12-31T00:00:00+00:00',\n       '2017-01-31T00:00:00+00:00', '2017-02-28T00:00:00+00:00',\n       '2017-03-31T00:00:00+00:00', '2017-04-30T00:00:00+00:00',\n       '2017-05-31T00:00:00+00:00', '2017-06-30T00:00:00+00:00',\n       '2017-07-31T00:00:00+00:00', '2017-08-31T00:00:00+00:00',\n       '2017-09-30T00:00:00+00:00', '2017-10-31T00:00:00+00:00',\n       '2017-11-30T00:00:00+00:00', '2017-12-31T00:00:00+00:00',\n       '2018-01-31T00:00:00+00:00', '2018-02-28T00:00:00+00:00',\n       '2018-03-31T00:00:00+00:00', '2018-04-30T00:00:00+00:00',\n       '2018-05-31T00:00:00+00:00', '2018-06-30T00:00:00+00:00',\n       '2018-07-31T00:00:00+00:00', '2018-08-31T00:00:00+00:00',\n       '2018-09-30T00:00:00+00:00', '2018-10-31T00:00:00+00:00',\n       '2018-11-30T00:00:00+00:00', '2018-12-31T00:00:00+00:00',\n       '2019-01-31T00:00:00+00:00', '2019-02-28T00:00:00+00:00',\n       '2019-03-31T00:00:00+00:00', '2019-04-30T00:00:00+00:00',\n...\n       '2020-07-31T00:00:00+00:00', '2020-08-31T00:00:00+00:00',\n       '2020-09-30T00:00:00+00:00', '2020-10-31T00:00:00+00:00',\n       '2020-11-30T00:00:00+00:00', '2020-12-31T00:00:00+00:00',\n       '2021-01-31T00:00:00+00:00', '2021-02-28T00:00:00+00:00',\n       '2021-03-31T00:00:00+00:00', '2021-04-30T00:00:00+00:00',\n       '2021-05-31T00:00:00+00:00', '2021-06-30T00:00:00+00:00',\n       '2021-07-31T00:00:00+00:00', '2021-08-31T00:00:00+00:00',\n       '2021-09-30T00:00:00+00:00', '2021-10-31T00:00:00+00:00',\n       '2021-11-30T00:00:00+00:00', '2021-12-31T00:00:00+00:00',\n       '2022-01-31T00:00:00+00:00', '2022-02-28T00:00:00+00:00',\n       '2022-03-31T00:00:00+00:00', '2022-04-30T00:00:00+00:00',\n       '2022-05-31T00:00:00+00:00', '2022-06-30T00:00:00+00:00',\n       '2022-07-31T00:00:00+00:00', '2022-08-31T00:00:00+00:00',\n       '2022-09-30T00:00:00+00:00', '2022-10-31T00:00:00+00:00',\n       '2022-11-30T00:00:00+00:00', '2022-12-31T00:00:00+00:00',\n       '2023-01-31T00:00:00+00:00', '2023-02-28T00:00:00+00:00',\n       '2023-03-31T00:00:00+00:00', '2023-04-30T00:00:00+00:00',\n       '2023-05-31T00:00:00+00:00', '2023-06-30T00:00:00+00:00',\n       '2023-07-31T00:00:00+00:00', '2023-08-31T00:00:00+00:00',\n       '2023-09-30T00:00:00+00:00'], dtype='&lt;U25')start_datetime(time)&lt;U25'2016-01-01T00:00:00+00:00' ... ...array(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n...\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'], dtype='&lt;U25')proj:bbox()object{90.0, 180.0, -90.0, -180.0}array({90.0, 180.0, -90.0, -180.0}, dtype=object)proj:shape()object{1800, 3600}array({1800, 3600}, dtype=object)proj:projjson()object{'id': {'code': 4326, 'authority...array({'id': {'code': 4326, 'authority': 'EPSG'}, 'name': 'WGS 84', 'type': 'GeographicCRS', 'datum': {'name': 'World Geodetic System 1984', 'type': 'GeodeticReferenceFrame', 'ellipsoid': {'name': 'WGS 84', 'semi_major_axis': 6378137, 'inverse_flattening': 298.257223563}}, '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json', 'coordinate_system': {'axis': [{'name': 'Geodetic latitude', 'unit': 'degree', 'direction': 'north', 'abbreviation': 'Lat'}, {'name': 'Geodetic longitude', 'unit': 'degree', 'direction': 'east', 'abbreviation': 'Lon'}], 'subtype': 'ellipsoidal'}},\n      dtype=object)proj:wkt2()&lt;U277'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984...array('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n      dtype='&lt;U277')description()&lt;U47'Cloud optimized default layer t...array('Cloud optimized default layer to display on map', dtype='&lt;U47')proj:geometry()object{'type': 'Polygon', 'coordinates...array({'type': 'Polygon', 'coordinates': [[[-180.0, -90.0], [180.0, -90.0], [180.0, 90.0], [-180.0, 90.0], [-180.0, -90.0]]]},\n      dtype=object)proj:code()&lt;U9'EPSG:4326'array('EPSG:4326', dtype='&lt;U9')proj:transform()object{0.1, 0.0, 1.0, -0.1, -180.0, 90.0}array({0.1, 0.0, 1.0, -0.1, -180.0, 90.0}, dtype=object)title()&lt;U17'Default COG Layer'array('Default COG Layer', dtype='&lt;U17')epsg()int644326array(4326)time(time)&lt;U25'2016-01-01T00:00:00+00:00' ... ...array(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n       '2019-05-01T00:00:00+00:00', '2019-06-01T00:00:00+00:00',\n       '2019-07-01T00:00:00+00:00', '2019-08-01T00:00:00+00:00',\n       '2019-09-01T00:00:00+00:00', '2019-10-01T00:00:00+00:00',\n       '2019-11-01T00:00:00+00:00', '2019-12-01T00:00:00+00:00',\n       '2020-01-01T00:00:00+00:00', '2020-02-01T00:00:00+00:00',\n       '2020-03-01T00:00:00+00:00', '2020-04-01T00:00:00+00:00',\n       '2020-05-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'], dtype='&lt;U25')Indexes: (3)xPandasIndexPandasIndex(Index([            -180.0,             -179.9,             -179.8,\n                   -179.7,             -179.6,             -179.5,\n                   -179.4,             -179.3,             -179.2,\n                   -179.1,\n       ...\n                    179.0, 179.10000000000002, 179.20000000000005,\n                    179.3, 179.40000000000003,              179.5,\n       179.60000000000002, 179.70000000000005,              179.8,\n       179.90000000000003],\n      dtype='float64', name='x', length=3600))yPandasIndexPandasIndex(Index([              90.0,               89.9,               89.8,\n                     89.7,               89.6,               89.5,\n                     89.4,               89.3,               89.2,\n                     89.1,\n       ...\n                    -89.0, -89.10000000000002, -89.20000000000002,\n       -89.30000000000001,              -89.4,              -89.5,\n       -89.60000000000002, -89.70000000000002, -89.80000000000001,\n                    -89.9],\n      dtype='float64', name='y', length=1800))timePandasIndexPandasIndex(Index(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n       '2019-05-01T00:00:00+00:00', '2019-06-01T00:00:00+00:00',\n       '2019-07-01T00:00:00+00:00', '2019-08-01T00:00:00+00:00',\n       '2019-09-01T00:00:00+00:00', '2019-10-01T00:00:00+00:00',\n       '2019-11-01T00:00:00+00:00', '2019-12-01T00:00:00+00:00',\n       '2020-01-01T00:00:00+00:00', '2020-02-01T00:00:00+00:00',\n       '2020-03-01T00:00:00+00:00', '2020-04-01T00:00:00+00:00',\n       '2020-05-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'],\n      dtype='object', name='time'))Attributes: (4)spec :RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), resolutions_xy=(0.1, 0.1))crs :epsg:4326transform :| 0.10, 0.00,-180.00|\n| 0.00,-0.10, 90.00|\n| 0.00, 0.00, 1.00|resolution :0.1"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#clip-the-data-to-aoi",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#clip-the-data-to-aoi",
    "title": "Open and visualize COGs",
    "section": "Clip the data to AOI",
    "text": "Clip the data to AOI\n\nsubset = da.rio.clip([france_aoi[\"geometry\"]])\nsubset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'stackstac-732215043b0b95a370dc66f3493b95b0' (time: 93,\n                                                                y: 97, x: 143)&gt; Size: 10MB\ndask.array&lt;getitem, shape=(93, 97, 143), dtype=float64, chunksize=(1, 97, 143), chunktype=numpy.ndarray&gt;\nCoordinates: (12/18)\n    id              (time) &lt;U37 14kB 'OMI_trno2_0.10x0.10_201601_Col3_V4.nc' ...\n    band            &lt;U11 44B 'cog_default'\n  * x               (x) float64 1kB -4.7 -4.6 -4.5 -4.4 -4.3 ... 9.2 9.3 9.4 9.5\n  * y               (y) float64 776B 51.0 50.9 50.8 50.7 ... 41.7 41.6 41.5 41.4\n    end_datetime    (time) &lt;U25 9kB '2016-01-31T00:00:00+00:00' ... '2023-09-...\n    start_datetime  (time) &lt;U25 9kB '2016-01-01T00:00:00+00:00' ... '2023-09-...\n    ...              ...\n    proj:code       &lt;U9 36B 'EPSG:4326'\n    proj:transform  object 8B {0.1, 0.0, 1.0, -0.1, -180.0, 90.0}\n    title           &lt;U17 68B 'Default COG Layer'\n    epsg            int64 8B 4326\n  * time            (time) &lt;U25 9kB '2016-01-01T00:00:00+00:00' ... '2023-09-...\n    spatial_ref     int64 8B 0\nAttributes:\n    spec:        RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), r...\n    resolution:  0.1xarray.DataArray'stackstac-732215043b0b95a370dc66f3493b95b0'time: 93y: 97x: 143dask.array&lt;chunksize=(1, 97, 143), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n9.84 MiB\n108.37 kiB\n\n\nShape\n(93, 97, 143)\n(1, 97, 143)\n\n\nDask graph\n93 chunks in 8 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                             143 97 93\n\n\n\n\nCoordinates: (18)id(time)&lt;U37'OMI_trno2_0.10x0.10_201601_Col3...array(['OMI_trno2_0.10x0.10_201601_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201602_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201603_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201604_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201605_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201606_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201607_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201608_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201609_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201610_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201611_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201612_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201701_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201702_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201703_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201704_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201705_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201706_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201707_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201708_Col3_V4.nc',\n...\n       'OMI_trno2_0.10x0.10_202202_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202203_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202204_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202205_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202206_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202207_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202208_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202209_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202210_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202211_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202212_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202301_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202302_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202303_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202304_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202305_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202306_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202307_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202308_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202309_Col3_V4.nc'], dtype='&lt;U37')band()&lt;U11'cog_default'array('cog_default', dtype='&lt;U11')x(x)float64-4.7 -4.6 -4.5 -4.4 ... 9.3 9.4 9.5axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([-4.7, -4.6, -4.5, -4.4, -4.3, -4.2, -4.1, -4. , -3.9, -3.8, -3.7, -3.6,\n       -3.5, -3.4, -3.3, -3.2, -3.1, -3. , -2.9, -2.8, -2.7, -2.6, -2.5, -2.4,\n       -2.3, -2.2, -2.1, -2. , -1.9, -1.8, -1.7, -1.6, -1.5, -1.4, -1.3, -1.2,\n       -1.1, -1. , -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1,  0. ,\n        0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ,  1.1,  1.2,\n        1.3,  1.4,  1.5,  1.6,  1.7,  1.8,  1.9,  2. ,  2.1,  2.2,  2.3,  2.4,\n        2.5,  2.6,  2.7,  2.8,  2.9,  3. ,  3.1,  3.2,  3.3,  3.4,  3.5,  3.6,\n        3.7,  3.8,  3.9,  4. ,  4.1,  4.2,  4.3,  4.4,  4.5,  4.6,  4.7,  4.8,\n        4.9,  5. ,  5.1,  5.2,  5.3,  5.4,  5.5,  5.6,  5.7,  5.8,  5.9,  6. ,\n        6.1,  6.2,  6.3,  6.4,  6.5,  6.6,  6.7,  6.8,  6.9,  7. ,  7.1,  7.2,\n        7.3,  7.4,  7.5,  7.6,  7.7,  7.8,  7.9,  8. ,  8.1,  8.2,  8.3,  8.4,\n        8.5,  8.6,  8.7,  8.8,  8.9,  9. ,  9.1,  9.2,  9.3,  9.4,  9.5])y(y)float6451.0 50.9 50.8 ... 41.6 41.5 41.4axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([51. , 50.9, 50.8, 50.7, 50.6, 50.5, 50.4, 50.3, 50.2, 50.1, 50. , 49.9,\n       49.8, 49.7, 49.6, 49.5, 49.4, 49.3, 49.2, 49.1, 49. , 48.9, 48.8, 48.7,\n       48.6, 48.5, 48.4, 48.3, 48.2, 48.1, 48. , 47.9, 47.8, 47.7, 47.6, 47.5,\n       47.4, 47.3, 47.2, 47.1, 47. , 46.9, 46.8, 46.7, 46.6, 46.5, 46.4, 46.3,\n       46.2, 46.1, 46. , 45.9, 45.8, 45.7, 45.6, 45.5, 45.4, 45.3, 45.2, 45.1,\n       45. , 44.9, 44.8, 44.7, 44.6, 44.5, 44.4, 44.3, 44.2, 44.1, 44. , 43.9,\n       43.8, 43.7, 43.6, 43.5, 43.4, 43.3, 43.2, 43.1, 43. , 42.9, 42.8, 42.7,\n       42.6, 42.5, 42.4, 42.3, 42.2, 42.1, 42. , 41.9, 41.8, 41.7, 41.6, 41.5,\n       41.4])end_datetime(time)&lt;U25'2016-01-31T00:00:00+00:00' ... ...array(['2016-01-31T00:00:00+00:00', '2016-02-29T00:00:00+00:00',\n       '2016-03-31T00:00:00+00:00', '2016-04-30T00:00:00+00:00',\n       '2016-05-31T00:00:00+00:00', '2016-06-30T00:00:00+00:00',\n       '2016-07-31T00:00:00+00:00', '2016-08-31T00:00:00+00:00',\n       '2016-09-30T00:00:00+00:00', '2016-10-31T00:00:00+00:00',\n       '2016-11-30T00:00:00+00:00', '2016-12-31T00:00:00+00:00',\n       '2017-01-31T00:00:00+00:00', '2017-02-28T00:00:00+00:00',\n       '2017-03-31T00:00:00+00:00', '2017-04-30T00:00:00+00:00',\n       '2017-05-31T00:00:00+00:00', '2017-06-30T00:00:00+00:00',\n       '2017-07-31T00:00:00+00:00', '2017-08-31T00:00:00+00:00',\n       '2017-09-30T00:00:00+00:00', '2017-10-31T00:00:00+00:00',\n       '2017-11-30T00:00:00+00:00', '2017-12-31T00:00:00+00:00',\n       '2018-01-31T00:00:00+00:00', '2018-02-28T00:00:00+00:00',\n       '2018-03-31T00:00:00+00:00', '2018-04-30T00:00:00+00:00',\n       '2018-05-31T00:00:00+00:00', '2018-06-30T00:00:00+00:00',\n       '2018-07-31T00:00:00+00:00', '2018-08-31T00:00:00+00:00',\n       '2018-09-30T00:00:00+00:00', '2018-10-31T00:00:00+00:00',\n       '2018-11-30T00:00:00+00:00', '2018-12-31T00:00:00+00:00',\n       '2019-01-31T00:00:00+00:00', '2019-02-28T00:00:00+00:00',\n       '2019-03-31T00:00:00+00:00', '2019-04-30T00:00:00+00:00',\n...\n       '2020-07-31T00:00:00+00:00', '2020-08-31T00:00:00+00:00',\n       '2020-09-30T00:00:00+00:00', '2020-10-31T00:00:00+00:00',\n       '2020-11-30T00:00:00+00:00', '2020-12-31T00:00:00+00:00',\n       '2021-01-31T00:00:00+00:00', '2021-02-28T00:00:00+00:00',\n       '2021-03-31T00:00:00+00:00', '2021-04-30T00:00:00+00:00',\n       '2021-05-31T00:00:00+00:00', '2021-06-30T00:00:00+00:00',\n       '2021-07-31T00:00:00+00:00', '2021-08-31T00:00:00+00:00',\n       '2021-09-30T00:00:00+00:00', '2021-10-31T00:00:00+00:00',\n       '2021-11-30T00:00:00+00:00', '2021-12-31T00:00:00+00:00',\n       '2022-01-31T00:00:00+00:00', '2022-02-28T00:00:00+00:00',\n       '2022-03-31T00:00:00+00:00', '2022-04-30T00:00:00+00:00',\n       '2022-05-31T00:00:00+00:00', '2022-06-30T00:00:00+00:00',\n       '2022-07-31T00:00:00+00:00', '2022-08-31T00:00:00+00:00',\n       '2022-09-30T00:00:00+00:00', '2022-10-31T00:00:00+00:00',\n       '2022-11-30T00:00:00+00:00', '2022-12-31T00:00:00+00:00',\n       '2023-01-31T00:00:00+00:00', '2023-02-28T00:00:00+00:00',\n       '2023-03-31T00:00:00+00:00', '2023-04-30T00:00:00+00:00',\n       '2023-05-31T00:00:00+00:00', '2023-06-30T00:00:00+00:00',\n       '2023-07-31T00:00:00+00:00', '2023-08-31T00:00:00+00:00',\n       '2023-09-30T00:00:00+00:00'], dtype='&lt;U25')start_datetime(time)&lt;U25'2016-01-01T00:00:00+00:00' ... ...array(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n...\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'], dtype='&lt;U25')proj:bbox()object{90.0, 180.0, -90.0, -180.0}array({90.0, 180.0, -90.0, -180.0}, dtype=object)proj:shape()object{1800, 3600}array({1800, 3600}, dtype=object)proj:projjson()object{'id': {'code': 4326, 'authority...array({'id': {'code': 4326, 'authority': 'EPSG'}, 'name': 'WGS 84', 'type': 'GeographicCRS', 'datum': {'name': 'World Geodetic System 1984', 'type': 'GeodeticReferenceFrame', 'ellipsoid': {'name': 'WGS 84', 'semi_major_axis': 6378137, 'inverse_flattening': 298.257223563}}, '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json', 'coordinate_system': {'axis': [{'name': 'Geodetic latitude', 'unit': 'degree', 'direction': 'north', 'abbreviation': 'Lat'}, {'name': 'Geodetic longitude', 'unit': 'degree', 'direction': 'east', 'abbreviation': 'Lon'}], 'subtype': 'ellipsoidal'}},\n      dtype=object)proj:wkt2()&lt;U277'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984...array('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n      dtype='&lt;U277')description()&lt;U47'Cloud optimized default layer t...array('Cloud optimized default layer to display on map', dtype='&lt;U47')proj:geometry()object{'type': 'Polygon', 'coordinates...array({'type': 'Polygon', 'coordinates': [[[-180.0, -90.0], [180.0, -90.0], [180.0, 90.0], [-180.0, 90.0], [-180.0, -90.0]]]},\n      dtype=object)proj:code()&lt;U9'EPSG:4326'array('EPSG:4326', dtype='&lt;U9')proj:transform()object{0.1, 0.0, 1.0, -0.1, -180.0, 90.0}array({0.1, 0.0, 1.0, -0.1, -180.0, 90.0}, dtype=object)title()&lt;U17'Default COG Layer'array('Default COG Layer', dtype='&lt;U17')epsg()int644326array(4326)time(time)&lt;U25'2016-01-01T00:00:00+00:00' ... ...array(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n       '2019-05-01T00:00:00+00:00', '2019-06-01T00:00:00+00:00',\n       '2019-07-01T00:00:00+00:00', '2019-08-01T00:00:00+00:00',\n       '2019-09-01T00:00:00+00:00', '2019-10-01T00:00:00+00:00',\n       '2019-11-01T00:00:00+00:00', '2019-12-01T00:00:00+00:00',\n       '2020-01-01T00:00:00+00:00', '2020-02-01T00:00:00+00:00',\n       '2020-03-01T00:00:00+00:00', '2020-04-01T00:00:00+00:00',\n       '2020-05-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'], dtype='&lt;U25')spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-4.7499999999999885 0.09999999999999992 0.0 51.05 0.0 -0.10000000000000002array(0)Indexes: (3)xPandasIndexPandasIndex(Index([ -4.699999999999989,  -4.599999999999994,                -4.5,\n        -4.399999999999977,  -4.299999999999983,  -4.199999999999989,\n        -4.099999999999994,                -4.0, -3.8999999999999773,\n        -3.799999999999983,\n       ...\n         8.600000000000023,   8.700000000000017,   8.800000000000011,\n         8.900000000000006,                 9.0,   9.100000000000023,\n         9.200000000000017,   9.300000000000011,   9.400000000000006,\n                       9.5],\n      dtype='float64', name='x', length=143))yPandasIndexPandasIndex(Index([              51.0,               50.9,               50.8,\n       50.699999999999996, 50.599999999999994,               50.5,\n                     50.4,               50.3, 50.199999999999996,\n       50.099999999999994,               50.0,               49.9,\n                     49.8, 49.699999999999996, 49.599999999999994,\n                     49.5,               49.4,               49.3,\n       49.199999999999996, 49.099999999999994,               49.0,\n                     48.9,               48.8, 48.699999999999996,\n       48.599999999999994,               48.5,               48.4,\n                     48.3, 48.199999999999996, 48.099999999999994,\n                     48.0,               47.9,               47.8,\n       47.699999999999996, 47.599999999999994,               47.5,\n                     47.4,               47.3, 47.199999999999996,\n       47.099999999999994,               47.0,               46.9,\n                     46.8, 46.699999999999996, 46.599999999999994,\n                     46.5,               46.4,               46.3,\n       46.199999999999996, 46.099999999999994,               46.0,\n                     45.9,               45.8, 45.699999999999996,\n       45.599999999999994,               45.5,               45.4,\n                     45.3, 45.199999999999996, 45.099999999999994,\n                     45.0,               44.9,               44.8,\n       44.699999999999996, 44.599999999999994,               44.5,\n                     44.4,               44.3, 44.199999999999996,\n       44.099999999999994,               44.0,               43.9,\n                     43.8, 43.699999999999996, 43.599999999999994,\n                     43.5,               43.4,               43.3,\n       43.199999999999996, 43.099999999999994,               43.0,\n                     42.9,               42.8, 42.699999999999996,\n       42.599999999999994,               42.5,               42.4,\n                     42.3, 42.199999999999996, 42.099999999999994,\n                     42.0,               41.9,               41.8,\n       41.699999999999996, 41.599999999999994,               41.5,\n                     41.4],\n      dtype='float64', name='y'))timePandasIndexPandasIndex(Index(['2016-01-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-03-01T00:00:00+00:00', '2019-04-01T00:00:00+00:00',\n       '2019-05-01T00:00:00+00:00', '2019-06-01T00:00:00+00:00',\n       '2019-07-01T00:00:00+00:00', '2019-08-01T00:00:00+00:00',\n       '2019-09-01T00:00:00+00:00', '2019-10-01T00:00:00+00:00',\n       '2019-11-01T00:00:00+00:00', '2019-12-01T00:00:00+00:00',\n       '2020-01-01T00:00:00+00:00', '2020-02-01T00:00:00+00:00',\n       '2020-03-01T00:00:00+00:00', '2020-04-01T00:00:00+00:00',\n       '2020-05-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-09-01T00:00:00+00:00'],\n      dtype='object', name='time'))Attributes: (2)spec :RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), resolutions_xy=(0.1, 0.1))resolution :0.1"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#compute-and-plot",
    "href": "user-guide/notebooks/quickstarts/visualize-multiple-times.html#compute-and-plot",
    "title": "Open and visualize COGs",
    "section": "Compute and plot",
    "text": "Compute and plot\nSo far we have just been setting up a calculation lazily in Dask. Now we can trigger computation using .compute().\n\n%%time\n\nimage_stack = subset.compute()\n\nCPU times: user 3.02 s, sys: 440 ms, total: 3.46 s\nWall time: 6.63 s\n\n\n\n# get the 2% and 98% percentiles for min and max bounds of color\nvmin, vmax = image_stack.quantile(0.02).item(), image_stack.quantile(0.98).item()\n\nimage_stack.hvplot.quadmesh(\n    groupby=\"time\",\n    tiles=True,\n    colorbar=False,\n    clim=(vmin, vmax),\n    cmap=\"viridis\",\n    alpha=0.8,\n    frame_height=512,\n    widget_location=\"bottom\",\n    aspect=1,\n)"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html",
    "href": "user-guide/notebooks/quickstarts/download-assets.html",
    "title": "Download STAC assets",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Accessing the Data Directly",
      "Download STAC assets"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/download-assets.html#run-this-notebook",
    "title": "Download STAC assets",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Accessing the Data Directly",
      "Download STAC assets"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html#approach",
    "href": "user-guide/notebooks/quickstarts/download-assets.html#approach",
    "title": "Download STAC assets",
    "section": "Approach",
    "text": "Approach\nThis notebook shows how to download data for local use.\nThis is generally not the recommended approach. Whenever possible it is better to not transfer large volumes of data out of the original physical storage location. Instead users should practice data-proximate computing by processing in the same cloud and region. That is why the data for VEDA are hosted in the same region as this VEDA JupyterHub instance.\nHowever, sometimes you do need to download assets. This might be because the assets cannot be accessed directly from remote storage, or you dont have access to an environment running in the same cloud/region.\nFor these special cases, this is how you go about downloading data:\n\nUse pystac_client to open and search the STAC catalog\nUse stac-asset to download the assets related to that search\nIf you need the file on your local machine, zip and download the output directory\n\nNote that the default examples environment is missing the stac-asset package. We can pip install that before trying to import.\n\n!pip install -q stac-asset\n\n\nimport stac_asset\nfrom pystac_client import Client",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Accessing the Data Directly",
      "Download STAC assets"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/download-assets.html#declare-your-collection-of-interest",
    "title": "Download STAC assets",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac/\"\ncollection = \"caldor-fire-burn-severity\"\n\n\ncatalog = Client.open(STAC_API_URL)\nsearch = catalog.search(collections=[collection])\n\nprint(f\"Found {len(search.item_collection())} items\")\n\nFound 1 items",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Accessing the Data Directly",
      "Download STAC assets"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html#download-the-assets",
    "href": "user-guide/notebooks/quickstarts/download-assets.html#download-the-assets",
    "title": "Download STAC assets",
    "section": "Download the assets",
    "text": "Download the assets\nOnce you have identified the items that you are interested in, use stac_asset to download the related assets.\n\nawait stac_asset.download_item_collection(\n    search.item_collection(), \n    directory=\"data\", \n    config=stac_asset.Config(make_directory=True, s3_requester_pays=True)\n)\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"FeatureCollection\"\n        \n    \n                \n            \n                \n                    \n        features[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        \n            id\n            \"bs_to_save\"\n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            end_datetime\n            \"2021-10-21T12:00:00+00:00\"\n        \n    \n            \n        \n            \n                \n        \n            start_datetime\n            \"2021-08-15T00:00:00+00:00\"\n        \n    \n            \n        \n            \n                \n        \n            datetime\n            None\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 5 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        links[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/collections/caldor-fire-burn-severity\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/collections/caldor-fire-burn-severity\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"VEDA (Visualization, Exploration, and Data Analysis) STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/raster/collections/caldor-fire-burn-severity/items/bs_to_save/map?assets=cog_default&rescale=0%2C5&colormap_name=inferno_r\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of Item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            cog_default\n            \n        \n            \n                \n        \n            href\n            \"/home/jovyan/veda-docs/user-guide/notebooks/quickstarts/data/bs_to_save/bs_to_save.tif\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Default COG Layer\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Cloud optimized default layer to display on map\"\n        \n    \n            \n        \n            \n                \n        proj:bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            4326\n        \n    \n            \n        \n            \n                \n        \n            proj:wkt2\n            \"GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]\"\n        \n    \n            \n        \n            \n                \n        proj:shape[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            1103\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            2149\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        raster:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            scale\n            1.0\n        \n    \n            \n        \n            \n                \n        \n            nodata\n            -100.0\n        \n    \n            \n        \n            \n                \n        \n            offset\n            0.0\n        \n    \n            \n        \n            \n                \n        \n            sampling\n            \"area\"\n        \n    \n            \n        \n            \n                \n        \n            data_type\n            \"float64\"\n        \n    \n            \n        \n            \n                \n        \n            histogram\n            \n        \n            \n                \n        \n            max\n            4.0\n        \n    \n            \n        \n            \n                \n        \n            min\n            1.0\n        \n    \n            \n        \n            \n                \n        \n            count\n            11\n        \n    \n            \n        \n            \n                \n        buckets[] 10 items\n        \n            \n        \n            \n                \n        \n            0\n            10233\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            67409\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            71518\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            24232\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            statistics\n            \n        \n            \n                \n        \n            mean\n            2.63295307741995\n        \n    \n            \n        \n            \n                \n        \n            stddev\n            0.7936384596443959\n        \n    \n            \n        \n            \n                \n        \n            maximum\n            4.0\n        \n    \n            \n        \n            \n                \n        \n            minimum\n            1.0\n        \n    \n            \n        \n            \n                \n        \n            valid_percent\n            32.191658745247146\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        coordinates[] 1 items\n        \n            \n        \n            \n                \n        0[] 5 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        1[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        2[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        3[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        4[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:projjson\n            \n        \n            \n                \n        \n            id\n            \n        \n            \n                \n        \n            code\n            4326\n        \n    \n            \n        \n            \n                \n        \n            authority\n            \"EPSG\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            name\n            \"WGS 84\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"GeographicCRS\"\n        \n    \n            \n        \n            \n                \n        \n            datum\n            \n        \n            \n                \n        \n            name\n            \"World Geodetic System 1984\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"GeodeticReferenceFrame\"\n        \n    \n            \n        \n            \n                \n        \n            ellipsoid\n            \n        \n            \n                \n        \n            name\n            \"WGS 84\"\n        \n    \n            \n        \n            \n                \n        \n            semi_major_axis\n            6378137\n        \n    \n            \n        \n            \n                \n        \n            inverse_flattening\n            298.257223563\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            $schema\n            \"https://proj.org/schemas/v0.4/projjson.schema.json\"\n        \n    \n            \n        \n            \n                \n        \n            coordinate_system\n            \n        \n            \n                \n        axis[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Geodetic latitude\"\n        \n    \n            \n        \n            \n                \n        \n            unit\n            \"degree\"\n        \n    \n            \n        \n            \n                \n        \n            direction\n            \"north\"\n        \n    \n            \n        \n            \n                \n        \n            abbreviation\n            \"Lat\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Geodetic longitude\"\n        \n    \n            \n        \n            \n                \n        \n            unit\n            \"degree\"\n        \n    \n            \n        \n            \n                \n        \n            direction\n            \"east\"\n        \n    \n            \n        \n            \n                \n        \n            abbreviation\n            \"Lon\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            subtype\n            \"ellipsoidal\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        proj:transform[] 9 items\n        \n            \n        \n            \n                \n        \n            0\n            0.0003230948999417961\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -0.00032309489994179427\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        roles[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"layer\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"/home/jovyan/veda-docs/user-guide/notebooks/quickstarts/data/bs_to_save/preview.png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        bbox[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -120.61338752166166\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            38.54940283865057\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -119.91905658168675\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            38.90577651328637\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        stac_extensions[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"caldor-fire-burn-severity\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n        \n    \n\n\n\nNote: For downloading just one item use stac_asset.download_item.",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Accessing the Data Directly",
      "Download STAC assets"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/download-assets.html#download-from-jupyterhub",
    "href": "user-guide/notebooks/quickstarts/download-assets.html#download-from-jupyterhub",
    "title": "Download STAC assets",
    "section": "Download from JupyterHub",
    "text": "Download from JupyterHub\nIf you want to further download from this JupyterHub to your local machine you can zip the data directory:\n\n!zip -r data.zip data\n\nupdating: data/ (stored 0%)\nupdating: data/item-collection.json (deflated 74%)\nupdating: data/bs_to_save/ (stored 0%)\nupdating: data/bs_to_save/bs_to_save.tif (deflated 16%)\nupdating: data/bs_to_save/preview.png (deflated 3%)\n\n\nThen right click on the the zipped file in the Jupyter file browser and select Download\n\n\n\nRight click on zip file to see options that include Download",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Accessing the Data Directly",
      "Download STAC assets"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html",
    "title": "Calculate timeseries from COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#run-this-notebook",
    "title": "Calculate timeseries from COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#approach",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#approach",
    "title": "Calculate timeseries from COGs",
    "section": "Approach",
    "text": "Approach\n\nUse pystac_client to open the STAC catalog and retrieve the items in the collection\nUse stackstac to create an xarray dataset containing all the items cropped to AOI\nCalculate the mean for each timestep over the AOI\n\n\nfrom pystac_client import Client\nimport pandas as pd\nimport stackstac\n\nimport rioxarray  # noqa\nimport hvplot.xarray  # noqa"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#declare-your-collection-of-interest",
    "title": "Calculate timeseries from COGs",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac/\"\ncollection = \"no2-monthly\""
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#discover-items-in-collection-for-region-and-time-of-interest",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#discover-items-in-collection-for-region-and-time-of-interest",
    "title": "Calculate timeseries from COGs",
    "section": "Discover items in collection for region and time of interest",
    "text": "Discover items in collection for region and time of interest\nUse pystac_client to search the STAC collection for a particular area of interest within specified datetime bounds.\n\nchina_bbox = [\n    73.675,\n    18.198,\n    135.026,\n    53.459,\n]\ndatetime = \"2000-01-01/2025-07-25\"\n\n\ncatalog = Client.open(STAC_API_URL)\nsearch = catalog.search(\n    bbox=china_bbox, datetime=datetime, collections=[collection], limit=1000\n)\nitem_collection = search.item_collection()\nprint(f\"Found {len(item_collection)} items\")\n\nFound 93 items"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#read-data",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#read-data",
    "title": "Calculate timeseries from COGs",
    "section": "Read data",
    "text": "Read data\nRead in data using xarray using a combination of xpystac, stackstac, and rasterio.\n\nda = stackstac.stack(item_collection, epsg=4326)\nda = da.assign_coords({\"time\": pd.to_datetime(da.start_datetime)}).squeeze()\nda\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'stackstac-707c2fec3a4bde6be0d838dc97f60ec1' (time: 93,\n                                                                y: 1800, x: 3600)&gt; Size: 5GB\ndask.array&lt;getitem, shape=(93, 1800, 3600), dtype=float64, chunksize=(1, 1024, 1024), chunktype=numpy.ndarray&gt;\nCoordinates: (12/17)\n    id              (time) &lt;U37 14kB 'OMI_trno2_0.10x0.10_202309_Col3_V4.nc' ...\n    band            &lt;U11 44B 'cog_default'\n  * x               (x) float64 29kB -180.0 -179.9 -179.8 ... 179.7 179.8 179.9\n  * y               (y) float64 14kB 90.0 89.9 89.8 89.7 ... -89.7 -89.8 -89.9\n    start_datetime  (time) &lt;U25 9kB '2023-09-01T00:00:00+00:00' ... '2016-01-...\n    end_datetime    (time) &lt;U25 9kB '2023-09-30T00:00:00+00:00' ... '2016-01-...\n    ...              ...\n    proj:code       &lt;U9 36B 'EPSG:4326'\n    title           &lt;U17 68B 'Default COG Layer'\n    proj:shape      object 8B {1800, 3600}\n    description     &lt;U47 188B 'Cloud optimized default layer to display on map'\n    epsg            int64 8B 4326\n  * time            (time) datetime64[ns, UTC] 744B 2023-09-01T00:00:00+00:00...\nAttributes:\n    spec:        RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), r...\n    crs:         epsg:4326\n    transform:   | 0.10, 0.00,-180.00|\\n| 0.00,-0.10, 90.00|\\n| 0.00, 0.00, 1...\n    resolution:  0.1xarray.DataArray'stackstac-707c2fec3a4bde6be0d838dc97f60ec1'time: 93y: 1800x: 3600dask.array&lt;chunksize=(1, 1024, 1024), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n4.49 GiB\n8.00 MiB\n\n\nShape\n(93, 1800, 3600)\n(1, 1024, 1024)\n\n\nDask graph\n744 chunks in 4 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                                     3600 1800 93\n\n\n\n\nCoordinates: (17)id(time)&lt;U37'OMI_trno2_0.10x0.10_202309_Col3...array(['OMI_trno2_0.10x0.10_202309_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202308_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202307_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202306_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202305_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202304_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202303_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202302_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202301_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202212_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202211_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202210_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202209_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202208_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202207_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202206_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202205_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202204_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202203_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202202_Col3_V4.nc',\n...\n       'OMI_trno2_0.10x0.10_201708_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201707_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201706_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201705_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201704_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201703_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201702_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201701_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201612_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201611_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201610_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201609_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201608_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201607_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201606_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201605_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201604_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201603_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201602_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201601_Col3_V4.nc'], dtype='&lt;U37')band()&lt;U11'cog_default'array('cog_default', dtype='&lt;U11')x(x)float64-180.0 -179.9 ... 179.8 179.9array([-180. , -179.9, -179.8, ...,  179.7,  179.8,  179.9], shape=(3600,))y(y)float6490.0 89.9 89.8 ... -89.8 -89.9array([ 90. ,  89.9,  89.8, ..., -89.7, -89.8, -89.9], shape=(1800,))start_datetime(time)&lt;U25'2023-09-01T00:00:00+00:00' ... ...array(['2023-09-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n...\n       '2019-03-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-01-01T00:00:00+00:00'], dtype='&lt;U25')end_datetime(time)&lt;U25'2023-09-30T00:00:00+00:00' ... ...array(['2023-09-30T00:00:00+00:00', '2023-08-31T00:00:00+00:00',\n       '2023-07-31T00:00:00+00:00', '2023-06-30T00:00:00+00:00',\n       '2023-05-31T00:00:00+00:00', '2023-04-30T00:00:00+00:00',\n       '2023-03-31T00:00:00+00:00', '2023-02-28T00:00:00+00:00',\n       '2023-01-31T00:00:00+00:00', '2022-12-31T00:00:00+00:00',\n       '2022-11-30T00:00:00+00:00', '2022-10-31T00:00:00+00:00',\n       '2022-09-30T00:00:00+00:00', '2022-08-31T00:00:00+00:00',\n       '2022-07-31T00:00:00+00:00', '2022-06-30T00:00:00+00:00',\n       '2022-05-31T00:00:00+00:00', '2022-04-30T00:00:00+00:00',\n       '2022-03-31T00:00:00+00:00', '2022-02-28T00:00:00+00:00',\n       '2022-01-31T00:00:00+00:00', '2021-12-31T00:00:00+00:00',\n       '2021-11-30T00:00:00+00:00', '2021-10-31T00:00:00+00:00',\n       '2021-09-30T00:00:00+00:00', '2021-08-31T00:00:00+00:00',\n       '2021-07-31T00:00:00+00:00', '2021-06-30T00:00:00+00:00',\n       '2021-05-31T00:00:00+00:00', '2021-04-30T00:00:00+00:00',\n       '2021-03-31T00:00:00+00:00', '2021-02-28T00:00:00+00:00',\n       '2021-01-31T00:00:00+00:00', '2020-12-31T00:00:00+00:00',\n       '2020-11-30T00:00:00+00:00', '2020-10-31T00:00:00+00:00',\n       '2020-09-30T00:00:00+00:00', '2020-08-31T00:00:00+00:00',\n       '2020-07-31T00:00:00+00:00', '2020-06-30T00:00:00+00:00',\n...\n       '2019-03-31T00:00:00+00:00', '2019-02-28T00:00:00+00:00',\n       '2019-01-31T00:00:00+00:00', '2018-12-31T00:00:00+00:00',\n       '2018-11-30T00:00:00+00:00', '2018-10-31T00:00:00+00:00',\n       '2018-09-30T00:00:00+00:00', '2018-08-31T00:00:00+00:00',\n       '2018-07-31T00:00:00+00:00', '2018-06-30T00:00:00+00:00',\n       '2018-05-31T00:00:00+00:00', '2018-04-30T00:00:00+00:00',\n       '2018-03-31T00:00:00+00:00', '2018-02-28T00:00:00+00:00',\n       '2018-01-31T00:00:00+00:00', '2017-12-31T00:00:00+00:00',\n       '2017-11-30T00:00:00+00:00', '2017-10-31T00:00:00+00:00',\n       '2017-09-30T00:00:00+00:00', '2017-08-31T00:00:00+00:00',\n       '2017-07-31T00:00:00+00:00', '2017-06-30T00:00:00+00:00',\n       '2017-05-31T00:00:00+00:00', '2017-04-30T00:00:00+00:00',\n       '2017-03-31T00:00:00+00:00', '2017-02-28T00:00:00+00:00',\n       '2017-01-31T00:00:00+00:00', '2016-12-31T00:00:00+00:00',\n       '2016-11-30T00:00:00+00:00', '2016-10-31T00:00:00+00:00',\n       '2016-09-30T00:00:00+00:00', '2016-08-31T00:00:00+00:00',\n       '2016-07-31T00:00:00+00:00', '2016-06-30T00:00:00+00:00',\n       '2016-05-31T00:00:00+00:00', '2016-04-30T00:00:00+00:00',\n       '2016-03-31T00:00:00+00:00', '2016-02-29T00:00:00+00:00',\n       '2016-01-31T00:00:00+00:00'], dtype='&lt;U25')proj:wkt2()&lt;U277'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984...array('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n      dtype='&lt;U277')proj:transform()object{0.1, 0.0, 1.0, -0.1, -180.0, 90.0}array({0.1, 0.0, 1.0, -0.1, -180.0, 90.0}, dtype=object)proj:projjson()object{'id': {'code': 4326, 'authority...array({'id': {'code': 4326, 'authority': 'EPSG'}, 'name': 'WGS 84', 'type': 'GeographicCRS', 'datum': {'name': 'World Geodetic System 1984', 'type': 'GeodeticReferenceFrame', 'ellipsoid': {'name': 'WGS 84', 'semi_major_axis': 6378137, 'inverse_flattening': 298.257223563}}, '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json', 'coordinate_system': {'axis': [{'name': 'Geodetic latitude', 'unit': 'degree', 'direction': 'north', 'abbreviation': 'Lat'}, {'name': 'Geodetic longitude', 'unit': 'degree', 'direction': 'east', 'abbreviation': 'Lon'}], 'subtype': 'ellipsoidal'}},\n      dtype=object)proj:bbox()object{90.0, 180.0, -90.0, -180.0}array({90.0, 180.0, -90.0, -180.0}, dtype=object)proj:geometry()object{'type': 'Polygon', 'coordinates...array({'type': 'Polygon', 'coordinates': [[[-180.0, -90.0], [180.0, -90.0], [180.0, 90.0], [-180.0, 90.0], [-180.0, -90.0]]]},\n      dtype=object)proj:code()&lt;U9'EPSG:4326'array('EPSG:4326', dtype='&lt;U9')title()&lt;U17'Default COG Layer'array('Default COG Layer', dtype='&lt;U17')proj:shape()object{1800, 3600}array({1800, 3600}, dtype=object)description()&lt;U47'Cloud optimized default layer t...array('Cloud optimized default layer to display on map', dtype='&lt;U47')epsg()int644326array(4326)time(time)datetime64[ns, UTC]2023-09-01T00:00:00+00:00 ... 20...&lt;DatetimeArray&gt;\n['2023-09-01 00:00:00+00:00', '2023-08-01 00:00:00+00:00',\n '2023-07-01 00:00:00+00:00', '2023-06-01 00:00:00+00:00',\n '2023-05-01 00:00:00+00:00', '2023-04-01 00:00:00+00:00',\n '2023-03-01 00:00:00+00:00', '2023-02-01 00:00:00+00:00',\n '2023-01-01 00:00:00+00:00', '2022-12-01 00:00:00+00:00',\n '2022-11-01 00:00:00+00:00', '2022-10-01 00:00:00+00:00',\n '2022-09-01 00:00:00+00:00', '2022-08-01 00:00:00+00:00',\n '2022-07-01 00:00:00+00:00', '2022-06-01 00:00:00+00:00',\n '2022-05-01 00:00:00+00:00', '2022-04-01 00:00:00+00:00',\n '2022-03-01 00:00:00+00:00', '2022-02-01 00:00:00+00:00',\n '2022-01-01 00:00:00+00:00', '2021-12-01 00:00:00+00:00',\n '2021-11-01 00:00:00+00:00', '2021-10-01 00:00:00+00:00',\n '2021-09-01 00:00:00+00:00', '2021-08-01 00:00:00+00:00',\n '2021-07-01 00:00:00+00:00', '2021-06-01 00:00:00+00:00',\n '2021-05-01 00:00:00+00:00', '2021-04-01 00:00:00+00:00',\n '2021-03-01 00:00:00+00:00', '2021-02-01 00:00:00+00:00',\n '2021-01-01 00:00:00+00:00', '2020-12-01 00:00:00+00:00',\n '2020-11-01 00:00:00+00:00', '2020-10-01 00:00:00+00:00',\n '2020-09-01 00:00:00+00:00', '2020-08-01 00:00:00+00:00',\n '2020-07-01 00:00:00+00:00', '2020-06-01 00:00:00+00:00',\n '2020-05-01 00:00:00+00:00', '2020-04-01 00:00:00+00:00',\n '2020-03-01 00:00:00+00:00', '2020-02-01 00:00:00+00:00',\n '2020-01-01 00:00:00+00:00', '2019-12-01 00:00:00+00:00',\n '2019-11-01 00:00:00+00:00', '2019-10-01 00:00:00+00:00',\n '2019-09-01 00:00:00+00:00', '2019-08-01 00:00:00+00:00',\n '2019-07-01 00:00:00+00:00', '2019-06-01 00:00:00+00:00',\n '2019-05-01 00:00:00+00:00', '2019-04-01 00:00:00+00:00',\n '2019-03-01 00:00:00+00:00', '2019-02-01 00:00:00+00:00',\n '2019-01-01 00:00:00+00:00', '2018-12-01 00:00:00+00:00',\n '2018-11-01 00:00:00+00:00', '2018-10-01 00:00:00+00:00',\n '2018-09-01 00:00:00+00:00', '2018-08-01 00:00:00+00:00',\n '2018-07-01 00:00:00+00:00', '2018-06-01 00:00:00+00:00',\n '2018-05-01 00:00:00+00:00', '2018-04-01 00:00:00+00:00',\n '2018-03-01 00:00:00+00:00', '2018-02-01 00:00:00+00:00',\n '2018-01-01 00:00:00+00:00', '2017-12-01 00:00:00+00:00',\n '2017-11-01 00:00:00+00:00', '2017-10-01 00:00:00+00:00',\n '2017-09-01 00:00:00+00:00', '2017-08-01 00:00:00+00:00',\n '2017-07-01 00:00:00+00:00', '2017-06-01 00:00:00+00:00',\n '2017-05-01 00:00:00+00:00', '2017-04-01 00:00:00+00:00',\n '2017-03-01 00:00:00+00:00', '2017-02-01 00:00:00+00:00',\n '2017-01-01 00:00:00+00:00', '2016-12-01 00:00:00+00:00',\n '2016-11-01 00:00:00+00:00', '2016-10-01 00:00:00+00:00',\n '2016-09-01 00:00:00+00:00', '2016-08-01 00:00:00+00:00',\n '2016-07-01 00:00:00+00:00', '2016-06-01 00:00:00+00:00',\n '2016-05-01 00:00:00+00:00', '2016-04-01 00:00:00+00:00',\n '2016-03-01 00:00:00+00:00', '2016-02-01 00:00:00+00:00',\n '2016-01-01 00:00:00+00:00']\nLength: 93, dtype: datetime64[ns, UTC]Indexes: (3)xPandasIndexPandasIndex(Index([            -180.0,             -179.9,             -179.8,\n                   -179.7,             -179.6,             -179.5,\n                   -179.4,             -179.3,             -179.2,\n                   -179.1,\n       ...\n                    179.0, 179.10000000000002, 179.20000000000005,\n                    179.3, 179.40000000000003,              179.5,\n       179.60000000000002, 179.70000000000005,              179.8,\n       179.90000000000003],\n      dtype='float64', name='x', length=3600))yPandasIndexPandasIndex(Index([              90.0,               89.9,               89.8,\n                     89.7,               89.6,               89.5,\n                     89.4,               89.3,               89.2,\n                     89.1,\n       ...\n                    -89.0, -89.10000000000002, -89.20000000000002,\n       -89.30000000000001,              -89.4,              -89.5,\n       -89.60000000000002, -89.70000000000002, -89.80000000000001,\n                    -89.9],\n      dtype='float64', name='y', length=1800))timePandasIndexPandasIndex(DatetimeIndex(['2023-09-01 00:00:00+00:00', '2023-08-01 00:00:00+00:00',\n               '2023-07-01 00:00:00+00:00', '2023-06-01 00:00:00+00:00',\n               '2023-05-01 00:00:00+00:00', '2023-04-01 00:00:00+00:00',\n               '2023-03-01 00:00:00+00:00', '2023-02-01 00:00:00+00:00',\n               '2023-01-01 00:00:00+00:00', '2022-12-01 00:00:00+00:00',\n               '2022-11-01 00:00:00+00:00', '2022-10-01 00:00:00+00:00',\n               '2022-09-01 00:00:00+00:00', '2022-08-01 00:00:00+00:00',\n               '2022-07-01 00:00:00+00:00', '2022-06-01 00:00:00+00:00',\n               '2022-05-01 00:00:00+00:00', '2022-04-01 00:00:00+00:00',\n               '2022-03-01 00:00:00+00:00', '2022-02-01 00:00:00+00:00',\n               '2022-01-01 00:00:00+00:00', '2021-12-01 00:00:00+00:00',\n               '2021-11-01 00:00:00+00:00', '2021-10-01 00:00:00+00:00',\n               '2021-09-01 00:00:00+00:00', '2021-08-01 00:00:00+00:00',\n               '2021-07-01 00:00:00+00:00', '2021-06-01 00:00:00+00:00',\n               '2021-05-01 00:00:00+00:00', '2021-04-01 00:00:00+00:00',\n               '2021-03-01 00:00:00+00:00', '2021-02-01 00:00:00+00:00',\n               '2021-01-01 00:00:00+00:00', '2020-12-01 00:00:00+00:00',\n               '2020-11-01 00:00:00+00:00', '2020-10-01 00:00:00+00:00',\n               '2020-09-01 00:00:00+00:00', '2020-08-01 00:00:00+00:00',\n               '2020-07-01 00:00:00+00:00', '2020-06-01 00:00:00+00:00',\n               '2020-05-01 00:00:00+00:00', '2020-04-01 00:00:00+00:00',\n               '2020-03-01 00:00:00+00:00', '2020-02-01 00:00:00+00:00',\n               '2020-01-01 00:00:00+00:00', '2019-12-01 00:00:00+00:00',\n               '2019-11-01 00:00:00+00:00', '2019-10-01 00:00:00+00:00',\n               '2019-09-01 00:00:00+00:00', '2019-08-01 00:00:00+00:00',\n               '2019-07-01 00:00:00+00:00', '2019-06-01 00:00:00+00:00',\n               '2019-05-01 00:00:00+00:00', '2019-04-01 00:00:00+00:00',\n               '2019-03-01 00:00:00+00:00', '2019-02-01 00:00:00+00:00',\n               '2019-01-01 00:00:00+00:00', '2018-12-01 00:00:00+00:00',\n               '2018-11-01 00:00:00+00:00', '2018-10-01 00:00:00+00:00',\n               '2018-09-01 00:00:00+00:00', '2018-08-01 00:00:00+00:00',\n               '2018-07-01 00:00:00+00:00', '2018-06-01 00:00:00+00:00',\n               '2018-05-01 00:00:00+00:00', '2018-04-01 00:00:00+00:00',\n               '2018-03-01 00:00:00+00:00', '2018-02-01 00:00:00+00:00',\n               '2018-01-01 00:00:00+00:00', '2017-12-01 00:00:00+00:00',\n               '2017-11-01 00:00:00+00:00', '2017-10-01 00:00:00+00:00',\n               '2017-09-01 00:00:00+00:00', '2017-08-01 00:00:00+00:00',\n               '2017-07-01 00:00:00+00:00', '2017-06-01 00:00:00+00:00',\n               '2017-05-01 00:00:00+00:00', '2017-04-01 00:00:00+00:00',\n               '2017-03-01 00:00:00+00:00', '2017-02-01 00:00:00+00:00',\n               '2017-01-01 00:00:00+00:00', '2016-12-01 00:00:00+00:00',\n               '2016-11-01 00:00:00+00:00', '2016-10-01 00:00:00+00:00',\n               '2016-09-01 00:00:00+00:00', '2016-08-01 00:00:00+00:00',\n               '2016-07-01 00:00:00+00:00', '2016-06-01 00:00:00+00:00',\n               '2016-05-01 00:00:00+00:00', '2016-04-01 00:00:00+00:00',\n               '2016-03-01 00:00:00+00:00', '2016-02-01 00:00:00+00:00',\n               '2016-01-01 00:00:00+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None))Attributes: (4)spec :RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), resolutions_xy=(0.1, 0.1))crs :epsg:4326transform :| 0.10, 0.00,-180.00|\n| 0.00,-0.10, 90.00|\n| 0.00, 0.00, 1.00|resolution :0.1"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#clip-the-data-to-the-bounding-box-for-china",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#clip-the-data-to-the-bounding-box-for-china",
    "title": "Calculate timeseries from COGs",
    "section": "Clip the data to the bounding box for China",
    "text": "Clip the data to the bounding box for China\n\n# Subset to Bounding Box for China\nsubset = da.rio.clip_box(*china_bbox)\nsubset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'stackstac-707c2fec3a4bde6be0d838dc97f60ec1' (time: 93,\n                                                                y: 354, x: 614)&gt; Size: 162MB\ndask.array&lt;getitem, shape=(93, 354, 614), dtype=float64, chunksize=(1, 354, 535), chunktype=numpy.ndarray&gt;\nCoordinates: (12/18)\n    id              (time) &lt;U37 14kB 'OMI_trno2_0.10x0.10_202309_Col3_V4.nc' ...\n    band            &lt;U11 44B 'cog_default'\n  * x               (x) float64 5kB 73.7 73.8 73.9 74.0 ... 134.8 134.9 135.0\n  * y               (y) float64 3kB 53.5 53.4 53.3 53.2 ... 18.5 18.4 18.3 18.2\n    start_datetime  (time) &lt;U25 9kB '2023-09-01T00:00:00+00:00' ... '2016-01-...\n    end_datetime    (time) &lt;U25 9kB '2023-09-30T00:00:00+00:00' ... '2016-01-...\n    ...              ...\n    title           &lt;U17 68B 'Default COG Layer'\n    proj:shape      object 8B {1800, 3600}\n    description     &lt;U47 188B 'Cloud optimized default layer to display on map'\n    epsg            int64 8B 4326\n  * time            (time) datetime64[ns, UTC] 744B 2023-09-01T00:00:00+00:00...\n    spatial_ref     int64 8B 0\nAttributes:\n    spec:        RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), r...\n    resolution:  0.1xarray.DataArray'stackstac-707c2fec3a4bde6be0d838dc97f60ec1'time: 93y: 354x: 614dask.array&lt;chunksize=(1, 354, 535), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n154.22 MiB\n1.44 MiB\n\n\nShape\n(93, 354, 614)\n(1, 354, 535)\n\n\nDask graph\n186 chunks in 5 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                               614 354 93\n\n\n\n\nCoordinates: (18)id(time)&lt;U37'OMI_trno2_0.10x0.10_202309_Col3...array(['OMI_trno2_0.10x0.10_202309_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202308_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202307_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202306_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202305_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202304_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202303_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202302_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202301_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202212_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202211_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202210_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202209_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202208_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202207_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202206_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202205_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202204_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202203_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_202202_Col3_V4.nc',\n...\n       'OMI_trno2_0.10x0.10_201708_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201707_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201706_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201705_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201704_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201703_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201702_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201701_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201612_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201611_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201610_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201609_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201608_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201607_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201606_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201605_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201604_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201603_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201602_Col3_V4.nc',\n       'OMI_trno2_0.10x0.10_201601_Col3_V4.nc'], dtype='&lt;U37')band()&lt;U11'cog_default'array('cog_default', dtype='&lt;U11')x(x)float6473.7 73.8 73.9 ... 134.9 135.0axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([ 73.7,  73.8,  73.9, ..., 134.8, 134.9, 135. ], shape=(614,))y(y)float6453.5 53.4 53.3 ... 18.4 18.3 18.2axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([53.5, 53.4, 53.3, ..., 18.4, 18.3, 18.2], shape=(354,))start_datetime(time)&lt;U25'2023-09-01T00:00:00+00:00' ... ...array(['2023-09-01T00:00:00+00:00', '2023-08-01T00:00:00+00:00',\n       '2023-07-01T00:00:00+00:00', '2023-06-01T00:00:00+00:00',\n       '2023-05-01T00:00:00+00:00', '2023-04-01T00:00:00+00:00',\n       '2023-03-01T00:00:00+00:00', '2023-02-01T00:00:00+00:00',\n       '2023-01-01T00:00:00+00:00', '2022-12-01T00:00:00+00:00',\n       '2022-11-01T00:00:00+00:00', '2022-10-01T00:00:00+00:00',\n       '2022-09-01T00:00:00+00:00', '2022-08-01T00:00:00+00:00',\n       '2022-07-01T00:00:00+00:00', '2022-06-01T00:00:00+00:00',\n       '2022-05-01T00:00:00+00:00', '2022-04-01T00:00:00+00:00',\n       '2022-03-01T00:00:00+00:00', '2022-02-01T00:00:00+00:00',\n       '2022-01-01T00:00:00+00:00', '2021-12-01T00:00:00+00:00',\n       '2021-11-01T00:00:00+00:00', '2021-10-01T00:00:00+00:00',\n       '2021-09-01T00:00:00+00:00', '2021-08-01T00:00:00+00:00',\n       '2021-07-01T00:00:00+00:00', '2021-06-01T00:00:00+00:00',\n       '2021-05-01T00:00:00+00:00', '2021-04-01T00:00:00+00:00',\n       '2021-03-01T00:00:00+00:00', '2021-02-01T00:00:00+00:00',\n       '2021-01-01T00:00:00+00:00', '2020-12-01T00:00:00+00:00',\n       '2020-11-01T00:00:00+00:00', '2020-10-01T00:00:00+00:00',\n       '2020-09-01T00:00:00+00:00', '2020-08-01T00:00:00+00:00',\n       '2020-07-01T00:00:00+00:00', '2020-06-01T00:00:00+00:00',\n...\n       '2019-03-01T00:00:00+00:00', '2019-02-01T00:00:00+00:00',\n       '2019-01-01T00:00:00+00:00', '2018-12-01T00:00:00+00:00',\n       '2018-11-01T00:00:00+00:00', '2018-10-01T00:00:00+00:00',\n       '2018-09-01T00:00:00+00:00', '2018-08-01T00:00:00+00:00',\n       '2018-07-01T00:00:00+00:00', '2018-06-01T00:00:00+00:00',\n       '2018-05-01T00:00:00+00:00', '2018-04-01T00:00:00+00:00',\n       '2018-03-01T00:00:00+00:00', '2018-02-01T00:00:00+00:00',\n       '2018-01-01T00:00:00+00:00', '2017-12-01T00:00:00+00:00',\n       '2017-11-01T00:00:00+00:00', '2017-10-01T00:00:00+00:00',\n       '2017-09-01T00:00:00+00:00', '2017-08-01T00:00:00+00:00',\n       '2017-07-01T00:00:00+00:00', '2017-06-01T00:00:00+00:00',\n       '2017-05-01T00:00:00+00:00', '2017-04-01T00:00:00+00:00',\n       '2017-03-01T00:00:00+00:00', '2017-02-01T00:00:00+00:00',\n       '2017-01-01T00:00:00+00:00', '2016-12-01T00:00:00+00:00',\n       '2016-11-01T00:00:00+00:00', '2016-10-01T00:00:00+00:00',\n       '2016-09-01T00:00:00+00:00', '2016-08-01T00:00:00+00:00',\n       '2016-07-01T00:00:00+00:00', '2016-06-01T00:00:00+00:00',\n       '2016-05-01T00:00:00+00:00', '2016-04-01T00:00:00+00:00',\n       '2016-03-01T00:00:00+00:00', '2016-02-01T00:00:00+00:00',\n       '2016-01-01T00:00:00+00:00'], dtype='&lt;U25')end_datetime(time)&lt;U25'2023-09-30T00:00:00+00:00' ... ...array(['2023-09-30T00:00:00+00:00', '2023-08-31T00:00:00+00:00',\n       '2023-07-31T00:00:00+00:00', '2023-06-30T00:00:00+00:00',\n       '2023-05-31T00:00:00+00:00', '2023-04-30T00:00:00+00:00',\n       '2023-03-31T00:00:00+00:00', '2023-02-28T00:00:00+00:00',\n       '2023-01-31T00:00:00+00:00', '2022-12-31T00:00:00+00:00',\n       '2022-11-30T00:00:00+00:00', '2022-10-31T00:00:00+00:00',\n       '2022-09-30T00:00:00+00:00', '2022-08-31T00:00:00+00:00',\n       '2022-07-31T00:00:00+00:00', '2022-06-30T00:00:00+00:00',\n       '2022-05-31T00:00:00+00:00', '2022-04-30T00:00:00+00:00',\n       '2022-03-31T00:00:00+00:00', '2022-02-28T00:00:00+00:00',\n       '2022-01-31T00:00:00+00:00', '2021-12-31T00:00:00+00:00',\n       '2021-11-30T00:00:00+00:00', '2021-10-31T00:00:00+00:00',\n       '2021-09-30T00:00:00+00:00', '2021-08-31T00:00:00+00:00',\n       '2021-07-31T00:00:00+00:00', '2021-06-30T00:00:00+00:00',\n       '2021-05-31T00:00:00+00:00', '2021-04-30T00:00:00+00:00',\n       '2021-03-31T00:00:00+00:00', '2021-02-28T00:00:00+00:00',\n       '2021-01-31T00:00:00+00:00', '2020-12-31T00:00:00+00:00',\n       '2020-11-30T00:00:00+00:00', '2020-10-31T00:00:00+00:00',\n       '2020-09-30T00:00:00+00:00', '2020-08-31T00:00:00+00:00',\n       '2020-07-31T00:00:00+00:00', '2020-06-30T00:00:00+00:00',\n...\n       '2019-03-31T00:00:00+00:00', '2019-02-28T00:00:00+00:00',\n       '2019-01-31T00:00:00+00:00', '2018-12-31T00:00:00+00:00',\n       '2018-11-30T00:00:00+00:00', '2018-10-31T00:00:00+00:00',\n       '2018-09-30T00:00:00+00:00', '2018-08-31T00:00:00+00:00',\n       '2018-07-31T00:00:00+00:00', '2018-06-30T00:00:00+00:00',\n       '2018-05-31T00:00:00+00:00', '2018-04-30T00:00:00+00:00',\n       '2018-03-31T00:00:00+00:00', '2018-02-28T00:00:00+00:00',\n       '2018-01-31T00:00:00+00:00', '2017-12-31T00:00:00+00:00',\n       '2017-11-30T00:00:00+00:00', '2017-10-31T00:00:00+00:00',\n       '2017-09-30T00:00:00+00:00', '2017-08-31T00:00:00+00:00',\n       '2017-07-31T00:00:00+00:00', '2017-06-30T00:00:00+00:00',\n       '2017-05-31T00:00:00+00:00', '2017-04-30T00:00:00+00:00',\n       '2017-03-31T00:00:00+00:00', '2017-02-28T00:00:00+00:00',\n       '2017-01-31T00:00:00+00:00', '2016-12-31T00:00:00+00:00',\n       '2016-11-30T00:00:00+00:00', '2016-10-31T00:00:00+00:00',\n       '2016-09-30T00:00:00+00:00', '2016-08-31T00:00:00+00:00',\n       '2016-07-31T00:00:00+00:00', '2016-06-30T00:00:00+00:00',\n       '2016-05-31T00:00:00+00:00', '2016-04-30T00:00:00+00:00',\n       '2016-03-31T00:00:00+00:00', '2016-02-29T00:00:00+00:00',\n       '2016-01-31T00:00:00+00:00'], dtype='&lt;U25')proj:wkt2()&lt;U277'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984...array('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n      dtype='&lt;U277')proj:transform()object{0.1, 0.0, 1.0, -0.1, -180.0, 90.0}array({0.1, 0.0, 1.0, -0.1, -180.0, 90.0}, dtype=object)proj:projjson()object{'id': {'code': 4326, 'authority...array({'id': {'code': 4326, 'authority': 'EPSG'}, 'name': 'WGS 84', 'type': 'GeographicCRS', 'datum': {'name': 'World Geodetic System 1984', 'type': 'GeodeticReferenceFrame', 'ellipsoid': {'name': 'WGS 84', 'semi_major_axis': 6378137, 'inverse_flattening': 298.257223563}}, '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json', 'coordinate_system': {'axis': [{'name': 'Geodetic latitude', 'unit': 'degree', 'direction': 'north', 'abbreviation': 'Lat'}, {'name': 'Geodetic longitude', 'unit': 'degree', 'direction': 'east', 'abbreviation': 'Lon'}], 'subtype': 'ellipsoidal'}},\n      dtype=object)proj:bbox()object{90.0, 180.0, -90.0, -180.0}array({90.0, 180.0, -90.0, -180.0}, dtype=object)proj:geometry()object{'type': 'Polygon', 'coordinates...array({'type': 'Polygon', 'coordinates': [[[-180.0, -90.0], [180.0, -90.0], [180.0, 90.0], [-180.0, 90.0], [-180.0, -90.0]]]},\n      dtype=object)proj:code()&lt;U9'EPSG:4326'array('EPSG:4326', dtype='&lt;U9')title()&lt;U17'Default COG Layer'array('Default COG Layer', dtype='&lt;U17')proj:shape()object{1800, 3600}array({1800, 3600}, dtype=object)description()&lt;U47'Cloud optimized default layer t...array('Cloud optimized default layer to display on map', dtype='&lt;U47')epsg()int644326array(4326)time(time)datetime64[ns, UTC]2023-09-01T00:00:00+00:00 ... 20...&lt;DatetimeArray&gt;\n['2023-09-01 00:00:00+00:00', '2023-08-01 00:00:00+00:00',\n '2023-07-01 00:00:00+00:00', '2023-06-01 00:00:00+00:00',\n '2023-05-01 00:00:00+00:00', '2023-04-01 00:00:00+00:00',\n '2023-03-01 00:00:00+00:00', '2023-02-01 00:00:00+00:00',\n '2023-01-01 00:00:00+00:00', '2022-12-01 00:00:00+00:00',\n '2022-11-01 00:00:00+00:00', '2022-10-01 00:00:00+00:00',\n '2022-09-01 00:00:00+00:00', '2022-08-01 00:00:00+00:00',\n '2022-07-01 00:00:00+00:00', '2022-06-01 00:00:00+00:00',\n '2022-05-01 00:00:00+00:00', '2022-04-01 00:00:00+00:00',\n '2022-03-01 00:00:00+00:00', '2022-02-01 00:00:00+00:00',\n '2022-01-01 00:00:00+00:00', '2021-12-01 00:00:00+00:00',\n '2021-11-01 00:00:00+00:00', '2021-10-01 00:00:00+00:00',\n '2021-09-01 00:00:00+00:00', '2021-08-01 00:00:00+00:00',\n '2021-07-01 00:00:00+00:00', '2021-06-01 00:00:00+00:00',\n '2021-05-01 00:00:00+00:00', '2021-04-01 00:00:00+00:00',\n '2021-03-01 00:00:00+00:00', '2021-02-01 00:00:00+00:00',\n '2021-01-01 00:00:00+00:00', '2020-12-01 00:00:00+00:00',\n '2020-11-01 00:00:00+00:00', '2020-10-01 00:00:00+00:00',\n '2020-09-01 00:00:00+00:00', '2020-08-01 00:00:00+00:00',\n '2020-07-01 00:00:00+00:00', '2020-06-01 00:00:00+00:00',\n '2020-05-01 00:00:00+00:00', '2020-04-01 00:00:00+00:00',\n '2020-03-01 00:00:00+00:00', '2020-02-01 00:00:00+00:00',\n '2020-01-01 00:00:00+00:00', '2019-12-01 00:00:00+00:00',\n '2019-11-01 00:00:00+00:00', '2019-10-01 00:00:00+00:00',\n '2019-09-01 00:00:00+00:00', '2019-08-01 00:00:00+00:00',\n '2019-07-01 00:00:00+00:00', '2019-06-01 00:00:00+00:00',\n '2019-05-01 00:00:00+00:00', '2019-04-01 00:00:00+00:00',\n '2019-03-01 00:00:00+00:00', '2019-02-01 00:00:00+00:00',\n '2019-01-01 00:00:00+00:00', '2018-12-01 00:00:00+00:00',\n '2018-11-01 00:00:00+00:00', '2018-10-01 00:00:00+00:00',\n '2018-09-01 00:00:00+00:00', '2018-08-01 00:00:00+00:00',\n '2018-07-01 00:00:00+00:00', '2018-06-01 00:00:00+00:00',\n '2018-05-01 00:00:00+00:00', '2018-04-01 00:00:00+00:00',\n '2018-03-01 00:00:00+00:00', '2018-02-01 00:00:00+00:00',\n '2018-01-01 00:00:00+00:00', '2017-12-01 00:00:00+00:00',\n '2017-11-01 00:00:00+00:00', '2017-10-01 00:00:00+00:00',\n '2017-09-01 00:00:00+00:00', '2017-08-01 00:00:00+00:00',\n '2017-07-01 00:00:00+00:00', '2017-06-01 00:00:00+00:00',\n '2017-05-01 00:00:00+00:00', '2017-04-01 00:00:00+00:00',\n '2017-03-01 00:00:00+00:00', '2017-02-01 00:00:00+00:00',\n '2017-01-01 00:00:00+00:00', '2016-12-01 00:00:00+00:00',\n '2016-11-01 00:00:00+00:00', '2016-10-01 00:00:00+00:00',\n '2016-09-01 00:00:00+00:00', '2016-08-01 00:00:00+00:00',\n '2016-07-01 00:00:00+00:00', '2016-06-01 00:00:00+00:00',\n '2016-05-01 00:00:00+00:00', '2016-04-01 00:00:00+00:00',\n '2016-03-01 00:00:00+00:00', '2016-02-01 00:00:00+00:00',\n '2016-01-01 00:00:00+00:00']\nLength: 93, dtype: datetime64[ns, UTC]spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :73.65000000000002 0.09999999999999998 0.0 53.55 0.0 -0.09999999999999999array(0)Indexes: (3)xPandasIndexPandasIndex(Index([ 73.70000000000002,  73.80000000000001,               73.9,\n                     74.0,  74.10000000000002,  74.20000000000002,\n        74.30000000000001,               74.4,               74.5,\n        74.60000000000002,\n       ...\n       134.10000000000002, 134.20000000000005,              134.3,\n       134.40000000000003,              134.5, 134.60000000000002,\n       134.70000000000005,              134.8, 134.90000000000003,\n                    135.0],\n      dtype='float64', name='x', length=614))yPandasIndexPandasIndex(Index([              53.5,               53.4,               53.3,\n       53.199999999999996,               53.1,               53.0,\n                     52.9,               52.8, 52.699999999999996,\n                     52.6,\n       ...\n       19.099999999999994,               19.0,  18.89999999999999,\n       18.799999999999997, 18.700000000000003, 18.599999999999994,\n                     18.5,  18.39999999999999, 18.299999999999997,\n       18.200000000000003],\n      dtype='float64', name='y', length=354))timePandasIndexPandasIndex(DatetimeIndex(['2023-09-01 00:00:00+00:00', '2023-08-01 00:00:00+00:00',\n               '2023-07-01 00:00:00+00:00', '2023-06-01 00:00:00+00:00',\n               '2023-05-01 00:00:00+00:00', '2023-04-01 00:00:00+00:00',\n               '2023-03-01 00:00:00+00:00', '2023-02-01 00:00:00+00:00',\n               '2023-01-01 00:00:00+00:00', '2022-12-01 00:00:00+00:00',\n               '2022-11-01 00:00:00+00:00', '2022-10-01 00:00:00+00:00',\n               '2022-09-01 00:00:00+00:00', '2022-08-01 00:00:00+00:00',\n               '2022-07-01 00:00:00+00:00', '2022-06-01 00:00:00+00:00',\n               '2022-05-01 00:00:00+00:00', '2022-04-01 00:00:00+00:00',\n               '2022-03-01 00:00:00+00:00', '2022-02-01 00:00:00+00:00',\n               '2022-01-01 00:00:00+00:00', '2021-12-01 00:00:00+00:00',\n               '2021-11-01 00:00:00+00:00', '2021-10-01 00:00:00+00:00',\n               '2021-09-01 00:00:00+00:00', '2021-08-01 00:00:00+00:00',\n               '2021-07-01 00:00:00+00:00', '2021-06-01 00:00:00+00:00',\n               '2021-05-01 00:00:00+00:00', '2021-04-01 00:00:00+00:00',\n               '2021-03-01 00:00:00+00:00', '2021-02-01 00:00:00+00:00',\n               '2021-01-01 00:00:00+00:00', '2020-12-01 00:00:00+00:00',\n               '2020-11-01 00:00:00+00:00', '2020-10-01 00:00:00+00:00',\n               '2020-09-01 00:00:00+00:00', '2020-08-01 00:00:00+00:00',\n               '2020-07-01 00:00:00+00:00', '2020-06-01 00:00:00+00:00',\n               '2020-05-01 00:00:00+00:00', '2020-04-01 00:00:00+00:00',\n               '2020-03-01 00:00:00+00:00', '2020-02-01 00:00:00+00:00',\n               '2020-01-01 00:00:00+00:00', '2019-12-01 00:00:00+00:00',\n               '2019-11-01 00:00:00+00:00', '2019-10-01 00:00:00+00:00',\n               '2019-09-01 00:00:00+00:00', '2019-08-01 00:00:00+00:00',\n               '2019-07-01 00:00:00+00:00', '2019-06-01 00:00:00+00:00',\n               '2019-05-01 00:00:00+00:00', '2019-04-01 00:00:00+00:00',\n               '2019-03-01 00:00:00+00:00', '2019-02-01 00:00:00+00:00',\n               '2019-01-01 00:00:00+00:00', '2018-12-01 00:00:00+00:00',\n               '2018-11-01 00:00:00+00:00', '2018-10-01 00:00:00+00:00',\n               '2018-09-01 00:00:00+00:00', '2018-08-01 00:00:00+00:00',\n               '2018-07-01 00:00:00+00:00', '2018-06-01 00:00:00+00:00',\n               '2018-05-01 00:00:00+00:00', '2018-04-01 00:00:00+00:00',\n               '2018-03-01 00:00:00+00:00', '2018-02-01 00:00:00+00:00',\n               '2018-01-01 00:00:00+00:00', '2017-12-01 00:00:00+00:00',\n               '2017-11-01 00:00:00+00:00', '2017-10-01 00:00:00+00:00',\n               '2017-09-01 00:00:00+00:00', '2017-08-01 00:00:00+00:00',\n               '2017-07-01 00:00:00+00:00', '2017-06-01 00:00:00+00:00',\n               '2017-05-01 00:00:00+00:00', '2017-04-01 00:00:00+00:00',\n               '2017-03-01 00:00:00+00:00', '2017-02-01 00:00:00+00:00',\n               '2017-01-01 00:00:00+00:00', '2016-12-01 00:00:00+00:00',\n               '2016-11-01 00:00:00+00:00', '2016-10-01 00:00:00+00:00',\n               '2016-09-01 00:00:00+00:00', '2016-08-01 00:00:00+00:00',\n               '2016-07-01 00:00:00+00:00', '2016-06-01 00:00:00+00:00',\n               '2016-05-01 00:00:00+00:00', '2016-04-01 00:00:00+00:00',\n               '2016-03-01 00:00:00+00:00', '2016-02-01 00:00:00+00:00',\n               '2016-01-01 00:00:00+00:00'],\n              dtype='datetime64[ns, UTC]', name='time', freq=None))Attributes: (2)spec :RasterSpec(epsg=4326, bounds=(-180.0, -90.0, 180.0, 90.0), resolutions_xy=(0.1, 0.1))resolution :0.1"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#aggregate-the-data",
    "href": "user-guide/notebooks/quickstarts/timeseries-rioxarray-stackstac.html#aggregate-the-data",
    "title": "Calculate timeseries from COGs",
    "section": "Aggregate the data",
    "text": "Aggregate the data\nCalculate the mean at each time across regional data. Note this is the first time that the data is actually loaded.\n\nmeans = subset.mean(dim=(\"x\", \"y\")).compute()\n\nPlot the mean monthly NO2 using hvplot\n\nmeans.hvplot.line(x=\"time\", ylabel=\"NO2\", title=\"Mean Monthly NO2 in China\")"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/map-plot.html",
    "href": "user-guide/notebooks/quickstarts/map-plot.html",
    "title": "Visualizing Elevation Data",
    "section": "",
    "text": "Query the STAC API to retrieve an item from the TDM30 EDEM collection\nGenerate map tiles through the raster API endpoint\nRender the tiles on an interactive map with folium\n\n\nimport requests\nimport folium",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Visualizing Elevation Data"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/map-plot.html#workflow",
    "href": "user-guide/notebooks/quickstarts/map-plot.html#workflow",
    "title": "Visualizing Elevation Data",
    "section": "",
    "text": "Query the STAC API to retrieve an item from the TDM30 EDEM collection\nGenerate map tiles through the raster API endpoint\nRender the tiles on an interactive map with folium\n\n\nimport requests\nimport folium",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Visualizing Elevation Data"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/map-plot.html#configure-api-endpoints",
    "href": "user-guide/notebooks/quickstarts/map-plot.html#configure-api-endpoints",
    "title": "Visualizing Elevation Data",
    "section": "Configure API Endpoints",
    "text": "Configure API Endpoints\nDiscover available datasets through:\n\nProgrammatically: See the list-collections.ipynb notebook\nJSON API: https://api.dev.veda.grss.cloud/stac/collections\n\n\nSTAC_API_URL = \"https://api.dev.veda.grss.cloud/stac\"\nRASTER_API_URL = \"https://api.dev.veda.grss.cloud/raster\"\n\ncollection_id = \"TDM30_EDEM\"",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Visualizing Elevation Data"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/map-plot.html#retrieve-collection-metadata",
    "href": "user-guide/notebooks/quickstarts/map-plot.html#retrieve-collection-metadata",
    "title": "Visualizing Elevation Data",
    "section": "Retrieve Collection Metadata",
    "text": "Retrieve Collection Metadata\nFetch the collection details to understand the available data and its properties.\n\nresponse = requests.get(f\"{STAC_API_URL}/collections/{collection_id}\")\nassert response.ok, response.text\n\ncollection = response.json()\ncollection\n\n{'id': 'TDM30_EDEM',\n 'type': 'Collection',\n 'links': [{'rel': 'items',\n   'type': 'application/geo+json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/TDM30_EDEM/items'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/'},\n  {'rel': 'self',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/TDM30_EDEM'},\n  {'rel': 'items',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/TDM30_EDEM/items',\n   'type': 'application/geo+json'},\n  {'rel': 'http://www.opengis.net/def/rel/ogc/1.0/queryables',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/TDM30_EDEM/queryables',\n   'type': 'application/schema+json',\n   'title': 'Queryables'},\n  {'rel': 'license',\n   'href': 'https://geoservice.dlr.de/resources/licenses/tdm30-edited/License_for_the_Utilization_of_TanDEM-X_30m-EDEM_DCM_for_Scientific_Use.pdf',\n   'type': 'application/pdf',\n   'title': 'License for the Utilization of TanDEM-X 30m DEM for Scientific Use'},\n  {'rel': 'cite-as',\n   'href': 'https://doi.org/10.3390/rs12233961',\n   'title': 'A Fully Automatic Algorithm for Editing the TanDEM-X Global DEM'},\n  {'rel': 'about',\n   'href': 'https://geoservice.dlr.de/web/dataguide/tdm30/',\n   'type': 'text/html',\n   'title': 'TanDEM-X 30m EDEM Data Guide'},\n  {'rel': 'http://www.opengis.net/def/rel/ogc/1.0/queryables',\n   'type': 'application/schema+json',\n   'title': 'Queryables',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/TDM30_EDEM/queryables'}],\n 'title': 'TanDEM-X - Edited Digital Elevation Model (EDEM) - Global, 30m',\n 'assets': {},\n 'extent': {'spatial': {'bbox': [[-11.000208333333333,\n     34.999861111111116,\n     19.00013888888889,\n     63.00013888888889]]},\n  'temporal': {'interval': [['2010-01-01 00:00:00+00',\n     '2014-12-31 23:59:59+00']]}},\n 'license': 'proprietary',\n 'renders': {'dem': {'assets': ['dem'],\n   'rescale': [[-500, 8000]],\n   'colormap_name': 'terrain'},\n  'dashboard': {'assets': ['dem'],\n   'rescale': [[-500, 8000]],\n   'colormap_name': 'terrain'}},\n 'sci:doi': '10.3390/rs12233961',\n 'keywords': ['TanDEM-X',\n  'DEM',\n  'EDEM',\n  'Digital Elevation Model',\n  'Digital Surface Model',\n  'DSM',\n  'Topography',\n  'SAR Interferometry',\n  'InSAR',\n  'Elevation',\n  'Global',\n  '30m',\n  'X-band',\n  'Radar'],\n 'providers': [{'url': 'https://www.dlr.de',\n   'name': 'German Aerospace Center (DLR)',\n   'roles': ['producer', 'processor', 'licensor'],\n   'description': 'The TanDEM-X mission is realized in a public-private partnership between DLR and Airbus Defence and Space.'},\n  {'url': 'https://www.airbus.com',\n   'name': 'Airbus Defence and Space',\n   'roles': ['producer'],\n   'description': 'Commercial partner for the TanDEM-X mission'},\n  {'url': 'https://geoservice.dlr.de',\n   'name': 'EOC Geoservice',\n   'roles': ['host'],\n   'description': 'DLR Earth Observation Center Geoservice for data distribution'}],\n 'summaries': {'datetime': ['2010-01-01T00:00:00Z']},\n 'description': \"The TanDEM-X 30m Edited Digital Elevation Model (EDEM) is a global Digital Elevation Model (DEM) with 1 arcsecond (~30m) pixel spacing, acquired by the German TanDEM-X mission between 2010 and 2014. It covers approximately 150 million square kilometers of all Earth's landmasses from pole to pole. The EDEM is an edited version of the TanDEM-X Global DEM, processed with a fully automatic algorithm to fill data gaps and remove artifacts using auxiliary elevation data from AW3D30, NASADEM, LiDAR, REMA DEM, and Arctic DEM. The product represents a Digital Surface Model (DSM) showing radar-reflective surfaces. The data has an absolute vertical accuracy of approximately 1 meter and horizontal accuracy (CE90) below 10 meters. The vertical datum is WGS84-G1150 ellipsoid (EPSG:4979) and EGM2008 geoid (EPSG:3855). This dataset serves as a reference for topographical analysis and change detection applications.\",\n 'item_assets': {'dem': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': 'Digital Elevation Model',\n   'description': 'Cloud optimized GeoTIFF containing elevation data in meters'}},\n 'sci:citation': 'C. Gonzlez, M. Bachmann, J.L. Bueso-Bello, P. Rizzoli, M. Zink. A Fully Automatic Algorithm for Editing the TanDEM-X Global DEM. Remote Sensing. 2020; 12(23):3961.',\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/render/v1.0.0/schema.json',\n  'https://stac-extensions.github.io/item-assets/v1.0.0/schema.json'],\n 'dashboard:is_periodic': False,\n 'dashboard:time_density': 'year'}",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Visualizing Elevation Data"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/map-plot.html#query-for-a-specific-item",
    "href": "user-guide/notebooks/quickstarts/map-plot.html#query-for-a-specific-item",
    "title": "Visualizing Elevation Data",
    "section": "Query for a Specific Item",
    "text": "Query for a Specific Item\nUse the STAC search endpoint to find items within the collection. For digital elevation models, we typically query by spatial extent.\n\n# Query items from the collection\nresponse = requests.get(\n    f\"{STAC_API_URL}/collections/{collection_id}/items\",\n    params={\"limit\": 10}\n)\n\nassert response.ok, response.text\n\nitems = response.json()[\"features\"]\nprint(f\"Found {len(items)} items\")\n\nFound 10 items\n\n\nExamine the structure of an item to understand the available assets:\n\nitem = items[0]\nitem\n\n{'id': 'TDM1_EDEM_10_N62W008_EDEM_W84_cog',\n 'bbox': [-8.000277777777777,\n  61.999861111111116,\n  -5.999722222222221,\n  63.00013888888889],\n 'type': 'Feature',\n 'links': [{'rel': 'collection',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/TDM30_EDEM'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/TDM30_EDEM'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/'},\n  {'rel': 'self',\n   'type': 'application/geo+json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/TDM30_EDEM/items/TDM1_EDEM_10_N62W008_EDEM_W84_cog'},\n  {'title': 'Map of Item',\n   'href': 'https://api.dev.veda.grss.cloud/raster/collections/TDM30_EDEM/items/TDM1_EDEM_10_N62W008_EDEM_W84_cog/WebMercatorQuad/map?assets=dem&rescale=-500%2C8000&colormap_name=terrain',\n   'rel': 'preview',\n   'type': 'text/html'}],\n 'assets': {'dem': {'href': 's3://ieee-grss-data-store/tandemx-30m-edem/cog/TDM1_EDEM_10_N62W008_EDEM_W84_cog.tif',\n   'type': 'image/tiff; application=geotiff',\n   'roles': ['data', 'layer'],\n   'title': 'Digital Elevation Model',\n   'proj:bbox': [-8.000277777777777,\n    61.999861111111116,\n    -5.999722222222221,\n    63.00013888888889],\n   'proj:epsg': 4326,\n   'proj:shape': [3601, 3601],\n   'description': 'Cloud optimized GeoTIFF containing elevation data in meters',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -32767.0,\n     'offset': 0.0,\n     'sampling': 'point',\n     'data_type': 'float32',\n     'histogram': {'max': 881.67578125,\n      'min': -224.88092041015625,\n      'count': 11,\n      'buckets': [10,\n       65,\n       962838,\n       20710,\n       21580,\n       20475,\n       14090,\n       6601,\n       1894,\n       313]},\n     'statistics': {'mean': 81.1307144165039,\n      'stddev': 89.53138942668164,\n      'maximum': 881.67578125,\n      'minimum': -224.88092041015625,\n      'valid_percent': 100.0}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-8.000277777777777, 61.999861111111116],\n      [-5.999722222222221, 61.999861111111116],\n      [-5.999722222222221, 63.00013888888889],\n      [-8.000277777777777, 63.00013888888889],\n      [-8.000277777777777, 61.999861111111116]]]},\n   'proj:transform': [0.0005555555555555556,\n    0.0,\n    -8.000277777777777,\n    0.0,\n    -0.0002777777777777778,\n    63.00013888888889,\n    0.0,\n    0.0,\n    1.0]},\n  'rendered_preview': {'title': 'Rendered preview',\n   'href': 'https://api.dev.veda.grss.cloud/raster/collections/TDM30_EDEM/items/TDM1_EDEM_10_N62W008_EDEM_W84_cog/preview.png?assets=dem&rescale=-500%2C8000&colormap_name=terrain',\n   'rel': 'preview',\n   'roles': ['overview'],\n   'type': 'image/png'}},\n 'geometry': {'type': 'Polygon',\n  'coordinates': [[[-8.000277777777777, 61.999861111111116],\n    [-5.999722222222221, 61.999861111111116],\n    [-5.999722222222221, 63.00013888888889],\n    [-8.000277777777777, 63.00013888888889],\n    [-8.000277777777777, 61.999861111111116]]]},\n 'collection': 'TDM30_EDEM',\n 'properties': {'end_datetime': '2014-12-31T23:59:59Z',\n  'start_datetime': '2010-01-01T00:00:00Z'},\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/raster/v1.1.0/schema.json',\n  'https://stac-extensions.github.io/projection/v1.1.0/schema.json']}",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Visualizing Elevation Data"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/map-plot.html#determine-visualization-parameters",
    "href": "user-guide/notebooks/quickstarts/map-plot.html#determine-visualization-parameters",
    "title": "Visualizing Elevation Data",
    "section": "Determine Visualization Parameters",
    "text": "Determine Visualization Parameters\nExtract statistics from the item to set appropriate rescale values for rendering.\n\n# Get the primary asset key\nasset_keys = list(item['assets'].keys())\nprint(f\"Available assets: {asset_keys}\")\n\n# Select the data asset (exclude metadata assets like 'rendered_preview')\ndata_asset = [k for k in asset_keys if k not in ['rendered_preview']][0]\nprint(f\"Using asset: {data_asset}\")\n\nAvailable assets: ['dem', 'rendered_preview']\nUsing asset: dem\n\n\n\n# Set elevation rescale values (typical range for terrain)\nrescale_values = (0, 3000)",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Visualizing Elevation Data"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/map-plot.html#generate-map-tiles",
    "href": "user-guide/notebooks/quickstarts/map-plot.html#generate-map-tiles",
    "title": "Visualizing Elevation Data",
    "section": "Generate Map Tiles",
    "text": "Generate Map Tiles\nRequest tile metadata from the raster API to visualize the elevation data.\n\ntile_matrix_set_id = \"WebMercatorQuad\"\ncolormap_name = \"terrain\"\n\nresponse = requests.get(\n    f\"{RASTER_API_URL}/collections/{collection_id}/items/{item['id']}/{tile_matrix_set_id}/tilejson.json\",\n    params={\n        \"assets\": data_asset,\n        \"colormap_name\": colormap_name,\n        \"rescale\": f\"{rescale_values[0]},{rescale_values[1]}\"\n    }\n)\n\nassert response.ok, response.text\n\ntiles = response.json()\ntiles\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://api.dev.veda.grss.cloud/raster/collections/TDM30_EDEM/items/TDM1_EDEM_10_N62W008_EDEM_W84_cog/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?assets=dem&colormap_name=terrain&rescale=0%2C3000'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-8.000277777777777,\n  61.999861111111116,\n  -5.999722222222221,\n  63.00013888888889],\n 'center': [-6.999999999999999, 62.5, 0]}",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Visualizing Elevation Data"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/map-plot.html#display-the-elevation-map",
    "href": "user-guide/notebooks/quickstarts/map-plot.html#display-the-elevation-map",
    "title": "Visualizing Elevation Data",
    "section": "Display the Elevation Map",
    "text": "Display the Elevation Map\nCreate an interactive map using folium to visualize the terrain data.\n\n# Calculate center from item bounds\nbbox = item['bbox']\ncenter_lat = (bbox[1] + bbox[3]) / 2\ncenter_lon = (bbox[0] + bbox[2]) / 2\n\nm = folium.Map(\n    location=[center_lat, center_lon],\n    zoom_start=8,\n    tiles=\"CartoDB positron\"\n)\n\nfolium.TileLayer(\n    tiles=tiles[\"tiles\"][0],\n    attr=\"GRSS VEDA\",\n    opacity=0.7,\n    overlay=True,\n    name=\"Elevation\"\n).add_to(m)\n\nfolium.LayerControl().add_to(m)\n\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Visualizing Elevation Data"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html",
    "title": "Population Density Time Series Analysis",
    "section": "",
    "text": "Retrieve STAC items for the population density collection and define an area of interest\nCompute statistics for each time step using the /statistics endpoint\nVisualize the resulting time series\nAccelerate processing with parallel computation using Dask\n\nThe statistics endpoint is provided by the VEDA titiler implementation, which enables dynamic tile generation and data aggregation. While the API is publicly accessible, the underlying data may require authentication. The body of any request must remain under 16Kb, which can be limiting for complex geometries.\n\nimport json\nimport sys\nimport requests\nimport folium\nimport shapely\n\nimport pandas as pd\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Population Density Time Series Analysis"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#workflow",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#workflow",
    "title": "Population Density Time Series Analysis",
    "section": "",
    "text": "Retrieve STAC items for the population density collection and define an area of interest\nCompute statistics for each time step using the /statistics endpoint\nVisualize the resulting time series\nAccelerate processing with parallel computation using Dask\n\nThe statistics endpoint is provided by the VEDA titiler implementation, which enables dynamic tile generation and data aggregation. While the API is publicly accessible, the underlying data may require authentication. The body of any request must remain under 16Kb, which can be limiting for complex geometries.\n\nimport json\nimport sys\nimport requests\nimport folium\nimport shapely\n\nimport pandas as pd\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Population Density Time Series Analysis"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#configure-the-data-collection",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#configure-the-data-collection",
    "title": "Population Density Time Series Analysis",
    "section": "Configure the Data Collection",
    "text": "Configure the Data Collection\nExplore available datasets through:\n\nProgrammatically: See list-collections.ipynb\nJSON API: https://api.dev.veda.grss.cloud/stac/collections\n\n\nSTAC_API_URL = \"https://api.dev.veda.grss.cloud/stac\"\nRASTER_API_URL = \"https://api.dev.veda.grss.cloud/raster\"\n\ncollection_id = \"sedac-popdensity-yeargrid5yr-v4.11\"",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Population Density Time Series Analysis"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#fetch-collection-metadata",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#fetch-collection-metadata",
    "title": "Population Density Time Series Analysis",
    "section": "Fetch Collection Metadata",
    "text": "Fetch Collection Metadata\nRetrieve details about the population density collection including temporal extent and data format.\n\nresponse = requests.get(f\"{STAC_API_URL}/collections/{collection_id}\")\nassert response.ok, response.text\n\ncollection = response.json()\ncollection\n\n{'id': 'sedac-popdensity-yeargrid5yr-v4.11',\n 'type': 'Collection',\n 'links': [{'rel': 'items',\n   'type': 'application/geo+json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/sedac-popdensity-yeargrid5yr-v4.11/items'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/'},\n  {'rel': 'self',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/sedac-popdensity-yeargrid5yr-v4.11'},\n  {'rel': 'http://www.opengis.net/def/rel/ogc/1.0/queryables',\n   'type': 'application/schema+json',\n   'title': 'Queryables',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/sedac-popdensity-yeargrid5yr-v4.11/queryables'}],\n 'title': 'SEDAC Gridded World Population Density v4.11',\n 'assets': {},\n 'extent': {'spatial': {'bbox': [[-180,\n     -90,\n     179.99999999999983,\n     89.99999999999991]]},\n  'temporal': {'interval': [['2000-01-01 00:00:00+00',\n     '2020-01-01 00:00:00+00']]}},\n 'license': 'CC-BY-4.0',\n 'renders': {'dashboard': {'assets': ['population-density'],\n   'rescale': [[0, 1000]],\n   'colormap_name': 'ylorrd'},\n  'population-density': {'assets': ['population-density'],\n   'rescale': [[0, 1000]],\n   'colormap_name': 'ylorrd'}},\n 'providers': [],\n 'summaries': {'datetime': ['2000-01-01T00:00:00Z',\n   '2005-01-01T00:00:00Z',\n   '2010-01-01T00:00:00Z',\n   '2015-01-01T00:00:00Z',\n   '2020-01-01T00:00:00Z']},\n 'description': 'The Socioeconomic Data and Applications Center (SEDAC) Gridded Population of the World (GPW), version 4, revision 11 dataset contains a Population Density product that provides estimates of population density (number of persons per square kilometer (persons/km)) at five year intervals for the years 2000, 2005, 2010, 2015, and 2020 on a 30 arc-second (~1 km at the equator) grid. The dataset can be used for assessing disaster impacts, risk mapping, and any other applications that include a human dimension. The source dataset can be found at https://doi.org/10.7927/H49C6VHW',\n 'item_assets': {'cog_default': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': 'Default COG Layer',\n   'description': 'Cloud optimized default layer to display on map'}},\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/render/v1.0.0/schema.json',\n  'https://stac-extensions.github.io/item-assets/v1.0.0/schema.json']}\n\n\n\nExamine Temporal Properties\nCheck the periodic nature and temporal coverage of the dataset.\n\nprint(f\"Periodic data: {collection.get('dashboard:is_periodic', 'N/A')}\")\nprint(f\"Time density: {collection.get('dashboard:time_density', 'N/A')}\")\nprint(f\"Temporal range: {collection.get('summaries', {}).get('datetime', 'N/A')}\")\n\nPeriodic data: N/A\nTime density: N/A\nTemporal range: ['2000-01-01T00:00:00Z', '2005-01-01T00:00:00Z', '2010-01-01T00:00:00Z', '2015-01-01T00:00:00Z', '2020-01-01T00:00:00Z']",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Population Density Time Series Analysis"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#retrieve-available-items",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#retrieve-available-items",
    "title": "Population Density Time Series Analysis",
    "section": "Retrieve Available Items",
    "text": "Retrieve Available Items\nQuery all STAC items within the collection.\n\nresponse = requests.get(\n    f\"{STAC_API_URL}/collections/{collection_id}/items\",\n    params={\"limit\": 100}\n)\nassert response.ok, response.text\n\nitems = response.json()[\"features\"]\nprint(f\"Retrieved {len(items)} items\")\n\nRetrieved 5 items\n\n\nInspect the structure of a single item:\n\nitems[0]\n\n{'id': 'sedac-popdensity-yeargrid5yr-v4.11-gpw_v4_population_density_rev11_2020_30_sec_2020',\n 'bbox': [-180.0, -90.0, 179.99999999999983, 89.99999999999991],\n 'type': 'Feature',\n 'links': [{'rel': 'collection',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/sedac-popdensity-yeargrid5yr-v4.11'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/sedac-popdensity-yeargrid5yr-v4.11'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/'},\n  {'rel': 'self',\n   'type': 'application/geo+json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/sedac-popdensity-yeargrid5yr-v4.11/items/sedac-popdensity-yeargrid5yr-v4.11-gpw_v4_population_density_rev11_2020_30_sec_2020'},\n  {'title': 'Map of Item',\n   'href': 'https://api.dev.veda.grss.cloud/raster/collections/sedac-popdensity-yeargrid5yr-v4.11/items/sedac-popdensity-yeargrid5yr-v4.11-gpw_v4_population_density_rev11_2020_30_sec_2020/WebMercatorQuad/map?assets=population-density&rescale=0%2C1000&colormap_name=ylorrd',\n   'rel': 'preview',\n   'type': 'text/html'}],\n 'assets': {'population-density': {'href': 's3://ieee-grss-data-store/sedac-population-density/gpw_v4_population_density_rev11_2020_30_sec_2020.tif',\n   'type': 'image/tiff; application=geotiff',\n   'roles': ['data', 'layer'],\n   'title': 'Population Density',\n   'proj:bbox': [-180.0, -90.0, 179.99999999999983, 89.99999999999991],\n   'proj:epsg': 4326,\n   'proj:shape': [21600, 43200],\n   'description': 'Gridded population density estimates for the years 2000, 2005, 2010, 2015, and 2020 from Gridded Population of the World (GPW) version 4, revision 11.',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -9999.0,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 30795.859375,\n      'min': -1505.7174072265625,\n      'count': 11,\n      'buckets': [129008, 362, 52, 22, 7, 2, 2, 0, 1, 1]},\n     'statistics': {'mean': 55.30964721876762,\n      'stddev': 319.5376065398882,\n      'maximum': 30795.859375,\n      'minimum': -1505.7174072265625,\n      'valid_percent': 24.69196319580078}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [179.99999999999983, -90.0],\n      [179.99999999999983, 89.99999999999991],\n      [-180.0, 89.99999999999991],\n      [-180.0, -90.0]]]},\n   'proj:transform': [0.00833333333333333,\n    0.0,\n    -180.0,\n    0.0,\n    -0.00833333333333333,\n    89.99999999999991,\n    0.0,\n    0.0,\n    1.0]},\n  'rendered_preview': {'title': 'Rendered preview',\n   'href': 'https://api.dev.veda.grss.cloud/raster/collections/sedac-popdensity-yeargrid5yr-v4.11/items/sedac-popdensity-yeargrid5yr-v4.11-gpw_v4_population_density_rev11_2020_30_sec_2020/preview.png?assets=population-density&rescale=0%2C1000&colormap_name=ylorrd',\n   'rel': 'preview',\n   'roles': ['overview'],\n   'type': 'image/png'}},\n 'geometry': {'type': 'Polygon',\n  'coordinates': [[[-180, -90],\n    [179.99999999999983, -90],\n    [179.99999999999983, 89.99999999999991],\n    [-180, 89.99999999999991],\n    [-180, -90]]]},\n 'collection': 'sedac-popdensity-yeargrid5yr-v4.11',\n 'properties': {'end_datetime': '2020-01-01T00:00:00Z',\n  'start_datetime': '2020-01-01T00:00:00Z'},\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/raster/v1.1.0/schema.json',\n  'https://stac-extensions.github.io/projection/v1.1.0/schema.json']}",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Population Density Time Series Analysis"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#define-area-of-interest",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#define-area-of-interest",
    "title": "Population Density Time Series Analysis",
    "section": "Define Area of Interest",
    "text": "Define Area of Interest\nCreate a bounding box covering the Indian subcontinent for population density analysis.\n\nindia_bbox = {\n    \"type\": \"Feature\",\n    \"properties\": {\"name\": \"Indian Subcontinent\"},\n    \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n            [\n                [68.0, 8.0],\n                [97.5, 8.0],\n                [97.5, 35.5],\n                [68.0, 35.5],\n                [68.0, 8.0],\n            ]\n        ],\n    },\n}\n\n\nm = folium.Map(\n    location=[22, 82],\n    zoom_start=4,\n)\n\nfolium.GeoJson(india_bbox, name=\"Study Area\").add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Population Density Time Series Analysis"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#calculate-zonal-statistics",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#calculate-zonal-statistics",
    "title": "Population Density Time Series Analysis",
    "section": "Calculate Zonal Statistics",
    "text": "Calculate Zonal Statistics\nDefine a function to compute statistics for each item within the AOI.\n\ndef compute_stats(item, geojson):\n    \"\"\"Compute zonal statistics for a STAC item over a GeoJSON feature.\"\"\"\n    response = requests.post(\n        f\"{RASTER_API_URL}/collections/{collection_id}/items/{item['id']}/statistics\",\n        json=geojson\n    )\n    assert response.ok, response.text\n    \n    result = response.json()\n    # Get the first asset's statistics\n    stats_key = list(result[\"properties\"][\"statistics\"].keys())[0]\n    \n    return {\n        **result[\"properties\"][\"statistics\"][stats_key],\n        \"datetime\": item[\"properties\"].get(\"datetime\") or item[\"properties\"].get(\"start_datetime\"),\n    }\n\nTest the function on a single item:\n\n%%time\ncompute_stats(items[0], india_bbox)\n\nCPU times: user 14.8 ms, sys: 5.15 ms, total: 19.9 ms\nWall time: 6.89 s\n\n\n{'min': 0.0,\n 'max': 183500.984375,\n 'mean': 319.87804557101936,\n 'count': 7634679.0,\n 'sum': 2442166197.0821047,\n 'std': 994.8761041031477,\n 'median': 134.92578125,\n 'majority': 0.0,\n 'minority': 1.2108720284231822e-06,\n 'unique': 832856.0,\n 'histogram': [[7630975, 3033, 339, 201, 93, 22, 8, 6, 0, 2],\n  [0.0,\n   18350.09765625,\n   36700.1953125,\n   55050.29296875,\n   73400.390625,\n   91750.484375,\n   110100.5859375,\n   128450.6875,\n   146800.78125,\n   165150.875,\n   183500.984375]],\n 'valid_percent': 65.32,\n 'masked_pixels': 4054162.0,\n 'valid_pixels': 7634679.0,\n 'percentile_2': 0.0,\n 'percentile_98': 1676.1239013671875,\n 'datetime': '2020-01-01T00:00:00Z'}\n\n\n\nProcess All Items\nGather statistics across the full temporal range.\n\n%%time\nstats = [compute_stats(item, india_bbox) for item in items]\n\nCPU times: user 108 ms, sys: 19.6 ms, total: 128 ms\nWall time: 33.1 s",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Population Density Time Series Analysis"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#visualize-results",
    "href": "user-guide/notebooks/quickstarts/timeseries-stac-api.html#visualize-results",
    "title": "Population Density Time Series Analysis",
    "section": "Visualize Results",
    "text": "Visualize Results\nConvert statistics to a pandas DataFrame for easier manipulation.\n\ndf = pd.DataFrame(stats)\ndf[\"date\"] = pd.to_datetime(df[\"datetime\"])\ndf = df.sort_values(\"date\")\ndf.head()\n\n\n\n\n\n\n\n\nmin\nmax\nmean\ncount\nsum\nstd\nmedian\nmajority\nminority\nunique\nhistogram\nvalid_percent\nmasked_pixels\nvalid_pixels\npercentile_2\npercentile_98\ndatetime\ndate\n\n\n\n\n4\n0.0\n91639.554688\n229.666597\n7634679.0\n1.753431e+09\n676.066884\n106.107010\n0.0\n0.000001\n832535.0\n[[7629171, 3259, 1697, 201, 69, 249, 15, 13, 3...\n65.32\n4054162.0\n7634679.0\n0.0\n1207.834595\n2000-01-01T00:00:00Z\n2000-01-01 00:00:00+00:00\n\n\n3\n0.0\n109011.375000\n247.572055\n7634679.0\n1.890133e+09\n726.471006\n113.783066\n0.0\n0.000001\n832324.0\n[[7630026, 2851, 1305, 175, 190, 104, 15, 11, ...\n65.32\n4054162.0\n7634679.0\n0.0\n1292.039673\n2005-01-01T00:00:00Z\n2005-01-01 00:00:00+00:00\n\n\n2\n0.0\n129676.320312\n268.397970\n7634679.0\n2.049132e+09\n790.871804\n120.475212\n0.0\n0.000001\n832717.0\n[[7630408, 3504, 321, 269, 130, 23, 16, 6, 0, ...\n65.32\n4054162.0\n7634679.0\n0.0\n1402.566040\n2010-01-01T00:00:00Z\n2010-01-01 00:00:00+00:00\n\n\n1\n0.0\n154258.656250\n292.296563\n7634679.0\n2.231590e+09\n873.666032\n127.544792\n0.0\n0.000001\n832952.0\n[[7630644, 3348, 430, 100, 116, 21, 12, 6, 0, ...\n65.32\n4054162.0\n7634679.0\n0.0\n1535.461792\n2015-01-01T00:00:00Z\n2015-01-01 00:00:00+00:00\n\n\n0\n0.0\n183500.984375\n319.878046\n7634679.0\n2.442166e+09\n994.876104\n134.925781\n0.0\n0.000001\n832856.0\n[[7630975, 3033, 339, 201, 93, 22, 8, 6, 0, 2]...\n65.32\n4054162.0\n7634679.0\n0.0\n1676.123901\n2020-01-01T00:00:00Z\n2020-01-01 00:00:00+00:00\n\n\n\n\n\n\n\n\nPlot the Time Series\n\nfig = plt.figure(figsize=(14, 7))\n\nplt.plot(\n    df[\"date\"],\n    df[\"mean\"],\n    color=\"darkblue\",\n    marker=\"o\",\n    linewidth=2,\n    label=\"Mean population density\"\n)\n\nplt.fill_between(\n    df[\"date\"],\n    df[\"mean\"] + df[\"std\"],\n    df[\"mean\"] - df[\"std\"],\n    alpha=0.2,\n    color=\"blue\",\n    label=\"+/- 1 standard deviation\"\n)\n\nplt.xlabel(\"Year\")\nplt.ylabel(\"Population Density (persons/km)\")\nplt.title(\"Population Density Trends - Indian Subcontinent\")\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\n\n\n\n\n\n\n\n\nThe time series reveals population growth patterns across the region over the available data period.",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Using the Raster API",
      "Population Density Time Series Analysis"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GRSS VEDA Docs",
    "section": "",
    "text": "IEEE GRSS has deployed VEDA (Developed by NASAs Earth Science Data Systems (ESDS) Program) as a platform for the GRSS community to share and access data, stories, and example code for geospatial data analysis and visualization.\nVEDA (Visualization, Exploration and Data Analysis) is a redeployable data platform to support scientific visualization and analysis.\nBy combining interactive storytelling with open science principles, VEDA enables researchers to engage new audiences and share their analysis results effectively.\nThese docs help you use the services provided by the NASA VEDA Platform and learn about the open-source software ecosystem that it is based on.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "GRSS VEDA Docs",
    "section": "",
    "text": "IEEE GRSS has deployed VEDA (Developed by NASAs Earth Science Data Systems (ESDS) Program) as a platform for the GRSS community to share and access data, stories, and example code for geospatial data analysis and visualization.\nVEDA (Visualization, Exploration and Data Analysis) is a redeployable data platform to support scientific visualization and analysis.\nBy combining interactive storytelling with open science principles, VEDA enables researchers to engage new audiences and share their analysis results effectively.\nThese docs help you use the services provided by the NASA VEDA Platform and learn about the open-source software ecosystem that it is based on.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#checkout-the-notebooks",
    "href": "index.html#checkout-the-notebooks",
    "title": "GRSS VEDA Docs",
    "section": "Checkout the notebooks",
    "text": "Checkout the notebooks\n\nDatasets\n\nWetland Methane Emissions, LPJ-EOSIM Model\n\n\n\nQuickstart guides\n\nGetting Started with VEDA\nMap plot\nTimeseries analysis",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#new-to-veda",
    "href": "index.html#new-to-veda",
    "title": "GRSS VEDA Docs",
    "section": "New to VEDA?",
    "text": "New to VEDA?\nLearn more about VEDA from its documentation at docs.openveda.cloud.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html",
    "title": "Open and plot COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#run-this-notebook",
    "title": "Open and plot COGs",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#approach",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#approach",
    "title": "Open and plot COGs",
    "section": "Approach",
    "text": "Approach\n\nUse pystac_client to open the STAC catalog and retrieve the items in the collection\nOpen the collection with xarray and stackstac\nPlot the data using hvplot"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#about-the-data",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#about-the-data",
    "title": "Open and plot COGs",
    "section": "About the data",
    "text": "About the data\nCDCs Social Vulnerability Index (SVI) uses 15 variables at the census tract level. The data comes from the U.S. decennial census for the years 2000 & 2010, and the American Community Survey (ACS) for the years 2014, 2016, and 2018. It is a hierarchical additive index (Tate, 2013), with the component elements of CDCs SVI including the following for 4 themes: Socioeconomic Status, Household Composition & Disability, Minority Status & Language, and Housing Type & Transportation.\nSVI indicates the relative vulnerability of every U.S. Census tractsubdivisions of counties for which the Census collects statistical data. SVI ranks the tracts on 15 social factors, including unemployment, minority status, and disability, and further groups them into four related themes. Thus, each tract receives a ranking for each Census variable and for each of the four themes, as well as an overall ranking.\n\nScientific research\nThe SVI Overall Score provides the overall, summed social vulnerability score for a given tract. The Overall Score SVI Grid is part of the U.S. Census Grids collection, and displays the Center for Disease Control & Prevention (CDC) SVI score. Funding for the final development, processing and dissemination of this data set by the Socioeconomic Data and Applications Center (SEDAC) was provided under the U.S. National Aeronautics and Space Administration (NASA).\nThe Overall SVI Score describes the vulnerability in a given county tract based on the combined percentile ranking of the four SVI scores (Socioeconomic Status, Household Composition & Disability, Minority Status & Language, and Housing Type & Transportation). The summed percentile ranking from the four themes is ordered, and then used to calculate an overall percentile ranking, ranging from 0 (less vulnerable) to 1 (more vulnerable). Tracts with higher Overall SVI Scores typically rank high in other SVI domains, and reveal communities that may require extra support, resources, and preventative care in order to better prepare for and manage emergency situations.\n\n\nInterpreting the data\nThe Overall SVI Score describes the vulnerability in a given county tract based on the combined percentile ranking of the four SVI scores (Socioeconomic Status, Household Composition & Disability, Minority Status & Language, and Housing Type & Transportation). The summed percentile ranking from the four themes is ordered, and then used to calculate an overall percentile ranking, ranging from 0 (less vulnerable) to 1 (more vulnerable). Tracts with higher Overall SVI Scores typically rank high in other SVI domains, and reveal communities that may require extra support, resources, and preventative care in order to better prepare for and manage emergency situations.\n\n\nCredits\n\nCenter for International Earth Science Information Network, (CIESIN), Columbia University. 2021. Documentation for the U.S. Social Vulnerability Index Grids. Palisades, NY: NASA Socioeconomic Data and Applications Center (SEDAC). https://doi.org/10.7927/fjr9-a973. Accessed 13 May 2022.\nCenters for Disease Control and Prevention/ Agency for Toxic Substances and Disease Registry/ Geospatial Research, Analysis, and Services Program. CDC/ATSDR Social Vulnerability Index Database. https://www.atsdr.cdc.gov/placeandhealth/svi/documentation/pdf/SVI2018Documentation_01192022_1.pdf\n\n\nfrom pystac_client import Client\nimport stackstac\n\nimport hvplot.xarray  # noqa"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#declare-your-collection-of-interest",
    "title": "Open and plot COGs",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac/\"\ncollection = \"social-vulnerability-index-overall-nopop\""
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#find-items-in-collection",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#find-items-in-collection",
    "title": "Open and plot COGs",
    "section": "Find items in collection",
    "text": "Find items in collection\nUse pystac_client to search the STAC collection.\n\ncatalog = Client.open(STAC_API_URL)\nsearch = catalog.search(collections=[collection])\n\nitem_collection = search.item_collection()\nprint(f\"Found {len(item_collection)} items\")\n\nFound 5 items"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#read-data",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#read-data",
    "title": "Open and plot COGs",
    "section": "Read data",
    "text": "Read data\nRead in data using xarray using a combination of xpystac, stackstac, and rasterio.\n\n%%time\nda = stackstac.stack(item_collection, epsg=4326)\nda = da.assign_coords({\"time\": da.start_datetime}).squeeze()\nda.name = collection\nda\n\nCPU times: user 89.8 ms, sys: 3.86 ms, total: 93.7 ms\nWall time: 94.6 ms\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'social-vulnerability-index-overall-nopop' (time: 5, y: 6298,\n                                                              x: 13354)&gt; Size: 3GB\ndask.array&lt;getitem, shape=(5, 6298, 13354), dtype=float64, chunksize=(1, 1024, 1024), chunktype=numpy.ndarray&gt;\nCoordinates: (12/17)\n    id              (time) &lt;U38 760B 'svi_2018_tract_overall_wgs84_nopop_cog'...\n    band            &lt;U11 44B 'cog_default'\n  * x               (x) float64 107kB -178.2 -178.2 -178.2 ... -66.97 -66.97\n  * y               (y) float64 50kB 71.38 71.37 71.37 ... 18.92 18.92 18.91\n    start_datetime  (time) &lt;U25 500B '2018-01-01T00:00:00+00:00' ... '2000-01...\n    end_datetime    (time) &lt;U25 500B '2018-12-31T00:00:00+00:00' ... '2000-12...\n    ...              ...\n    description     &lt;U47 188B 'Cloud optimized default layer to display on map'\n    proj:geometry   object 8B {'type': 'Polygon', 'coordinates': [[[-178.2333...\n    proj:bbox       object 8B {-178.23333334, 18.908332897999998, -66.9583337...\n    title           &lt;U17 68B 'Default COG Layer'\n    epsg            int64 8B 4326\n  * time            (time) &lt;U25 500B '2018-01-01T00:00:00+00:00' ... '2000-01...\nAttributes:\n    spec:           RasterSpec(epsg=4326, bounds=(-178.24166595386018, 18.899...\n    crs:            epsg:4326\n    transform:      | 0.01, 0.00,-178.24|\\n| 0.00,-0.01, 71.38|\\n| 0.00, 0.00...\n    resolution_xy:  (0.00833333330000749, 0.00833333329998412)xarray.DataArray'social-vulnerability-index-overall-nopop'time: 5y: 6298x: 13354dask.array&lt;chunksize=(1, 1024, 1024), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n3.13 GiB\n8.00 MiB\n\n\nShape\n(5, 6298, 13354)\n(1, 1024, 1024)\n\n\nDask graph\n490 chunks in 4 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                                       13354 6298 5\n\n\n\n\nCoordinates: (17)id(time)&lt;U38'svi_2018_tract_overall_wgs84_no...array(['svi_2018_tract_overall_wgs84_nopop_cog',\n       'svi_2016_tract_overall_wgs84_nopop_cog',\n       'svi_2014_tract_overall_wgs84_nopop_cog',\n       'svi_2010_tract_overall_wgs84_nopop_cog',\n       'svi_2000_tract_overall_wgs84_nopop_cog'], dtype='&lt;U38')band()&lt;U11'cog_default'array('cog_default', dtype='&lt;U11')x(x)float64-178.2 -178.2 ... -66.97 -66.97array([-178.241666, -178.233333, -178.224999, ...,  -66.983333,  -66.975   ,\n        -66.966666], shape=(13354,))y(y)float6471.38 71.37 71.37 ... 18.92 18.91array([71.383333, 71.375   , 71.366666, ..., 18.925   , 18.916667, 18.908333],\n      shape=(6298,))start_datetime(time)&lt;U25'2018-01-01T00:00:00+00:00' ... ...array(['2018-01-01T00:00:00+00:00', '2016-01-01T00:00:00+00:00',\n       '2014-01-01T00:00:00+00:00', '2010-01-01T00:00:00+00:00',\n       '2000-01-01T00:00:00+00:00'], dtype='&lt;U25')end_datetime(time)&lt;U25'2018-12-31T00:00:00+00:00' ... ...array(['2018-12-31T00:00:00+00:00', '2016-12-31T00:00:00+00:00',\n       '2014-12-31T00:00:00+00:00', '2010-12-31T00:00:00+00:00',\n       '2000-12-31T00:00:00+00:00'], dtype='&lt;U25')proj:wkt2()&lt;U277'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984...array('GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]',\n      dtype='&lt;U277')proj:shape()object{6297, 13353}array({6297, 13353}, dtype=object)proj:code()&lt;U9'EPSG:4326'array('EPSG:4326', dtype='&lt;U9')proj:transform()object{0.00833333330000749, 0.0, 1.0, ...array({0.00833333330000749, 0.0, 1.0, -0.00833333329998412, 71.383332688, -178.23333334},\n      dtype=object)proj:projjson()object{'id': {'code': 4326, 'authority...array({'id': {'code': 4326, 'authority': 'EPSG'}, 'name': 'WGS 84', 'type': 'GeographicCRS', 'datum': {'name': 'World Geodetic System 1984', 'type': 'GeodeticReferenceFrame', 'ellipsoid': {'name': 'WGS 84', 'semi_major_axis': 6378137, 'inverse_flattening': 298.257223563}}, '$schema': 'https://proj.org/schemas/v0.4/projjson.schema.json', 'coordinate_system': {'axis': [{'name': 'Geodetic latitude', 'unit': 'degree', 'direction': 'north', 'abbreviation': 'Lat'}, {'name': 'Geodetic longitude', 'unit': 'degree', 'direction': 'east', 'abbreviation': 'Lon'}], 'subtype': 'ellipsoidal'}},\n      dtype=object)description()&lt;U47'Cloud optimized default layer t...array('Cloud optimized default layer to display on map', dtype='&lt;U47')proj:geometry()object{'type': 'Polygon', 'coordinates...array({'type': 'Polygon', 'coordinates': [[[-178.23333334, 18.908332897999998], [-66.958333785, 18.908332897999998], [-66.958333785, 71.383332688], [-178.23333334, 71.383332688], [-178.23333334, 18.908332897999998]]]},\n      dtype=object)proj:bbox()object{-178.23333334, 18.9083328979999...array({-178.23333334, 18.908332897999998, -66.958333785, 71.383332688},\n      dtype=object)title()&lt;U17'Default COG Layer'array('Default COG Layer', dtype='&lt;U17')epsg()int644326array(4326)time(time)&lt;U25'2018-01-01T00:00:00+00:00' ... ...array(['2018-01-01T00:00:00+00:00', '2016-01-01T00:00:00+00:00',\n       '2014-01-01T00:00:00+00:00', '2010-01-01T00:00:00+00:00',\n       '2000-01-01T00:00:00+00:00'], dtype='&lt;U25')Indexes: (3)xPandasIndexPandasIndex(Index([-178.24166595386018, -178.23333262056016, -178.22499928726018,\n       -178.21666595396016, -178.20833262066014, -178.19999928736013,\n       -178.19166595406014, -178.18333262076013,  -178.1749992874601,\n       -178.16666595416012,\n       ...\n        -67.04166639856027,  -67.03333306526025,  -67.02499973196025,\n        -67.01666639866023,  -67.00833306536023,  -66.99999973206023,\n        -66.99166639876022,  -66.98333306546022,   -66.9749997321602,\n         -66.9666663988602],\n      dtype='float64', name='x', length=13354))yPandasIndexPandasIndex(Index([ 71.38333304766397,  71.37499971436398,    71.366666381064,\n        71.35833304776402,  71.34999971446403,  71.34166638116405,\n        71.33333304786406,  71.32499971456407,   71.3166663812641,\n        71.30833304796411,\n       ...\n       18.983333257363824, 18.974999924063845, 18.966666590763857,\n        18.95833325746387,  18.94999992416389, 18.941666590863903,\n       18.933333257563923, 18.924999924263936, 18.916666590963956,\n        18.90833325766397],\n      dtype='float64', name='y', length=6298))timePandasIndexPandasIndex(Index(['2018-01-01T00:00:00+00:00', '2016-01-01T00:00:00+00:00',\n       '2014-01-01T00:00:00+00:00', '2010-01-01T00:00:00+00:00',\n       '2000-01-01T00:00:00+00:00'],\n      dtype='object', name='time'))Attributes: (4)spec :RasterSpec(epsg=4326, bounds=(-178.24166595386018, 18.899999924363982, -66.95833306556018, 71.38333304766397), resolutions_xy=(0.00833333330000749, 0.00833333329998412))crs :epsg:4326transform :| 0.01, 0.00,-178.24|\n| 0.00,-0.01, 71.38|\n| 0.00, 0.00, 1.00|resolution_xy :(0.00833333330000749, 0.00833333329998412)\n\n\nThere are 5 items representing the 5 years of data in the collection (2000, 2010, 2014, 2016, and 2018)."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/open-and-plot.html#plot-data",
    "href": "user-guide/notebooks/quickstarts/open-and-plot.html#plot-data",
    "title": "Open and plot COGs",
    "section": "Plot data",
    "text": "Plot data\nPlot data using hvplot. By using rasterize=True we tell hvplot to use datashader behind the scenes to make the plot render more quickly and re-render on zoom.\n\n%%time\nda.compute().hvplot(x=\"x\", y=\"y\", rasterize=True, clim=(0, 1), coastline=True, cmap=\"viridis\", widget_location=\"bottom\")\n\nCPU times: user 32.7 s, sys: 2.39 s, total: 35.1 s\nWall time: 18.4 s"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html",
    "title": "Get tiles from COGs",
    "section": "",
    "text": "You can launch this notbook using mybinder, by clicking the button below."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#run-this-notebook",
    "title": "Get tiles from COGs",
    "section": "",
    "text": "You can launch this notbook using mybinder, by clicking the button below."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#approach",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#approach",
    "title": "Get tiles from COGs",
    "section": "Approach",
    "text": "Approach\n\nIdentify available dates within a bounding box, which is also an area of interest (AOI) in this example, for a given collection\nRegister a dynamic tiler search for an AOI and specific date range for a given collection\nExplore different options for displaying multi-band Harmonized Landsat and Sentinel (HLS) assets with the Raster API."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#about-the-data",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#about-the-data",
    "title": "Get tiles from COGs",
    "section": "About the Data",
    "text": "About the Data\nA small subset of HLS data has been ingested to the VEDA datastore to visually explore data using the Raster API, which is a VEDA instance of (pgstac-titiler). This limited subset includes two granules for dates before and after Hurricane Maria in 2017 and Hurricane Ida in 2021.\nNote about HLS datasets: The Sentinel and Landsat assets have been harmonized in the sense that these products have been generated to use the same spatial resolution and grid system. Thus these 2 HLS S30 and L30 productscan be used interchangeably in algorithms. However, the individual band assets are specific to each provider. This notebook focuses on displaying HLS data with a dynamic tiler so separate examples are provided for rendering the unique band assets of each collection.\nAdditional Resources\n\nHLSL30 Dataset Landing Page\nLandsat 8 Bands and Combinations Blog\nHLSS30 Dataset Landing Page\nSentinel 2 Bands and Combinations Blog\nCQL2 STAC-API Examples\nCQL2 Playground\n\n\nimport json\nimport requests\n\nfrom folium import Map, TileLayer"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#parameters-for-investigating-hurricane-events-with-the-dynamic-tiler-and-custom-band-combinations",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#parameters-for-investigating-hurricane-events-with-the-dynamic-tiler-and-custom-band-combinations",
    "title": "Get tiles from COGs",
    "section": "Parameters for investigating hurricane events with the dynamic tiler and custom band combinations",
    "text": "Parameters for investigating hurricane events with the dynamic tiler and custom band combinations\nIn this notebook we will focus on HLS S30 data for Hurricane Ida, but Hurricane Maria and L30 parameters are provided below for further exploration.\n\n# Endpoints\nSTAC_API_URL = \"https://openveda.cloud/api/stac\"\nRASTER_API_URL = \"https://openveda.cloud/api/raster\"\n\n# Harmonized Sentinel collection id and configuration info\ns30_collection_id = \"hls-s30-002-ej-reprocessed\"\ns30_swir_assets = [\"B12\", \"B8A\", \"B04\"]\ns30_vegetation_index_assets = [\"B08\", \"B04\"]\ns30_vegetation_index_expression = \"(B08_b1-B04_b1)/(B08_b1+B04_b1)\"\ns30_vegetation_index_rescaling = \"0,1\"\ns30_vegetation_index_colormap = \"rdylgn\"\n\n# Harmonized Landsat collection id and map configuration info\nl30_collection_id = \"hls-l30-002-ej-reprocessed\"\nl30_swir_assets = [\"B07\", \"B05\", \"B04\"]\nl30_ndwi_expression = \"(B03_b1-B05_b1)/(B03_b1+B05_b1)\"\nl30_ndwi_assets = [\"B03\", \"B05\"]\nl30_ndwi_rescaling = \"0,1\"\nl30_ndwi_colormap = \"spectral\"\n\n# Search criteria for events in both HLS Events collections\nmaria_bbox = [-66.167596, 17.961538, -65.110098, 18.96772]\nmaria_temporal_range = [\"2017-10-02T00:00:00Z\", \"2017-10-17T00:00:00Z\"]\n\nida_bbox = [-90.932637, 29.705366, -89.766437, 30.71627]\nida_temporal_range = [\"2021-09-02T00:00:00Z\", \"2021-09-17T00:00:00Z\"]\n\n\nFirst, search the STAC API to find the specific dates available within timeframe of interest (Hurricane Ida)\nTo focus on a specific point in time, we will restrict the temporal range when defining the item search in the example below.\nNote: For STAC there are more succinct ways of filtering, but we will use full cql2-json syntax in this example so that the filter are reusable with the Raster API.\n\ncollections_filter = {\n    \"op\": \"=\",\n    \"args\": [{\"property\": \"collection\"}, s30_collection_id],\n}\n\nspatial_filter = {\"op\": \"s_intersects\", \"args\": [{\"property\": \"bbox\"}, ida_bbox]}\n\ntemporal_filter = {\n    \"op\": \"t_intersects\",\n    \"args\": [{\"property\": \"datetime\"}, {\"interval\": ida_temporal_range}],\n}\n\n# Additional filters can be applied for other search criteria like &lt;= maximum eo:cloud_cover in item properties\ncloud_filter = {\"op\": \"&lt;=\", \"args\": [{\"property\": \"eo:cloud_cover\"}, 80]}\n\n# Specify cql2-json filter language in search body and add sort by datetime\nsearch_body = {\n    \"filter-lang\": \"cql2-json\",\n    \"limit\": 100,\n    \"sortby\": [{\"direction\": \"asc\", \"field\": \"properties.datetime\"}],\n    \"filter\": {\n        \"op\": \"and\",\n        \"args\": [collections_filter, spatial_filter, temporal_filter, cloud_filter],\n    },\n}\n\nstac_items_response = requests.post(\n    f\"{STAC_API_URL}/search\",\n    json=search_body,\n).json()\n\n# Check how many items were matched in search\nprint(\"Number of items returned:\", stac_items_response[\"numberMatched\"])\n\n# Iterate over search results to get an array of item datetimes\n[item[\"properties\"][\"datetime\"] for item in stac_items_response[\"features\"]]\n\nNumber of items returned: 2\n\n\n['2021-09-02T16:55:09.568600+00:00', '2021-09-07T16:55:13.430530+00:00']"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#visualizing-the-data-on-a-map",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#visualizing-the-data-on-a-map",
    "title": "Get tiles from COGs",
    "section": "Visualizing the data on a map",
    "text": "Visualizing the data on a map\nThe VEDA backend is based on eoAPI, an application for searching and tiling earth observation STAC records. The application uses titiler-pgstac for dynamically mosaicing cloud optimized data from a registered STAC API search.\nTo use the dynamic tiler, register a STAC item search and then use the registered search ID to dynamically mosaic the search results on the map\n\nUpdate the temporal range in search body and register that search with the Raster API\nThe registered search id can be reused for alternate map layer visualizations.\n\nmosaic_response = requests.post(\n    f\"{RASTER_API_URL}/searches/register\",\n    json=search_body,\n).json()\nprint(json.dumps(mosaic_response, indent=2))\n\n{\n  \"id\": \"60c4cc6fc305665fce131dc218f2bb46\",\n  \"links\": [\n    {\n      \"href\": \"https://openveda.cloud/api/raster/searches/60c4cc6fc305665fce131dc218f2bb46/info\",\n      \"rel\": \"metadata\",\n      \"title\": \"Mosaic metadata\"\n    },\n    {\n      \"href\": \"https://openveda.cloud/api/raster/searches/60c4cc6fc305665fce131dc218f2bb46/{tileMatrixSetId}/tilejson.json\",\n      \"rel\": \"tilejson\",\n      \"templated\": true,\n      \"title\": \"Link for TileJSON (Template URL)\"\n    },\n    {\n      \"href\": \"https://openveda.cloud/api/raster/searches/60c4cc6fc305665fce131dc218f2bb46/{tileMatrixSetId}/WMTSCapabilities.xml\",\n      \"rel\": \"wmts\",\n      \"templated\": true,\n      \"title\": \"Link for WMTS (Template URL)\"\n    }\n  ]\n}\n\n\n\n# Get base url for tiler from the register mosaic request\ntiles_href = next(\n    link[\"href\"] for link in mosaic_response[\"links\"] if link[\"rel\"] == \"tilejson\"\n)\n\n\n\nConfigure map formatting parameters\nSee the openveda.cloud/api/raster/docs for more formatting options"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#use-the-built-in-swir-post-processing-algorithm",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#use-the-built-in-swir-post-processing-algorithm",
    "title": "Get tiles from COGs",
    "section": "Use the built-in SWIR post processing algorithm",
    "text": "Use the built-in SWIR post processing algorithm\nNote in the example below the band assets for HLS S30 are selected. The equivalent SWIR band assets for L30 are provided at the top of this notebook.\n\n# Add additional map formatting parameters to tiles url\n\n# Use default tile matrix set\ntile_matrix_set_id = \"WebMercatorQuad\"\n\ntilejson_response = requests.get(\n    tiles_href.format(tileMatrixSetId=tile_matrix_set_id),\n    params={\n        # Info to add to the tilejson response\n        \"minzoom\": 6,\n        \"maxzoom\": 12,\n        \"algorithm\": \"swir\",\n        \"assets\": s30_swir_assets\n    },\n).json()\nprint(json.dumps(tilejson_response, indent=2))\n\n{\n  \"tilejson\": \"2.2.0\",\n  \"name\": \"60c4cc6fc305665fce131dc218f2bb46\",\n  \"version\": \"1.0.0\",\n  \"scheme\": \"xyz\",\n  \"tiles\": [\n    \"https://openveda.cloud/api/raster/searches/60c4cc6fc305665fce131dc218f2bb46/tiles/WebMercatorQuad/{z}/{x}/{y}?algorithm=swir&assets=B12&assets=B8A&assets=B04\"\n  ],\n  \"minzoom\": 6,\n  \"maxzoom\": 12,\n  \"bounds\": [\n    -180.0,\n    -85.0511287798066,\n    180.00000000000009,\n    85.0511287798066\n  ],\n  \"center\": [\n    4.263256414560601e-14,\n    0.0,\n    6\n  ]\n}\n\n\n\nDisplay the data on a map\n\n# Use bbox initial zoom and map\n# Set up a map located w/in event bounds\nzoom_start = 11\nm = Map(\n    tiles=\"OpenStreetMap\",\n    location=((ida_bbox[1] + ida_bbox[3]) / 2, (ida_bbox[0] + ida_bbox[2]) / 2),\n    zoom_start=zoom_start,\n)\n\n# Add the formatted map layer\nmap_layer = TileLayer(\n    tiles=tilejson_response[\"tiles\"][0],\n    attr=\"Mosaic\",\n)\nmap_layer.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nFormat and render tiles using custom formatting\nThe titiler/raster-api supports user defined band combinations, band math expressions, rescaling, band index, resampling and more.\n\n# Add additional map formatting parameters to tiles url\n\n# Use default tile matrix set\ntile_matrix_set_id = \"WebMercatorQuad\"\n\ntilejson_response = requests.get(\n    tiles_href.format(tileMatrixSetId=tile_matrix_set_id),\n    params={\n        # Info to add to the tilejson response\n        \"minzoom\": 6,\n        \"maxzoom\": 12,\n        \"assets\": s30_vegetation_index_assets,\n        \"expression\": s30_vegetation_index_expression,\n        \"rescale\": s30_vegetation_index_rescaling,\n        \"colormap_name\": s30_vegetation_index_colormap,\n    },\n).json()\nprint(json.dumps(tilejson_response, indent=2))\n\n{\n  \"tilejson\": \"2.2.0\",\n  \"name\": \"60c4cc6fc305665fce131dc218f2bb46\",\n  \"version\": \"1.0.0\",\n  \"scheme\": \"xyz\",\n  \"tiles\": [\n    \"https://openveda.cloud/api/raster/searches/60c4cc6fc305665fce131dc218f2bb46/tiles/WebMercatorQuad/{z}/{x}/{y}?assets=B08&assets=B04&expression=%28B08_b1-B04_b1%29%2F%28B08_b1%2BB04_b1%29&rescale=0%2C1&colormap_name=rdylgn\"\n  ],\n  \"minzoom\": 6,\n  \"maxzoom\": 12,\n  \"bounds\": [\n    -180.0,\n    -85.0511287798066,\n    180.00000000000009,\n    85.0511287798066\n  ],\n  \"center\": [\n    4.263256414560601e-14,\n    0.0,\n    6\n  ]\n}\n\n\n\n# Use bbox initial zoom and map\n# Set up a map located w/in event bounds\nzoom_start = 11\nm = Map(\n    tiles=\"OpenStreetMap\",\n    location=((ida_bbox[1] + ida_bbox[3]) / 2, (ida_bbox[0] + ida_bbox[2]) / 2),\n    zoom_start=zoom_start,\n)\n\n# Add the formatted map layer\nmap_layer = TileLayer(\n    tiles=tilejson_response[\"tiles\"][0],\n    attr=\"Mosaic\",\n)\nmap_layer.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/hls-visualization.html#l30-hurricane-maria-example",
    "href": "user-guide/notebooks/quickstarts/hls-visualization.html#l30-hurricane-maria-example",
    "title": "Get tiles from COGs",
    "section": "L30 Hurricane Maria Example",
    "text": "L30 Hurricane Maria Example\n\ncollections_filter = {\n    \"op\": \"=\", \n    \"args\" : [{ \"property\": \"collection\" }, l30_collection_id]\n}\n\nspatial_filter = {\n    \"op\": \"s_intersects\",\n    \"args\": [\n        {\"property\": \"bbox\"}, maria_bbox\n    ]\n}\n\ntemporal_filter = {\n    \"op\": \"t_intersects\",\n    \"args\": [\n        { \"property\": \"datetime\" },\n        { \"interval\" : maria_temporal_range }\n    ]\n}\n\n# Additional filters can be applied for other search criteria like &lt;= maximum eo:cloud_cover in item properties\ncloud_filter = {\n    \"op\": \"&lt;=\",\n    \"args\": [\n        {\"property\": \"eo:cloud_cover\"},\n        80\n    ]\n}\n\n# Specify cql2-json filter language in search body and add sort by datetime\nsearch_body = {\n    \"filter-lang\": \"cql2-json\",\n    \"sortby\": [{\"direction\": \"asc\", \"field\": \"properties.datetime\"}],\n    \"filter\": {\n        \"op\": \"and\",\n        \"args\": [\n            collections_filter,\n            temporal_filter,\n            cloud_filter\n        ]\n    }\n}\n\nmosaic_response = requests.post(\n    f\"{RASTER_API_URL}/searches/register\",\n    json=search_body,\n).json()\n\n\n# Set up format for Map API url\n# Get base url for tiler from the register mosaic request\ntiles_href = next(link[\"href\"] for link in mosaic_response[\"links\"] if link[\"rel\"]==\"tilejson\")\n\n# Use default tile matrix set\ntile_matrix_set_id = \"WebMercatorQuad\"\n\ntilejson_response = requests.get(\n    tiles_href.format(tileMatrixSetId=tile_matrix_set_id),\n    params={\n        # Info to add to the tilejson response\n        \"minzoom\": 6,\n        \"maxzoom\": 12,\n        \"assets\": l30_ndwi_assets,\n        \"expression\": l30_ndwi_expression,\n        \"rescale\": l30_ndwi_rescaling,\n        \"colormap_name\": \"viridis\"\n    }\n).json()\n\n\n# Use bbox initial zoom and map\n# Set up a map located w/in event bounds\nzoom_start = 11\nm = Map(\n    tiles=\"OpenStreetMap\",\n    location=((maria_bbox[1] + maria_bbox[3]) / 2,(maria_bbox[0] + maria_bbox[2]) / 2),\n    zoom_start=zoom_start\n)\n\n# Add the formatted map layer\nmap_layer = TileLayer(\n    tiles=tilejson_response[\"tiles\"][0],\n    attr=\"Mosaic\",  \n)\nmap_layer.add_to(m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/list-collections.html",
    "href": "user-guide/notebooks/quickstarts/list-collections.html",
    "title": "Browse Available Collections",
    "section": "",
    "text": "Connect to the GRSS VEDA STAC catalog using pystac_client\nEnumerate all available collections and display their titles",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Accessing the Data Directly",
      "Browse Available Collections"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/list-collections.html#workflow",
    "href": "user-guide/notebooks/quickstarts/list-collections.html#workflow",
    "title": "Browse Available Collections",
    "section": "",
    "text": "Connect to the GRSS VEDA STAC catalog using pystac_client\nEnumerate all available collections and display their titles",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Accessing the Data Directly",
      "Browse Available Collections"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/list-collections.html#connect-to-the-stac-catalog",
    "href": "user-guide/notebooks/quickstarts/list-collections.html#connect-to-the-stac-catalog",
    "title": "Browse Available Collections",
    "section": "Connect to the STAC Catalog",
    "text": "Connect to the STAC Catalog\n\nfrom pystac_client import Client\n\nSTAC_API_URL = \"https://api.dev.veda.grss.cloud/stac\"\ncatalog = Client.open(STAC_API_URL)",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Accessing the Data Directly",
      "Browse Available Collections"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/list-collections.html#display-all-collections",
    "href": "user-guide/notebooks/quickstarts/list-collections.html#display-all-collections",
    "title": "Browse Available Collections",
    "section": "Display All Collections",
    "text": "Display All Collections\n\ncollections = list(catalog.get_collections())\nprint(f\"Found {len(collections)} collections:\\n\")\n\nfor collection in sorted(collections, key=lambda x: x.title or x.id):\n    print(f\"- {collection.title or collection.id}\")\n\nFound 4 collections:\n\n- (Monthly) Wetland Methane Emissions, LPJ-EOSIM Model v2\n- HLS_S30_Nadir_BRDF_Adjusted_Reflectance\n- SEDAC Gridded World Population Density v4.11\n- TanDEM-X - Edited Digital Elevation Model (EDEM) - Global, 30m",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Accessing the Data Directly",
      "Browse Available Collections"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/list-collections.html#other-ways-to-discover-data",
    "href": "user-guide/notebooks/quickstarts/list-collections.html#other-ways-to-discover-data",
    "title": "Browse Available Collections",
    "section": "Other Ways to Discover Data",
    "text": "Other Ways to Discover Data\nIn addition to programmatic access, you can explore collections through:\n\nJSON API: https://api.dev.veda.grss.cloud/stac/collections\nWeb Interface: https://api.dev.veda.grss.cloud",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Quickstarts",
      "Accessing the Data Directly",
      "Browse Available Collections"
    ]
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html",
    "title": "Visualize zarr",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailing aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#run-this-notebook",
    "title": "Visualize zarr",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailing aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#approach",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#approach",
    "title": "Visualize zarr",
    "section": "Approach",
    "text": "Approach\n\nUse pystac to open a STAC collection\nUse xarray and dask to lazily read in the data\nPlot the data using hvplot"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#about-the-data",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#about-the-data",
    "title": "Visualize zarr",
    "section": "About the data",
    "text": "About the data\nThis is the Gridded Daily OCO-2 Carbon Dioxide assimilated dataset. More information can be found at: OCO-2 GEOS Level 3 daily, 0.5x0.625 assimilated CO2 V10r (OCO2_GEOS_L3CO2_DAY)\nThe data has been converted to zarr format and published to the development version of the VEDA STAC Catalog.\n\nimport pystac\nimport xarray as xr\n\nimport hvplot.xarray  # noqa"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#declare-your-collection-of-interest",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#declare-your-collection-of-interest",
    "title": "Visualize zarr",
    "section": "Declare your collection of interest",
    "text": "Declare your collection of interest\nYou can discover available collections the following ways:\n\nProgrammatically: see example in the list-collections.ipynb notebook\nJSON API: https://openveda.cloud/api/stac/collections\nSTAC Browser: https://openveda.cloud\n\n\nSTAC_API_URL = \"https://openveda.cloud/api/stac\"\ncollection_id = \"oco2-geos-l3-daily\""
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#get-stac-collection",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#get-stac-collection",
    "title": "Visualize zarr",
    "section": "Get STAC collection",
    "text": "Get STAC collection\nUse pystac to access the STAC collection.\n\ncollection = pystac.Collection.from_file(f\"{STAC_API_URL}/collections/{collection_id}\")\ncollection\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Collection\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"oco2-geos-l3-daily\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"The OCO-2 mission provides the highest quality space-based XCO2 retrievals to date. However, the instrument data are characterized by large gaps in coverage due to OCO-2s narrow 10-km ground track and an inability to see through clouds and thick aerosols. This global gridded dataset is produced using a data assimilation technique commonly referred to as state estimation within the geophysical literature. Data assimilation synthesizes simulations and observations, adjusting the state of atmospheric constituents like CO2 to reflect observed values, thus gap-filling observations when and where they are unavailable based on previous observations and short transport simulations by GEOS. Compared to other methods, data assimilation has the advantage that it makes estimates based on our collective scientific understanding, notably of the Earth's carbon cycle and atmospheric transport. OCO-2 GEOS (Goddard Earth Observing System) Level 3 data are produced by ingesting OCO-2 L2 retrievals every 6 hours with GEOS CoDAS, a modeling and data assimilation system maintained by NASA's Global Modeling and Assimilation Office (GMAO). GEOS CoDAS uses a high-performance computing implementation of the Gridpoint Statistical Interpolation approach for solving the state estimation problem. GSI finds the analyzed state that minimizes the three-dimensional variational (3D-Var) cost function formulation of the state estimation problem.\"\n        \n    \n                \n            \n                \n                    \n        links[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/collections/oco2-geos-l3-daily\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"items\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/collections/oco2-geos-l3-daily/items\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"external\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://catalog.data.gov/dataset/oco-2-geos-level-3-daily-0-5x0-625-assimilated-co2-v10r-oco2-geos-l3co2-day-at-ges-disc-72b15\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OCO-2 GEOS Level 3 daily, 0.5x0.625 assimilated CO2 V10r (OCO2_GEOS_L3CO2_DAY) at GES DISC\"\n        \n    \n            \n        \n            \n                \n        \n            label:assets\n            None\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://openveda.cloud/api/stac/collections/oco2-geos-l3-daily/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        stac_extensions[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/datacube/v2.2.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            cube:variables\n            \n        \n            \n                \n        \n            XCO2\n            \n        \n            \n                \n        \n            type\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            unit\n            \"mol CO2/mol dry\"\n        \n    \n            \n        \n            \n                \n        \n            attrs\n            \n        \n            \n                \n        \n            units\n            \"mol CO2/mol dry\"\n        \n    \n            \n        \n            \n                \n        \n            long_name\n            \"Assimilated dry-air column average CO2 daily mean\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        shape[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            2500\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            361\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            576\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        chunks[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            100\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            100\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            100\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        dimensions[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \"time\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"lat\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"lon\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Assimilated dry-air column average CO2 daily mean\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            XCO2PREC\n            \n        \n            \n                \n        \n            type\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            unit\n            \"mol CO2/mol dry\"\n        \n    \n            \n        \n            \n                \n        \n            attrs\n            \n        \n            \n                \n        \n            units\n            \"mol CO2/mol dry\"\n        \n    \n            \n        \n            \n                \n        \n            long_name\n            \"Precision of dry-air column average CO2 daily mean from Desroziers et al. (2005) diagnostic\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        shape[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            2500\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            361\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            576\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        chunks[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            100\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            100\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            100\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        dimensions[] 3 items\n        \n            \n        \n            \n                \n        \n            0\n            \"time\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"lat\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"lon\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Precision of dry-air column average CO2 daily mean from Desroziers et al. (2005) diagnostic\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            cube:dimensions\n            \n        \n            \n                \n        \n            lat\n            \n        \n            \n                \n        \n            axis\n            \"y\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"spatial\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -90.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            90.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"latitude\"\n        \n    \n            \n        \n            \n                \n        \n            reference_system\n            4326\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            lon\n            \n        \n            \n                \n        \n            axis\n            \"x\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"spatial\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -180.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            179.375\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"longitude\"\n        \n    \n            \n        \n            \n                \n        \n            reference_system\n            4326\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            time\n            \n        \n            \n                \n        \n            step\n            \"P1DT0H0M0S\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"temporal\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"2015-01-01T12:00:00Z\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"2021-11-04T12:00:00Z\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"time\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            dashboard:is_periodic\n            True\n        \n    \n                \n            \n                \n                    \n        \n            dashboard:time_density\n            \"day\"\n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"Gridded Daily OCO-2 Carbon Dioxide assimilated dataset\"\n        \n    \n                \n            \n                \n                    \n        \n            extent\n            \n        \n            \n                \n        \n            spatial\n            \n        \n            \n                \n        bbox[] 1 items\n        \n            \n        \n            \n                \n        0[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -180.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            -90.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            180.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            90.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            temporal\n            \n        \n            \n                \n        interval[] 1 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            None\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            None\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            license\n            \"CC0-1.0\"\n        \n    \n                \n            \n                \n                    \n        providers[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"NASA VEDA\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"host\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.earthdata.nasa.gov/dashboard/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            assets\n            \n        \n            \n                \n        \n            zarr\n            \n        \n            \n                \n        \n            href\n            \"s3://veda-data-store/oco2-geos-l3-daily/OCO2_GEOS_L3CO2_day.zarr\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/vnd+zarr\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"zarr\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n        \n    \n\n\n\nWe can see that there is one zarr asset:\n\ncollection.get_assets(media_type=\"application/vnd+zarr\")\n\n{'zarr': &lt;Asset href=s3://veda-data-store/oco2-geos-l3-daily/OCO2_GEOS_L3CO2_day.zarr&gt;}"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#read-from-zarr-to-xarray",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#read-from-zarr-to-xarray",
    "title": "Visualize zarr",
    "section": "Read from zarr to xarray",
    "text": "Read from zarr to xarray\nWith the url pointing to the Zarr store, you can create an xarray dataset backed by a dask array.\n\nurl = collection.assets[\"zarr\"].href\n\nds = xr.open_dataset(url, engine=\"zarr\", chunks=\"auto\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 8GB\nDimensions:   (time: 2500, lat: 361, lon: 576)\nCoordinates:\n  * lat       (lat) float64 3kB -90.0 -89.5 -89.0 -88.5 ... 88.5 89.0 89.5 90.0\n  * lon       (lon) float64 5kB -180.0 -179.4 -178.8 ... 178.1 178.8 179.4\n  * time      (time) datetime64[ns] 20kB 2015-01-01T12:00:00 ... 2021-11-04T1...\nData variables:\n    XCO2      (time, lat, lon) float64 4GB dask.array&lt;chunksize=(200, 200, 200), meta=np.ndarray&gt;\n    XCO2PREC  (time, lat, lon) float64 4GB dask.array&lt;chunksize=(200, 200, 200), meta=np.ndarray&gt;\nAttributes: (12/25)\n    BuildId:                        B10.2.06\n    Contact:                        Brad Weir (brad.weir@nasa.gov)\n    Conventions:                    CF-1\n    DataResolution:                 0.5x0.625\n    EastBoundingCoordinate:         179.375\n    Format:                         NetCDF-4/HDF-5\n    ...                             ...\n    ShortName:                      OCO2_GEOS_L3CO2_DAY_10r\n    SouthBoundingCoordinate:        -90.0\n    SpatialCoverage:                global\n    Title:                          OCO-2 GEOS Level 3 daily, 0.5x0.625 assim...\n    VersionID:                      V10r\n    WestBoundingCoordinate:         -180.0xarray.DatasetDimensions:time: 2500lat: 361lon: 576Coordinates: (3)lat(lat)float64-90.0 -89.5 -89.0 ... 89.5 90.0long_name :latitudeunits :degrees_northarray([-90. , -89.5, -89. , ...,  89. ,  89.5,  90. ], shape=(361,))lon(lon)float64-180.0 -179.4 ... 178.8 179.4long_name :longitudeunits :degrees_eastarray([-180.   , -179.375, -178.75 , ...,  178.125,  178.75 ,  179.375],\n      shape=(576,))time(time)datetime64[ns]2015-01-01T12:00:00 ... 2021-11-...begin_date :20170801begin_time :120000long_name :timearray(['2015-01-01T12:00:00.000000000', '2015-01-02T12:00:00.000000000',\n       '2015-01-03T12:00:00.000000000', ..., '2021-11-02T12:00:00.000000000',\n       '2021-11-03T12:00:00.000000000', '2021-11-04T12:00:00.000000000'],\n      shape=(2500,), dtype='datetime64[ns]')Data variables: (2)XCO2(time, lat, lon)float64dask.array&lt;chunksize=(200, 200, 200), meta=np.ndarray&gt;long_name :Assimilated dry-air column average CO2 daily meanunits :mol CO2/mol dry\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n3.87 GiB\n61.04 MiB\n\n\nShape\n(2500, 361, 576)\n(200, 200, 200)\n\n\nDask graph\n78 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                       576 361 2500\n\n\n\n\nXCO2PREC(time, lat, lon)float64dask.array&lt;chunksize=(200, 200, 200), meta=np.ndarray&gt;long_name :Precision of dry-air column average CO2 daily mean from Desroziers et al. (2005) diagnosticunits :mol CO2/mol dry\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n3.87 GiB\n61.04 MiB\n\n\nShape\n(2500, 361, 576)\n(200, 200, 200)\n\n\nDask graph\n78 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                       576 361 2500\n\n\n\n\nIndexes: (3)latPandasIndexPandasIndex(Index([-90.0, -89.5, -89.0, -88.5, -88.0, -87.5, -87.0, -86.5, -86.0, -85.5,\n       ...\n        85.5,  86.0,  86.5,  87.0,  87.5,  88.0,  88.5,  89.0,  89.5,  90.0],\n      dtype='float64', name='lat', length=361))lonPandasIndexPandasIndex(Index([  -180.0, -179.375,  -178.75, -178.125,   -177.5, -176.875,  -176.25,\n       -175.625,   -175.0, -174.375,\n       ...\n         173.75,  174.375,    175.0,  175.625,   176.25,  176.875,    177.5,\n        178.125,   178.75,  179.375],\n      dtype='float64', name='lon', length=576))timePandasIndexPandasIndex(DatetimeIndex(['2015-01-01 12:00:00', '2015-01-02 12:00:00',\n               '2015-01-03 12:00:00', '2015-01-04 12:00:00',\n               '2015-01-05 12:00:00', '2015-01-06 12:00:00',\n               '2015-01-07 12:00:00', '2015-01-08 12:00:00',\n               '2015-01-09 12:00:00', '2015-01-10 12:00:00',\n               ...\n               '2021-10-26 12:00:00', '2021-10-27 12:00:00',\n               '2021-10-28 12:00:00', '2021-10-29 12:00:00',\n               '2021-10-30 12:00:00', '2021-10-31 12:00:00',\n               '2021-11-01 12:00:00', '2021-11-02 12:00:00',\n               '2021-11-03 12:00:00', '2021-11-04 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=2500, freq=None))Attributes: (25)BuildId :B10.2.06Contact :Brad Weir (brad.weir@nasa.gov)Conventions :CF-1DataResolution :0.5x0.625EastBoundingCoordinate :179.375Format :NetCDF-4/HDF-5History :Original file generated: Tue Mar 15 12:02:48 2022 GMTIdentifierProductDOI :10.5067/Y9M4NM9MPCGHIdentifierProductDOIAuthority :http://doi.org/Institution :NASA GSFC Global Modeling and Assimilation Office and OCO-2 Project, Jet Propulsion LaboratoryLatitudeResolution :0.5LongName :OCO-2 GEOS Level 3 daily, 0.5x0.625 assimilated CO2LongitudeResolution :0.625NorthBoundingCoordinate :90.0ProductionDateTime :2022-03-15T12:02:48ZRangeBeginningDate :2017-08-01RangeBeginningTime :00:00:00.000000RangeEndingDate :2017-08-01RangeEndingTime :23:59:99.999999ShortName :OCO2_GEOS_L3CO2_DAY_10rSouthBoundingCoordinate :-90.0SpatialCoverage :globalTitle :OCO-2 GEOS Level 3 daily, 0.5x0.625 assimilated CO2VersionID :V10rWestBoundingCoordinate :-180.0\n\n\nIn xarray you can inspect just one data variable using dot notation:\n\nds.XCO2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'XCO2' (time: 2500, lat: 361, lon: 576)&gt; Size: 4GB\ndask.array&lt;open_dataset-XCO2, shape=(2500, 361, 576), dtype=float64, chunksize=(200, 200, 200), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * lat      (lat) float64 3kB -90.0 -89.5 -89.0 -88.5 ... 88.5 89.0 89.5 90.0\n  * lon      (lon) float64 5kB -180.0 -179.4 -178.8 -178.1 ... 178.1 178.8 179.4\n  * time     (time) datetime64[ns] 20kB 2015-01-01T12:00:00 ... 2021-11-04T12...\nAttributes:\n    long_name:  Assimilated dry-air column average CO2 daily mean\n    units:      mol CO2/mol dryxarray.DataArray'XCO2'time: 2500lat: 361lon: 576dask.array&lt;chunksize=(200, 200, 200), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n3.87 GiB\n61.04 MiB\n\n\nShape\n(2500, 361, 576)\n(200, 200, 200)\n\n\nDask graph\n78 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                                       576 361 2500\n\n\n\n\nCoordinates: (3)lat(lat)float64-90.0 -89.5 -89.0 ... 89.5 90.0long_name :latitudeunits :degrees_northarray([-90. , -89.5, -89. , ...,  89. ,  89.5,  90. ], shape=(361,))lon(lon)float64-180.0 -179.4 ... 178.8 179.4long_name :longitudeunits :degrees_eastarray([-180.   , -179.375, -178.75 , ...,  178.125,  178.75 ,  179.375],\n      shape=(576,))time(time)datetime64[ns]2015-01-01T12:00:00 ... 2021-11-...begin_date :20170801begin_time :120000long_name :timearray(['2015-01-01T12:00:00.000000000', '2015-01-02T12:00:00.000000000',\n       '2015-01-03T12:00:00.000000000', ..., '2021-11-02T12:00:00.000000000',\n       '2021-11-03T12:00:00.000000000', '2021-11-04T12:00:00.000000000'],\n      shape=(2500,), dtype='datetime64[ns]')Indexes: (3)latPandasIndexPandasIndex(Index([-90.0, -89.5, -89.0, -88.5, -88.0, -87.5, -87.0, -86.5, -86.0, -85.5,\n       ...\n        85.5,  86.0,  86.5,  87.0,  87.5,  88.0,  88.5,  89.0,  89.5,  90.0],\n      dtype='float64', name='lat', length=361))lonPandasIndexPandasIndex(Index([  -180.0, -179.375,  -178.75, -178.125,   -177.5, -176.875,  -176.25,\n       -175.625,   -175.0, -174.375,\n       ...\n         173.75,  174.375,    175.0,  175.625,   176.25,  176.875,    177.5,\n        178.125,   178.75,  179.375],\n      dtype='float64', name='lon', length=576))timePandasIndexPandasIndex(DatetimeIndex(['2015-01-01 12:00:00', '2015-01-02 12:00:00',\n               '2015-01-03 12:00:00', '2015-01-04 12:00:00',\n               '2015-01-05 12:00:00', '2015-01-06 12:00:00',\n               '2015-01-07 12:00:00', '2015-01-08 12:00:00',\n               '2015-01-09 12:00:00', '2015-01-10 12:00:00',\n               ...\n               '2021-10-26 12:00:00', '2021-10-27 12:00:00',\n               '2021-10-28 12:00:00', '2021-10-29 12:00:00',\n               '2021-10-30 12:00:00', '2021-10-31 12:00:00',\n               '2021-11-01 12:00:00', '2021-11-02 12:00:00',\n               '2021-11-03 12:00:00', '2021-11-04 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=2500, freq=None))Attributes: (2)long_name :Assimilated dry-air column average CO2 daily meanunits :mol CO2/mol dry"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/visualize-zarr.html#plot-data",
    "href": "user-guide/notebooks/quickstarts/visualize-zarr.html#plot-data",
    "title": "Visualize zarr",
    "section": "Plot data",
    "text": "Plot data\nWe can plot the XCO2 variable as an interactive map (with date slider) using hvplot.\n\nds.XCO2.hvplot(\n    x=\"lon\",\n    y=\"lat\",\n    groupby=\"time\",\n    coastline=True,\n    rasterize=True,\n    aggregator=\"mean\",\n    widget_location=\"bottom\",\n    frame_width=600,\n)\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\nThe time slider will only work when running in the notebook. When rendered on a static website the slider has no impact."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html",
    "title": "Downsample zarr",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#run-this-notebook",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#run-this-notebook",
    "title": "Downsample zarr",
    "section": "",
    "text": "You can launch this notebook in VEDA JupyterHub by clicking the link below.\nLaunch in VEDA JupyterHub (requires access)\n\n\nLearn more\n\n\n\nThis notebook was written on the VEDA JupyterHub and as such is designed to be run on a jupyterhub which is associated with an AWS IAM role which has been granted permissions to the VEDA data store via its bucket policy. The instance used provided 16GB of RAM.\nSee (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n\n\n\nThe data is in a protected bucket. Please request access by emailng aimee@developmentseed.org or alexandra@developmentseed.org and providing your affiliation, interest in or expected use of the dataset and an AWS IAM role or user Amazon Resource Name (ARN). The team will help you configure the cognito client.\nYou should then run:\n%run -i 'cognito_login.py'"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#approach",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#approach",
    "title": "Downsample zarr",
    "section": "Approach",
    "text": "Approach\nThis notebook demonstrates 2 strategies for resampling data from a Zarr dataset in order to visualize within the memory limits of a notebook.\n\nDownsample the temporal resolution of the data using xarray.DataArray.resample\nCoarsening the spatial resolution of the data using xarray.DataArray.coarsen\n\nA strategy for visualizing any large amount of data is Datashader which bins data into a fixed 2-D array. Using the rasterize argument within hvplot calls ensures the use of the datashader library to bin the data. Optionally an external Dask cluster is used to parallelize and distribute these large downsampling operations across compute nodes."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#about-the-data",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#about-the-data",
    "title": "Downsample zarr",
    "section": "About the data",
    "text": "About the data\nThe SMAP mission is an orbiting observatory that measures the amount of water in the surface soil everywhere on Earth."
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#load-libraries",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#load-libraries",
    "title": "Downsample zarr",
    "section": "Load libraries",
    "text": "Load libraries\n\nimport xarray as xr\nimport hvplot.xarray\nimport cartopy.crs as ccrs"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#optional-create-and-scale-a-dask-cluster",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#optional-create-and-scale-a-dask-cluster",
    "title": "Downsample zarr",
    "section": "Optional: Create and Scale a Dask Cluster",
    "text": "Optional: Create and Scale a Dask Cluster\nWe create a separate Dask cluster to speed up reprojecting the data (and other potential computations which could be required and are parallelizable).\nNote if you skip this cell you will still be using Dask, youll just be using the machine where you are running this notebook.\n\nfrom dask_gateway import GatewayCluster, Gateway\n\ngateway = Gateway()\nclusters = gateway.list_clusters()\n\n# connect to an existing cluster - this is useful when the kernel shutdown in the middle of an interactive session\nif clusters:\n    cluster = gateway.connect(clusters[0].name)\nelse:\n    cluster = GatewayCluster(shutdown_on_close=True)\n\ncluster.scale(16)\nclient = cluster.get_client()\nclient\n\n\n     \n    \n        Client\n        Client-05313042-8cbb-11f0-816a-9ee98308dd31\n        \n\n\n\nConnection method: Cluster object\nCluster type: dask_gateway.GatewayCluster\n\n\nDashboard: /services/dask-gateway/clusters/prod.ad9ae8551f5e47a48262103ee2e6acb9/status\n\n\n\n\n\n\n        \n            \n                Launch dashboard in JupyterLab\n            \n        \n\n        \n            \n            Cluster Info\n            \n  GatewayCluster\n  \n    Name: prod.ad9ae8551f5e47a48262103ee2e6acb9\n    Dashboard: /services/dask-gateway/clusters/prod.ad9ae8551f5e47a48262103ee2e6acb9/status"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#open-the-dataset-from-s3",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#open-the-dataset-from-s3",
    "title": "Downsample zarr",
    "section": "Open the dataset from S3",
    "text": "Open the dataset from S3\n\nds = xr.open_zarr(\"s3://veda-data-store-staging/EIS/zarr/SPL3SMP.zarr\")\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 68GB\nDimensions:                        (northing_m: 406, easting_m: 964,\n                                    datetime: 1679)\nCoordinates:\n  * datetime                       (datetime) datetime64[ns] 13kB 2018-01-01 ...\n  * easting_m                      (easting_m) float64 8kB -1.735e+07 ... 1.7...\n  * northing_m                     (northing_m) float64 3kB 7.297e+06 ... -7....\nData variables: (12/26)\n    albedo                         (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    albedo_pm                      (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    bulk_density                   (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    bulk_density_pm                (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    clay_fraction                  (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    clay_fraction_pm               (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    ...                             ...\n    static_water_body_fraction     (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    static_water_body_fraction_pm  (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    surface_flag                   (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    surface_flag_pm                (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    surface_temperature            (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n    surface_temperature_pm         (northing_m, easting_m, datetime) float32 3GB dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;xarray.DatasetDimensions:northing_m: 406easting_m: 964datetime: 1679Coordinates: (3)datetime(datetime)datetime64[ns]2018-01-01 ... 2022-09-09array(['2018-01-01T00:00:00.000000000', '2018-01-02T00:00:00.000000000',\n       '2018-01-03T00:00:00.000000000', ..., '2022-09-07T00:00:00.000000000',\n       '2022-09-08T00:00:00.000000000', '2022-09-09T00:00:00.000000000'],\n      shape=(1679,), dtype='datetime64[ns]')easting_m(easting_m)float64-1.735e+07 -1.731e+07 ... 1.735e+07array([-17349514.34, -17313482.12, -17277449.9 , ...,  17277449.08,\n        17313481.3 ,  17349513.52], shape=(964,))northing_m(northing_m)float647.297e+06 7.26e+06 ... -7.297e+06array([ 7296524.72,  7260492.5 ,  7224460.28, ..., -7224459.94, -7260492.16,\n       -7296524.38], shape=(406,))Data variables: (26)albedo(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Diffuse reflecting power of the Earth&apos;s surface used in DCA within the grid cell.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nalbedo_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Diffuse reflecting power of the Earth&apos;s surface used in DCA retrievals within the grid cell.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nbulk_density(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :A unitless value that is indicative of aggregated bulk_density within the 36 km grid cell.valid_max :2.6500000953674316valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nbulk_density_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :A unitless value that is indicative of aggregated bulk density within the 36 km grid cell.valid_max :2.6500000953674316valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nclay_fraction(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :A unitless value that is indicative of aggregated clay fraction within the 36 km grid cell.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nclay_fraction_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :A unitless value that is indicative of aggregated clay fraction within the 36 km grid cell.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nfreeze_thaw_fraction(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Fraction of the 36 km grid cell that is denoted as frozen.  Based on binary flag that specifies freeze thaw conditions in each of the component 3 km grid cells.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nfreeze_thaw_fraction_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Fraction of the 36 km grid cell that is denoted as frozen.  Based on binary flag that specifies freeze thaw conditions in each of the component 3 km grid cells.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\ngrid_surface_status(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Indicates if the grid point lies on land (0) or water (1).valid_max :1valid_min :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\ngrid_surface_status_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Indicates if the grid point lies on land (0) or water (1).valid_max :1valid_min :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nradar_water_body_fraction(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :The fraction of the area of the 36 km grid cell that is covered by water based on the radar detection algorithm.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nradar_water_body_fraction_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :The fraction of the area of the 36 km grid cell that is covered by water based on the radar detection algorithm.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nretrieval_qual_flag(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;flag_masks :1s, 2s, 4s, 8sflag_meanings :Retrieval_recommended Retrieval_attempted Retrieval_success FT_retrieval_successlong_name :Bit flags that record the conditions and the quality of the DCA retrieval algorithms that generate soil moisture for the grid cell.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nretrieval_qual_flag_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;flag_masks :1s, 2s, 4s, 8sflag_meanings :Retrieval_recommended Retrieval_attempted Retrieval_success FT_retrieval_successlong_name :Bit flags that record the conditions and the quality of the DCA retrieval algorithms that generate soil moisture for the grid cell.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nroughness_coefficient(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :A unitless value that is indicative of bare soil roughness used in DCA within the 36 km grid cell.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nroughness_coefficient_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :A unitless value that is indicative of bare soil roughness used in DCA retrievals within the 36 km grid cell.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nsoil_moisture(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Representative DCA soil moisture measurement for the Earth based grid cell.units :cm**3/cm**3valid_max :0.5valid_min :0.019999999552965164\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nsoil_moisture_error(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Net uncertainty measure of soil moisture measure for the Earth based grid cell. - Calculation method is TBD.units :cm**3/cm**3valid_max :0.20000000298023224valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nsoil_moisture_error_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Net uncertainty measure of soil moisture measure for the Earth based grid cell. - Calculation method is TBD.units :cm**3/cm**3valid_max :0.20000000298023224valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nsoil_moisture_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Representative DCA soil moisture measurement for the Earth based grid cell.units :cm**3/cm**3valid_max :0.5valid_min :0.019999999552965164\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nstatic_water_body_fraction(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :The fraction of the area of the 36 km grid cell that is covered by static water based on a Digital Elevation Map.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nstatic_water_body_fraction_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :The fraction of the area of the 36 km grid cell that is covered by static water based on a Digital Elevation Map.valid_max :1.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nsurface_flag(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;flag_masks :1s, 2s, 4s, 8s, 16s, 32s, 64s, 128s, 256s, 512s, 1024s, 2048sflag_meanings :36_km_static_water_body 36_km_radar_water_body_detection 36_km_coastal_proximity 36_km_urban_area 36_km_precipitation 36_km_snow_or_ice 36_km_permanent_snow_or_ice 36_km_radiometer_frozen_ground 36_km_model_frozen_ground 36_km_mountainous_terrain 36_km_dense_vegetation 36_km_nadir_regionlong_name :Bit flags that record ambient surface conditions for the grid cell\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nsurface_flag_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;flag_masks :1s, 2s, 4s, 8s, 16s, 32s, 64s, 128s, 256s, 512s, 1024s, 2048sflag_meanings :36_km_static_water_body 36_km_radar_water_body_detection 36_km_coastal_proximity 36_km_urban_area 36_km_precipitation 36_km_snow_or_ice 36_km_permanent_snow_or_ice 36_km_radar_frozen_ground 36_km_model_frozen_ground 36_km_mountainous_terrain 36_km_dense_vegetation 36_km_nadir_regionlong_name :Bit flags that record ambient surface conditions for the grid cell\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nsurface_temperature(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Temperature at land surface based on GMAO GEOS-5 data.units :Kelvinsvalid_max :350.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nsurface_temperature_pm(northing_m, easting_m, datetime)float32dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;long_name :Temperature at land surface based on GMAO GEOS-5 data.units :Kelvinsvalid_max :350.0valid_min :0.0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nIndexes: (3)datetimePandasIndexPandasIndex(DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n               '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08',\n               '2018-01-09', '2018-01-10',\n               ...\n               '2022-08-31', '2022-09-01', '2022-09-02', '2022-09-03',\n               '2022-09-04', '2022-09-05', '2022-09-06', '2022-09-07',\n               '2022-09-08', '2022-09-09'],\n              dtype='datetime64[ns]', name='datetime', length=1679, freq=None))easting_mPandasIndexPandasIndex(Index([      -17349514.34,       -17313482.12,        -17277449.9,\n             -17241417.68,       -17205385.46,       -17169353.24,\n             -17133321.02,        -17097288.8,       -17061256.58,\n             -17025224.36,\n       ...\n       17025223.540000003,        17061255.76,        17097287.98,\n               17133320.2, 17169352.419999998, 17205384.640000004,\n       17241416.860000003, 17277449.080000002,         17313481.3,\n              17349513.52],\n      dtype='float64', name='easting_m', length=964))northing_mPandasIndexPandasIndex(Index([        7296524.72,          7260492.5,  7224460.279999999,\n               7188428.06,         7152395.84,         7116363.62,\n        7080331.399999999,         7044299.18,         7008266.96,\n               6972234.74,\n       ...\n       -6972234.400000001,        -7008266.62, -7044298.840000001,\n       -7080331.060000001,        -7116363.28, -7152395.500000001,\n       -7188427.720000002,        -7224459.94, -7260492.160000001,\n              -7296524.38],\n      dtype='float64', name='northing_m', length=406))Attributes: (0)\n\n\nSelect the variable of interest (soil moisture for this example).\n\nsoil_moisture = ds.soil_moisture\nsoil_moisture\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'soil_moisture' (northing_m: 406, easting_m: 964,\n                                   datetime: 1679)&gt; Size: 3GB\ndask.array&lt;open_dataset-soil_moisture, shape=(406, 964, 1679), dtype=float32, chunksize=(100, 100, 100), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * datetime    (datetime) datetime64[ns] 13kB 2018-01-01 ... 2022-09-09\n  * easting_m   (easting_m) float64 8kB -1.735e+07 -1.731e+07 ... 1.735e+07\n  * northing_m  (northing_m) float64 3kB 7.297e+06 7.26e+06 ... -7.297e+06\nAttributes:\n    long_name:  Representative DCA soil moisture measurement for the Earth ba...\n    units:      cm**3/cm**3\n    valid_max:  0.5\n    valid_min:  0.019999999552965164xarray.DataArray'soil_moisture'northing_m: 406easting_m: 964datetime: 1679dask.array&lt;chunksize=(100, 100, 100), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.45 GiB\n3.81 MiB\n\n\nShape\n(406, 964, 1679)\n(100, 100, 100)\n\n\nDask graph\n850 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                                                   1679 964 406\n\n\n\n\nCoordinates: (3)datetime(datetime)datetime64[ns]2018-01-01 ... 2022-09-09array(['2018-01-01T00:00:00.000000000', '2018-01-02T00:00:00.000000000',\n       '2018-01-03T00:00:00.000000000', ..., '2022-09-07T00:00:00.000000000',\n       '2022-09-08T00:00:00.000000000', '2022-09-09T00:00:00.000000000'],\n      shape=(1679,), dtype='datetime64[ns]')easting_m(easting_m)float64-1.735e+07 -1.731e+07 ... 1.735e+07array([-17349514.34, -17313482.12, -17277449.9 , ...,  17277449.08,\n        17313481.3 ,  17349513.52], shape=(964,))northing_m(northing_m)float647.297e+06 7.26e+06 ... -7.297e+06array([ 7296524.72,  7260492.5 ,  7224460.28, ..., -7224459.94, -7260492.16,\n       -7296524.38], shape=(406,))Indexes: (3)datetimePandasIndexPandasIndex(DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n               '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08',\n               '2018-01-09', '2018-01-10',\n               ...\n               '2022-08-31', '2022-09-01', '2022-09-02', '2022-09-03',\n               '2022-09-04', '2022-09-05', '2022-09-06', '2022-09-07',\n               '2022-09-08', '2022-09-09'],\n              dtype='datetime64[ns]', name='datetime', length=1679, freq=None))easting_mPandasIndexPandasIndex(Index([      -17349514.34,       -17313482.12,        -17277449.9,\n             -17241417.68,       -17205385.46,       -17169353.24,\n             -17133321.02,        -17097288.8,       -17061256.58,\n             -17025224.36,\n       ...\n       17025223.540000003,        17061255.76,        17097287.98,\n               17133320.2, 17169352.419999998, 17205384.640000004,\n       17241416.860000003, 17277449.080000002,         17313481.3,\n              17349513.52],\n      dtype='float64', name='easting_m', length=964))northing_mPandasIndexPandasIndex(Index([        7296524.72,          7260492.5,  7224460.279999999,\n               7188428.06,         7152395.84,         7116363.62,\n        7080331.399999999,         7044299.18,         7008266.96,\n               6972234.74,\n       ...\n       -6972234.400000001,        -7008266.62, -7044298.840000001,\n       -7080331.060000001,        -7116363.28, -7152395.500000001,\n       -7188427.720000002,        -7224459.94, -7260492.160000001,\n              -7296524.38],\n      dtype='float64', name='northing_m', length=406))Attributes: (4)long_name :Representative DCA soil moisture measurement for the Earth based grid cell.units :cm**3/cm**3valid_max :0.5valid_min :0.019999999552965164"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#strategy-1-downsample-the-temporal-resolution-of-the-data",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#strategy-1-downsample-the-temporal-resolution-of-the-data",
    "title": "Downsample zarr",
    "section": "Strategy 1: Downsample the temporal resolution of the data",
    "text": "Strategy 1: Downsample the temporal resolution of the data\nTo plot one day from every month, resample the data to 1 observation a month.\n\nsomo_one_month = soil_moisture.resample(datetime=\"1ME\").nearest()\n\nNotice that that took very little time because it was just setting up the calculation. We can call .compute() to tell dask to trigger evaluation.\n\n%%time\n\nsomo_one_month_evaluated = somo_one_month.compute()\n\nCPU times: user 94.9 ms, sys: 64.3 ms, total: 159 ms\nWall time: 3.97 s\n\n\n\nQuick plot\nWe can generate a quick plot using hvplot and datashader.\n\nsomo_one_month_evaluated.hvplot(\n    x=\"easting_m\",\n    y=\"northing_m\",\n    groupby=\"datetime\",\n    crs=ccrs.epsg(6933),  # this is a workaround for https://github.com/holoviz/hvplot/issues/1329\n    rasterize=True,\n    geo=True,\n    coastline=True,\n    aggregator=\"mean\",\n    frame_height=400,\n    widget_location=\"bottom\",\n)\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nReproject before plotting\nReproject the data for map visualization.\n\nsomo_one_month = somo_one_month.transpose(\"datetime\", \"northing_m\", \"easting_m\")\nsomo_one_month = somo_one_month.rio.set_spatial_dims(\n    x_dim=\"easting_m\", y_dim=\"northing_m\"\n)\nsomo_one_month = somo_one_month.rio.write_crs(\"EPSG:6933\")\nsomo_reprojected = somo_one_month.rio.reproject(\"EPSG:4326\")\nsomo_reprojected\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'soil_moisture' (datetime: 57, y: 1046, x: 2214)&gt; Size: 528MB\narray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]],\n      shape=(57, 1046, 2214), dtype=float32)\nCoordinates:\n  * x            (x) float64 18kB -179.9 -179.8 -179.6 ... 179.6 179.8 179.9\n  * y            (y) float64 8kB 84.96 84.8 84.64 84.48 ... -84.64 -84.8 -84.96\n  * datetime     (datetime) datetime64[ns] 456B 2018-01-31 ... 2022-09-30\n    spatial_ref  int64 8B 0\nAttributes:\n    long_name:  Representative DCA soil moisture measurement for the Earth ba...\n    units:      cm**3/cm**3\n    valid_max:  0.5\n    valid_min:  0.019999999552965164xarray.DataArray'soil_moisture'datetime: 57y: 1046x: 2214nan nan nan nan nan nan nan nan ... nan nan nan nan nan nan nan nanarray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]],\n      shape=(57, 1046, 2214), dtype=float32)Coordinates: (4)x(x)float64-179.9 -179.8 ... 179.8 179.9axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([-179.918425, -179.755825, -179.593224, ...,  179.591393,  179.753993,\n        179.916594], shape=(2214,))y(y)float6484.96 84.8 84.64 ... -84.8 -84.96axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([ 84.963262,  84.800655,  84.638047, ..., -84.636773, -84.79938 ,\n       -84.961988], shape=(1046,))datetime(datetime)datetime64[ns]2018-01-31 ... 2022-09-30array(['2018-01-31T00:00:00.000000000', '2018-02-28T00:00:00.000000000',\n       '2018-03-31T00:00:00.000000000', '2018-04-30T00:00:00.000000000',\n       '2018-05-31T00:00:00.000000000', '2018-06-30T00:00:00.000000000',\n       '2018-07-31T00:00:00.000000000', '2018-08-31T00:00:00.000000000',\n       '2018-09-30T00:00:00.000000000', '2018-10-31T00:00:00.000000000',\n       '2018-11-30T00:00:00.000000000', '2018-12-31T00:00:00.000000000',\n       '2019-01-31T00:00:00.000000000', '2019-02-28T00:00:00.000000000',\n       '2019-03-31T00:00:00.000000000', '2019-04-30T00:00:00.000000000',\n       '2019-05-31T00:00:00.000000000', '2019-06-30T00:00:00.000000000',\n       '2019-07-31T00:00:00.000000000', '2019-08-31T00:00:00.000000000',\n       '2019-09-30T00:00:00.000000000', '2019-10-31T00:00:00.000000000',\n       '2019-11-30T00:00:00.000000000', '2019-12-31T00:00:00.000000000',\n       '2020-01-31T00:00:00.000000000', '2020-02-29T00:00:00.000000000',\n       '2020-03-31T00:00:00.000000000', '2020-04-30T00:00:00.000000000',\n       '2020-05-31T00:00:00.000000000', '2020-06-30T00:00:00.000000000',\n       '2020-07-31T00:00:00.000000000', '2020-08-31T00:00:00.000000000',\n       '2020-09-30T00:00:00.000000000', '2020-10-31T00:00:00.000000000',\n       '2020-11-30T00:00:00.000000000', '2020-12-31T00:00:00.000000000',\n       '2021-01-31T00:00:00.000000000', '2021-02-28T00:00:00.000000000',\n       '2021-03-31T00:00:00.000000000', '2021-04-30T00:00:00.000000000',\n       '2021-05-31T00:00:00.000000000', '2021-06-30T00:00:00.000000000',\n       '2021-07-31T00:00:00.000000000', '2021-08-31T00:00:00.000000000',\n       '2021-09-30T00:00:00.000000000', '2021-10-31T00:00:00.000000000',\n       '2021-11-30T00:00:00.000000000', '2021-12-31T00:00:00.000000000',\n       '2022-01-31T00:00:00.000000000', '2022-02-28T00:00:00.000000000',\n       '2022-03-31T00:00:00.000000000', '2022-04-30T00:00:00.000000000',\n       '2022-05-31T00:00:00.000000000', '2022-06-30T00:00:00.000000000',\n       '2022-07-31T00:00:00.000000000', '2022-08-31T00:00:00.000000000',\n       '2022-09-30T00:00:00.000000000'], dtype='datetime64[ns]')spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-179.99972539195164 0.1626005508861423 0.0 85.04456635019852 0.0 -0.16260789541619725array(0)Indexes: (3)xPandasIndexPandasIndex(Index([-179.91842511650856, -179.75582456562242, -179.59322401473628,\n       -179.43062346385014,   -179.268022912964, -179.10542236207786,\n        -178.9428218111917, -178.78022126030555,  -178.6176207094194,\n       -178.45502015853327,\n       ...\n        178.45318903654908,  178.61578958743524,  178.77839013832136,\n        178.94099068920752,  179.10359124009364,   179.2661917909798,\n        179.42879234186597,  179.59139289275208,  179.75399344363825,\n        179.91659399452436],\n      dtype='float64', name='x', length=2214))yPandasIndexPandasIndex(Index([ 84.96326240249043,  84.80065450707423,  84.63804661165804,\n        84.47543871624184,  84.31283082082564,  84.15022292540944,\n        83.98761502999325,  83.82500713457705,  83.66239923916085,\n        83.49979134374465,\n       ...\n       -83.49851724868991, -83.66112514410612, -83.82373303952231,\n        -83.9863409349385, -84.14894883035471,  -84.3115567257709,\n       -84.47416462118711,  -84.6367725166033, -84.79938041201949,\n        -84.9619883074357],\n      dtype='float64', name='y', length=1046))datetimePandasIndexPandasIndex(DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30',\n               '2018-05-31', '2018-06-30', '2018-07-31', '2018-08-31',\n               '2018-09-30', '2018-10-31', '2018-11-30', '2018-12-31',\n               '2019-01-31', '2019-02-28', '2019-03-31', '2019-04-30',\n               '2019-05-31', '2019-06-30', '2019-07-31', '2019-08-31',\n               '2019-09-30', '2019-10-31', '2019-11-30', '2019-12-31',\n               '2020-01-31', '2020-02-29', '2020-03-31', '2020-04-30',\n               '2020-05-31', '2020-06-30', '2020-07-31', '2020-08-31',\n               '2020-09-30', '2020-10-31', '2020-11-30', '2020-12-31',\n               '2021-01-31', '2021-02-28', '2021-03-31', '2021-04-30',\n               '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31',\n               '2021-09-30', '2021-10-31', '2021-11-30', '2021-12-31',\n               '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-30',\n               '2022-05-31', '2022-06-30', '2022-07-31', '2022-08-31',\n               '2022-09-30'],\n              dtype='datetime64[ns]', name='datetime', freq=None))Attributes: (4)long_name :Representative DCA soil moisture measurement for the Earth based grid cell.units :cm**3/cm**3valid_max :0.5valid_min :0.019999999552965164\n\n\n\n[!NOTE] This is now a fully materialized data array - when we reprojected we triggered an implicit compute.\n\n\nsomo_reprojected.hvplot(\n    x=\"x\",\n    y=\"y\",\n    groupby=\"datetime\",\n    coastline=True,\n    rasterize=True,\n    aggregator=\"mean\",\n    frame_height=400,\n    widget_location=\"bottom\",\n)"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#strategy-2-coarsen-spatial-resolution-of-the-data",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#strategy-2-coarsen-spatial-resolution-of-the-data",
    "title": "Downsample zarr",
    "section": "Strategy 2: Coarsen spatial resolution of the data",
    "text": "Strategy 2: Coarsen spatial resolution of the data\nBelow, we coarsen the spatial resolution of the data by a factor of 4 in the x and 2 in the y. These values were chosen because they can be used with the exact boundary argument as the dimensions size is a multiple of these values.\nYou can also coarsen by datetime, using the same strategy as below but replacing easting_m and northing_m with datetime. If {datetime: n} is the value given to the dim argument, this would create a mean of the soil moisture average for n days.\nOnce the data has been coarsened, again it is reprojected for map visualization and then visualized.\n\ncoarsened = soil_moisture.coarsen(dim={\"easting_m\": 4, \"northing_m\": 2}).mean()\n\ncoarsened = coarsened.transpose(\"datetime\", \"northing_m\", \"easting_m\")\ncoarsened = coarsened.rio.set_spatial_dims(x_dim=\"easting_m\", y_dim=\"northing_m\")\ncoarsened = coarsened.rio.write_crs(\"epsg:6933\")\ncoarsened_reprojected = coarsened.rio.reproject(\"EPSG:4326\")\ncoarsened_reprojected\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'soil_moisture' (datetime: 1679, y: 315, x: 667)&gt; Size: 1GB\narray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]],\n      shape=(1679, 315, 667), dtype=float32)\nCoordinates:\n  * x            (x) float64 5kB -179.7 -179.2 -178.7 ... 178.6 179.2 179.7\n  * y            (y) float64 3kB 84.77 84.23 83.7 83.16 ... -83.64 -84.18 -84.72\n  * datetime     (datetime) datetime64[ns] 13kB 2018-01-01 ... 2022-09-09\n    spatial_ref  int64 8B 0\nAttributes:\n    long_name:   Representative DCA soil moisture measurement for the Earth b...\n    units:       cm**3/cm**3\n    valid_max:   0.5\n    valid_min:   0.019999999552965164\n    _FillValue:  nanxarray.DataArray'soil_moisture'datetime: 1679y: 315x: 667nan nan nan nan nan nan nan nan ... nan nan nan nan nan nan nan nanarray([[[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n...\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        ...,\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan],\n        [nan, nan, nan, ..., nan, nan, nan]]],\n      shape=(1679, 315, 667), dtype=float32)Coordinates: (4)x(x)float64-179.7 -179.2 ... 179.2 179.7axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([-179.729872, -179.190164, -178.650456, ...,  178.636044,  179.175751,\n        179.715459], shape=(667,))y(y)float6484.77 84.23 83.7 ... -84.18 -84.72axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([ 84.774672,  84.234883,  83.695095, ..., -83.639381, -84.17917 ,\n       -84.718958], shape=(315,))datetime(datetime)datetime64[ns]2018-01-01 ... 2022-09-09array(['2018-01-01T00:00:00.000000000', '2018-01-02T00:00:00.000000000',\n       '2018-01-03T00:00:00.000000000', ..., '2022-09-07T00:00:00.000000000',\n       '2022-09-08T00:00:00.000000000', '2022-09-09T00:00:00.000000000'],\n      shape=(1679,), dtype='datetime64[ns]')spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-179.99972539195164 0.5397077035841558 0.0 85.04456635019838 0.0 -0.5397886314149526array(0)Indexes: (3)xPandasIndexPandasIndex(Index([-179.72987154015956,  -179.1901638365754, -178.65045613299125,\n        -178.1107484294071, -177.57104072582294, -177.03133302223878,\n       -176.49162531865463, -175.95191761507047, -175.41220991148631,\n       -174.87250220790216,\n       ...\n        174.85808971463078,  175.39779741821494,   175.9375051217991,\n        176.47721282538325,   177.0169205289674,  177.55662823255156,\n        178.09633593613572,  178.63604363971987,  179.17575134330403,\n        179.71545904688818],\n      dtype='float64', name='x', length=667))yPandasIndexPandasIndex(Index([  84.7746720344909,  84.23488340307595,    83.695094771661,\n        83.15530614024604,  82.61551750883109,  82.07572887741614,\n        81.53594024600119,  80.99615161458624,  80.45636298317129,\n        79.91657435175634,\n       ...\n       -79.86086054706963, -80.40064917848458, -80.94043780989954,\n       -81.48022644131449, -82.02001507272944, -82.55980370414439,\n       -83.09959233555936, -83.63938096697431, -84.17916959838927,\n       -84.71895822980422],\n      dtype='float64', name='y', length=315))datetimePandasIndexPandasIndex(DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n               '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08',\n               '2018-01-09', '2018-01-10',\n               ...\n               '2022-08-31', '2022-09-01', '2022-09-02', '2022-09-03',\n               '2022-09-04', '2022-09-05', '2022-09-06', '2022-09-07',\n               '2022-09-08', '2022-09-09'],\n              dtype='datetime64[ns]', name='datetime', length=1679, freq=None))Attributes: (5)long_name :Representative DCA soil moisture measurement for the Earth based grid cell.units :cm**3/cm**3valid_max :0.5valid_min :0.019999999552965164_FillValue :nan\n\n\n\ncoarsened_reprojected.hvplot(\n    x=\"x\",\n    y=\"y\",\n    groupby=\"datetime\",\n    coastline=True,\n    rasterize=True,\n    aggregator=\"mean\",\n    frame_height=400,\n    widget_location=\"bottom\",\n)"
  },
  {
    "objectID": "user-guide/notebooks/quickstarts/downsample-zarr.html#cleanup",
    "href": "user-guide/notebooks/quickstarts/downsample-zarr.html#cleanup",
    "title": "Downsample zarr",
    "section": "Cleanup",
    "text": "Cleanup\nWhen using a remote Dask cluster it is recommented to explicitly close the cluster.\nclient.shutdown()"
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "",
    "text": "Query the GRSS VEDA STAC API to discover available dates and temporal frequency for the Wetland Methane Emissions collection.\nGenerate map tiles using the raster API endpoint.\nCompare methane emissions across different time periods using side-by-side visualization with folium.plugins.DualMap.\nCompute zonal statistics for a specified region of interest.",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Datasets",
      "Wetland Methane Emissions, LPJ-EOSIM Model"
    ]
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#overview",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#overview",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "",
    "text": "Query the GRSS VEDA STAC API to discover available dates and temporal frequency for the Wetland Methane Emissions collection.\nGenerate map tiles using the raster API endpoint.\nCompare methane emissions across different time periods using side-by-side visualization with folium.plugins.DualMap.\nCompute zonal statistics for a specified region of interest.",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Datasets",
      "Wetland Methane Emissions, LPJ-EOSIM Model"
    ]
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#background",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#background",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Background",
    "text": "Background\nWetland ecosystems represent the dominant natural source of atmospheric methane (CH), accounting for approximately one-third of total global emissions from both natural and human-caused sources. The production of methane in wetlands occurs through microbial decomposition of organic matter in waterlogged, oxygen-depleted soils.\nThe LPJ-EOSIM (Lund-Potsdam-Jena Earth Observation SIMulator) model provides global estimates of wetland methane emissions at 0.5  0.5 spatial resolution. The model simulates wetland extent and incorporates key environmental parameters including soil moisture, temperature, and carbon content to estimate CH flux rates.\nThis dataset reveals concentrated methane sources in tropical regions and high-latitude ecosystems. The model outputs are used with NASAs GEOS atmospheric model to understand how wetland emissions influence global methane concentrations.",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Datasets",
      "Wetland Methane Emissions, LPJ-EOSIM Model"
    ]
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#required-libraries",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#required-libraries",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Required Libraries",
    "text": "Required Libraries\nInstall dependencies if running outside the hub environment:\n%pip install requests folium rasterstats pystac_client pandas matplotlib --quiet",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Datasets",
      "Wetland Methane Emissions, LPJ-EOSIM Model"
    ]
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#connect-to-the-stac-api",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#connect-to-the-stac-api",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Connect to the STAC API",
    "text": "Connect to the STAC API\nImport required libraries and configure the API endpoints to access the GRSS VEDA STAC catalog.\n\nimport requests\nimport folium\nimport folium.plugins\nfrom folium import Map, TileLayer\nfrom pystac_client import Client\nimport branca\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n# Configure API endpoints for the GRSS VEDA platform\nSTAC_API_URL = \"https://api.dev.veda.grss.cloud/stac\"\nRASTER_API_URL = \"https://api.dev.veda.grss.cloud/raster\"\n\n# Collection identifier for wetland methane emissions\ncollection_name = \"LPJ_EOSIM_L2_MCH4E.001\"\n\n# Asset containing the ensemble mean CH4 emissions data\nasset_name = \"ensemble-mean-ch4-wetlands-emissions\"\n\n\n# Retrieve collection metadata\ncollection = requests.get(f\"{STAC_API_URL}/collections/{collection_name}\").json()\ncollection\n\n{'id': 'LPJ_EOSIM_L2_MCH4E.001',\n 'type': 'Collection',\n 'links': [{'rel': 'items',\n   'type': 'application/geo+json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/LPJ_EOSIM_L2_MCH4E.001/items'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/'},\n  {'rel': 'self',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/LPJ_EOSIM_L2_MCH4E.001'},\n  {'rel': 'http://www.opengis.net/def/rel/ogc/1.0/queryables',\n   'type': 'application/schema+json',\n   'title': 'Queryables',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/LPJ_EOSIM_L2_MCH4E.001/queryables'}],\n 'title': '(Monthly) Wetland Methane Emissions, LPJ-EOSIM Model v2',\n 'assets': {},\n 'extent': {'spatial': {'bbox': [[-180, -90, 180, 90]]},\n  'temporal': {'interval': [['2017-06-01T00:00:00+00:00',\n     '2023-12-31T00:00:00+00:00']]}},\n 'license': 'CC0-1.0',\n 'renders': {'dashboard': {'assets': ['ensemble-mean-ch4-wetlands-emissions'],\n   'rescale': [[0, 3e-09]],\n   'colormap_name': 'magma'},\n  'era5-ch4-wetlands-emissions': {'assets': ['era5-ch4-wetlands-emissions'],\n   'rescale': [[0, 3e-09]],\n   'colormap_name': 'magma'},\n  'merra2-ch4-wetlands-emissions': {'assets': ['merra2-ch4-wetlands-emissions'],\n   'rescale': [[0, 3e-09]],\n   'colormap_name': 'magma'},\n  'ensemble-mean-ch4-wetlands-emissions': {'assets': ['ensemble-mean-ch4-wetlands-emissions'],\n   'rescale': [[0, 3e-09]],\n   'colormap_name': 'magma'}},\n 'providers': [{'name': 'NASA'}],\n 'summaries': {'datetime': ['2017-06-01T00:00:00Z', '2023-12-01T00:00:00Z']},\n 'description': 'Global, monthly estimates of methane (CH) emissions from terrestrial wetlands at 0.5 x 0.5 degree spatial resolution using the Earth Observation SIMulator version (LPJ-EOSIM) of the Lund-Potsdam-Jena Dynamic Global Vegetation Model (LPJ-DGVM). Methane emissions from vegetated wetlands are estimated to be the largest natural source of methane in the global CH budget, contributing to roughly one third of the total of natural and anthropogenic emissions. Wetland CH is produced by microbes breaking down organic matter in the oxygen deprived environment of inundated soils. Due to limited data availability, the details of the role of wetland CH emissions have thus far been underrepresented. The LPJ-EOSIM model estimates wetland methane emissions by simulating wetland extent and using characteristics of these inundated areas such as soil moisture, temperature, and carbon content to estimate CH quantities emitted into the atmosphere. Input climate forcing data comes from Modern-Era Retrospective analysis for Research and Applications Version 2 (MERRA-2) data and ECMWF Re-Analysis data (ERA5). An ensemble layer provides the result of the mean of the MERRA-2 and ERA5 layers. The source data can be found at https://doi.org/10.5067/Community/LPJ-EOSIM/LPJ_EOSIM_L2_MCH4E.001 and https://doi.org/10.5067/Community/LPJ-EOSIM/LPJ_EOSIM_L2_MCH4E_LL.001.',\n 'item_assets': {'cog_default': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n   'roles': ['data', 'layer'],\n   'title': 'Default COG Layer',\n   'description': 'Cloud optimized default layer to display on map'}},\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/render/v1.0.0/schema.json',\n  'https://stac-extensions.github.io/item-assets/v1.0.0/schema.json'],\n 'dashboard:is_periodic': True,\n 'dashboard:time_density': 'month'}\n\n\nThe collection metadata shows temporal coverage from 1990 to present with daily observations, as indicated by dashboard:time_density.\n\ndef count_collection_items(collection_id):\n    \"\"\"Count total items in a STAC collection using pagination.\"\"\"\n    count = 0\n    items_url = f\"{STAC_API_URL}/collections/{collection_id}/items\"\n\n    while True:\n        response = requests.get(items_url)\n        if not response.ok:\n            print(\"Error retrieving items\")\n            break\n\n        stac = response.json()\n        count += int(stac.get(\"numberReturned\", 0))\n\n        next_link = [link for link in stac[\"links\"] if link[\"rel\"] == \"next\"]\n        if not next_link:\n            break\n        items_url = next_link[0][\"href\"]\n\n    return count\n\n\n# Fetch available items from the collection\ntotal_count = count_collection_items(collection_name)\nitems = requests.get(f\"{STAC_API_URL}/collections/{collection_name}/items?limit=600\").json()[\"features\"]\nprint(f\"Retrieved {len(items)} items from collection\")\n\nRetrieved 79 items from collection\n\n\n\n# Inspect the structure of an individual item\nitems[0]\n\n{'id': 'LPJ_EOSIM_L2_MCH4E.001-202312',\n 'bbox': [-180.0, -90.0, 180.0, 90.0],\n 'type': 'Feature',\n 'links': [{'rel': 'collection',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/LPJ_EOSIM_L2_MCH4E.001'},\n  {'rel': 'parent',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/LPJ_EOSIM_L2_MCH4E.001'},\n  {'rel': 'root',\n   'type': 'application/json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/'},\n  {'rel': 'self',\n   'type': 'application/geo+json',\n   'href': 'https://api.dev.veda.grss.cloud/stac/collections/LPJ_EOSIM_L2_MCH4E.001/items/LPJ_EOSIM_L2_MCH4E.001-202312'},\n  {'title': 'Map of Item',\n   'href': 'https://api.dev.veda.grss.cloud/raster/collections/LPJ_EOSIM_L2_MCH4E.001/items/LPJ_EOSIM_L2_MCH4E.001-202312/WebMercatorQuad/map?assets=ensemble-mean-ch4-wetlands-emissions&rescale=0%2C3e-09&colormap_name=magma',\n   'rel': 'preview',\n   'type': 'text/html'}],\n 'assets': {'era5-ch4-wetlands-emissions': {'href': 's3://ieee-grss-data-store/LPJ_EOSIM_L2_MCH4E.001/LPJ_EOSIM_L2_MCH4E_ERA5_001_202312.tif',\n   'type': 'image/tiff; application=geotiff',\n   'roles': ['data', 'layer'],\n   'title': '(Monthly) Wetland Methane Emissions, ERA5 LPJ-EOSIM Model v2',\n   'proj:bbox': [-180.0, -90.0, 180.0, 90.0],\n   'proj:epsg': 4326,\n   'proj:shape': [360, 720],\n   'description': 'Methane emissions from wetlands in units of grams of methane per meter squared per second. ECMWF Re-Analysis (ERA5) as input to LPJ-EOSIM model.',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -9999.0,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 3.2194256149864486e-09,\n      'min': 0.0,\n      'count': 11,\n      'buckets': [61519, 551, 176, 86, 47, 33, 22, 19, 6, 2]},\n     'statistics': {'mean': 2.1687599436592488e-11,\n      'stddev': 1.1635106754765193e-10,\n      'maximum': 3.2194256149864486e-09,\n      'minimum': 0.0,\n      'valid_percent': 24.097608024691358}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [180.0, -90.0],\n      [180.0, 90.0],\n      [-180.0, 90.0],\n      [-180.0, -90.0]]]},\n   'proj:transform': [0.5, 0.0, -180.0, 0.0, -0.5, 90.0, 0.0, 0.0, 1.0]},\n  'merra2-ch4-wetlands-emissions': {'href': 's3://ieee-grss-data-store/LPJ_EOSIM_L2_MCH4E.001/LPJ_EOSIM_L2_MCH4E_MERRA2_001_202312.tif',\n   'type': 'image/tiff; application=geotiff',\n   'roles': ['data', 'layer'],\n   'title': '(Monthly) Wetland Methane Emissions, MERRA-2 LPJ-EOSIM Model v2',\n   'proj:bbox': [-180.0, -90.0, 180.0, 90.0],\n   'proj:epsg': 4326,\n   'proj:shape': [360, 720],\n   'description': 'Methane emissions from wetlands in units of grams of methane per meter squared per second. Modern-Era Retrospective analysis for Research and Applications Version 2 (MERRA-2) data as input to LPJ-EOSIM model.',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -9999.0,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 3.598020326123219e-09,\n      'min': 0.0,\n      'count': 11,\n      'buckets': [61509, 531, 232, 102, 52, 14, 8, 7, 0, 1]},\n     'statistics': {'mean': 2.263860874804124e-11,\n      'stddev': 1.1585119186254324e-10,\n      'maximum': 3.598020326123219e-09,\n      'minimum': 0.0,\n      'valid_percent': 24.095679012345677}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [180.0, -90.0],\n      [180.0, 90.0],\n      [-180.0, 90.0],\n      [-180.0, -90.0]]]},\n   'proj:transform': [0.5, 0.0, -180.0, 0.0, -0.5, 90.0, 0.0, 0.0, 1.0]},\n  'ensemble-mean-ch4-wetlands-emissions': {'href': 's3://ieee-grss-data-store/LPJ_EOSIM_L2_MCH4E.001/LPJ_EOSIM_L2_MCH4E_ensemble_mean_001_202312.tif',\n   'type': 'image/tiff; application=geotiff',\n   'roles': ['data', 'layer'],\n   'title': '(Monthly) Wetland Methane Emissions, Ensemble Mean LPJ-EOSIM Model v2',\n   'proj:bbox': [-180.0, -90.0, 180.0, 90.0],\n   'proj:epsg': 4326,\n   'proj:shape': [360, 720],\n   'description': 'Methane emissions from wetlands in units of grams of methane per meter squared per second. Ensemble of multiple climate forcing data sources input to LPJ-EOSIM model.',\n   'raster:bands': [{'scale': 1.0,\n     'nodata': -9999.0,\n     'offset': 0.0,\n     'sampling': 'area',\n     'data_type': 'float32',\n     'histogram': {'max': 3.037322837684542e-09,\n      'min': 0.0,\n      'count': 11,\n      'buckets': [61377, 582, 255, 111, 60, 35, 19, 9, 7, 1]},\n     'statistics': {'mean': 2.2163971297311943e-11,\n      'stddev': 1.1311244931150401e-10,\n      'maximum': 3.037322837684542e-09,\n      'minimum': 0.0,\n      'valid_percent': 24.095679012345677}}],\n   'proj:geometry': {'type': 'Polygon',\n    'coordinates': [[[-180.0, -90.0],\n      [180.0, -90.0],\n      [180.0, 90.0],\n      [-180.0, 90.0],\n      [-180.0, -90.0]]]},\n   'proj:transform': [0.5, 0.0, -180.0, 0.0, -0.5, 90.0, 0.0, 0.0, 1.0]},\n  'rendered_preview': {'title': 'Rendered preview',\n   'href': 'https://api.dev.veda.grss.cloud/raster/collections/LPJ_EOSIM_L2_MCH4E.001/items/LPJ_EOSIM_L2_MCH4E.001-202312/preview.png?assets=ensemble-mean-ch4-wetlands-emissions&rescale=0%2C3e-09&colormap_name=magma',\n   'rel': 'preview',\n   'roles': ['overview'],\n   'type': 'image/png'}},\n 'geometry': {'type': 'Polygon',\n  'coordinates': [[[-180, -90],\n    [180, -90],\n    [180, 90],\n    [-180, 90],\n    [-180, -90]]]},\n 'collection': 'LPJ_EOSIM_L2_MCH4E.001',\n 'properties': {'end_datetime': '2023-12-31T00:00:00Z',\n  'start_datetime': '2023-12-01T00:00:00Z'},\n 'stac_version': '1.0.0',\n 'stac_extensions': ['https://stac-extensions.github.io/raster/v1.1.0/schema.json',\n  'https://stac-extensions.github.io/projection/v1.1.0/schema.json']}\n\n\nSet rescale values for visualization:\n\nrescale_values = {'max': 0.0003, 'min': 0.0}",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Datasets",
      "Wetland Methane Emissions, LPJ-EOSIM Model"
    ]
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#visualize-methane-emissions-over-time",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#visualize-methane-emissions-over-time",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Visualize Methane Emissions Over Time",
    "text": "Visualize Methane Emissions Over Time\nGenerate map tiles using the Raster API to compare emissions across different dates.\n\n# Index items by date for easy lookup\nitems_by_date = {item[\"properties\"][\"start_datetime\"][:10]: item for item in items}\n\n\nitems_by_date['2023-07-01']['id']\n\n'LPJ_EOSIM_L2_MCH4E.001-202307'\n\n\n\ncolor_map = \"magma\"\n\n# Fetch tiles for summer observation (July)\nsummer_date = '2023-07-01'\nsummer_tile = requests.get(\n    f\"{RASTER_API_URL}/collections/{collection_name}/items/{items_by_date[summer_date]['id']}/WebMercatorQuad/tilejson.json?\"\n    f\"&assets={asset_name}\"\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\"\n).json()\n\nsummer_tile\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://api.dev.veda.grss.cloud/raster/collections/LPJ_EOSIM_L2_MCH4E.001/items/LPJ_EOSIM_L2_MCH4E.001-202307/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?assets=ensemble-mean-ch4-wetlands-emissions&color_formula=gamma+r+1.05&colormap_name=magma&rescale=0.0%2C0.0003'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}\n\n\n\n# Fetch tiles for winter observation (January)\nwinter_date = '2023-01-01'\nwinter_tile = requests.get(\n    f\"{RASTER_API_URL}/collections/{items_by_date[winter_date]['collection']}/items/{items_by_date[winter_date]['id']}/WebMercatorQuad/tilejson.json?\"\n    f\"&assets={asset_name}\"\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\"\n).json()\n\nwinter_tile\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://api.dev.veda.grss.cloud/raster/collections/LPJ_EOSIM_L2_MCH4E.001/items/LPJ_EOSIM_L2_MCH4E.001-202301/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?assets=ensemble-mean-ch4-wetlands-emissions&color_formula=gamma+r+1.05&colormap_name=magma&rescale=0.0%2C0.0003'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Datasets",
      "Wetland Methane Emissions, LPJ-EOSIM Model"
    ]
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#side-by-side-comparison-summer-vs-winter-emissions",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#side-by-side-comparison-summer-vs-winter-emissions",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Side-by-Side Comparison: Summer vs Winter Emissions",
    "text": "Side-by-Side Comparison: Summer vs Winter Emissions\n\n# Compare summer and winter emissions over Southeast Asia\nmap_ = folium.plugins.DualMap(location=(15, 100), zoom_start=4)\n\nsummer_layer = TileLayer(\n    tiles=summer_tile[\"tiles\"][0],\n    attr=\"GRSS VEDA\",\n    opacity=0.6,\n)\nsummer_layer.add_to(map_.m1)\n\nwinter_layer = TileLayer(\n    tiles=winter_tile[\"tiles\"][0],\n    attr=\"GRSS VEDA\",\n    opacity=0.6,\n)\nwinter_layer.add_to(map_.m2)\n\nmap_\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Datasets",
      "Wetland Methane Emissions, LPJ-EOSIM Model"
    ]
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#zonal-statistics-analysis",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#zonal-statistics-analysis",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Zonal Statistics Analysis",
    "text": "Zonal Statistics Analysis\nDefine a region of interest to compute statistics over time. Here we analyze emissions across the Amazon basin.\n\n# Define Amazon basin region\namazon_aoi = {\n    \"type\": \"Feature\",\n    \"properties\": {},\n    \"geometry\": {\n        \"coordinates\": [\n            [\n                [-70, -10],\n                [-70, 5],\n                [-50, 5],\n                [-50, -10],\n                [-70, -10]\n            ]\n        ],\n        \"type\": \"Polygon\",\n    },\n}\n\n\n# Display the AOI on a map\naoi_map = Map(\n    tiles=\"OpenStreetMap\",\n    location=[-2, -60],\n    zoom_start=4,\n)\n\nfolium.GeoJson(amazon_aoi, name=\"Amazon Basin\").add_to(aoi_map)\naoi_map\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n# Refresh items list\nitems = requests.get(\n    f\"{STAC_API_URL}/collections/{collection_name}/items?limit=600\"\n).json()[\"features\"]\nprint(f\"Processing {len(items)} items\")\n\nProcessing 79 items\n\n\n\ndef compute_statistics(item, geojson):\n    \"\"\"Calculate zonal statistics for a single item over the given AOI.\"\"\"\n    result = requests.post(\n        f\"{RASTER_API_URL}/cog/statistics\",\n        params={\"url\": item[\"assets\"][asset_name][\"href\"]},\n        json=geojson,\n    ).json()\n\n    return {\n        **result[\"properties\"],\n        \"datetime\": item[\"properties\"][\"start_datetime\"],\n    }\n\n\n%%time\n# Compute statistics for all available items\nstats = [compute_statistics(item, amazon_aoi) for item in items]\n\nCPU times: user 1.16 s, sys: 164 ms, total: 1.32 s\nWall time: 1min 5s\n\n\n\n# Preview statistics from first item\nstats[0]\n\n{'statistics': {'b1': {'min': 0.0,\n   'max': 1.9596972933300094e-09,\n   'mean': 1.3262628495436246e-10,\n   'count': 1184.0,\n   'sum': 1.5702951827734069e-07,\n   'std': 2.2244537361546118e-10,\n   'median': 4.504550898953852e-11,\n   'majority': 0.0,\n   'minority': 3.515131938661571e-16,\n   'unique': 1175.0,\n   'histogram': [[946, 127, 48, 31, 16, 7, 4, 3, 0, 2],\n    [0.0,\n     1.9596972655744338e-10,\n     3.9193945311488676e-10,\n     5.879091657945423e-10,\n     7.838789062297735e-10,\n     9.798486466650047e-10,\n     1.1758183315890847e-09,\n     1.371788127535467e-09,\n     1.567757812459547e-09,\n     1.763727497383627e-09,\n     1.9596972933300094e-09]],\n   'valid_percent': 98.67,\n   'masked_pixels': 16.0,\n   'valid_pixels': 1184.0,\n   'percentile_2': 3.5622706499004175e-13,\n   'percentile_98': 8.656201866408253e-10}},\n 'datetime': '2023-12-01T00:00:00Z'}\n\n\n\ndef format_stats_dataframe(stats_json):\n    \"\"\"Convert statistics JSON to a pandas DataFrame.\"\"\"\n    df = pd.json_normalize(stats_json)\n    df.columns = [col.replace(\"statistics.b1.\", \"\") for col in df.columns]\n    df[\"date\"] = pd.to_datetime(df[\"datetime\"])\n    return df\n\ndf = format_stats_dataframe(stats)\ndf.head()\n\n\n\n\n\n\n\n\ndatetime\nmin\nmax\nmean\ncount\nsum\nstd\nmedian\nmajority\nminority\nunique\nhistogram\nvalid_percent\nmasked_pixels\nvalid_pixels\npercentile_2\npercentile_98\ndate\n\n\n\n\n0\n2023-12-01T00:00:00Z\n0.0\n1.959697e-09\n1.326263e-10\n1184.0\n1.570295e-07\n2.224454e-10\n4.504551e-11\n0.0\n3.515132e-16\n1175.0\n[[946, 127, 48, 31, 16, 7, 4, 3, 0, 2], [0.0, ...\n98.67\n16.0\n1184.0\n3.562271e-13\n8.656202e-10\n2023-12-01 00:00:00+00:00\n\n\n1\n2023-11-01T00:00:00Z\n0.0\n1.458412e-09\n7.439366e-11\n1184.0\n8.808209e-08\n1.382741e-10\n2.440544e-11\n0.0\n4.514389e-16\n1175.0\n[[1022, 88, 41, 14, 7, 7, 2, 1, 1, 1], [0.0, 1...\n98.67\n16.0\n1184.0\n1.529063e-13\n4.990412e-10\n2023-11-01 00:00:00+00:00\n\n\n2\n2023-10-01T00:00:00Z\n0.0\n1.405805e-09\n6.002457e-11\n1184.0\n7.106909e-08\n1.099642e-10\n1.825424e-11\n0.0\n6.518826e-16\n1175.0\n[[1038, 88, 41, 7, 5, 3, 1, 0, 0, 1], [0.0, 1....\n98.67\n16.0\n1184.0\n1.417882e-13\n3.901165e-10\n2023-10-01 00:00:00+00:00\n\n\n3\n2023-09-01T00:00:00Z\n0.0\n1.231651e-09\n4.619366e-11\n1184.0\n5.469329e-08\n9.049517e-11\n1.315866e-11\n0.0\n7.323344e-16\n1175.0\n[[1059, 89, 20, 9, 2, 1, 2, 1, 0, 1], [0.0, 1....\n98.67\n16.0\n1184.0\n1.210498e-13\n2.977404e-10\n2023-09-01 00:00:00+00:00\n\n\n4\n2023-08-01T00:00:00Z\n0.0\n1.872944e-09\n8.588581e-11\n1184.0\n1.016888e-07\n1.791557e-10\n1.520345e-11\n0.0\n2.753062e-15\n1175.0\n[[1019, 99, 31, 15, 5, 10, 2, 2, 0, 1], [0.0, ...\n98.67\n16.0\n1184.0\n1.849912e-13\n6.827569e-10\n2023-08-01 00:00:00+00:00",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Datasets",
      "Wetland Methane Emissions, LPJ-EOSIM Model"
    ]
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#time-series-visualization",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#time-series-visualization",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Time Series Visualization",
    "text": "Time Series Visualization\nPlot the temporal evolution of methane emissions over the Amazon basin.\n\nfig = plt.figure(figsize=(16, 8))\n\nplt.plot(\n    df[\"date\"],\n    df[\"max\"],\n    color=\"darkgreen\",\n    linestyle=\"-\",\n    linewidth=0.8,\n    label=\"Maximum monthly CH emissions\",\n)\n\nplt.plot(\n    df[\"date\"],\n    df[\"mean\"],\n    color=\"forestgreen\",\n    linestyle=\"--\",\n    linewidth=0.5,\n    label=\"Mean monthly CH emissions\",\n)\n\nplt.legend()\nplt.xlabel(\"Date\")\nplt.ylabel(\"CH emissions (g/m)\")\nplt.title(\"Monthly Methane Emissions from Wetlands - Amazon Basin\")\nplt.tight_layout()",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Datasets",
      "Wetland Methane Emissions, LPJ-EOSIM Model"
    ]
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#regional-snapshot",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#regional-snapshot",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Regional Snapshot",
    "text": "Regional Snapshot\nVisualize a specific observation over the Amazon region.\n\n# Select a specific observation\nprint(f\"Selected date: {items[10]['properties']['start_datetime']}\")\n\nSelected date: 2023-02-01T00:00:00Z\n\n\n\nselected_tile = requests.get(\n    f\"{RASTER_API_URL}/collections/{items[10]['collection']}/items/{items[10]['id']}/WebMercatorQuad/tilejson.json?&assets={asset_name}\"\n    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n    f\"&rescale={rescale_values['min']},{rescale_values['max']}\"\n).json()\n\nselected_tile\n\n{'tilejson': '2.2.0',\n 'version': '1.0.0',\n 'scheme': 'xyz',\n 'tiles': ['https://api.dev.veda.grss.cloud/raster/collections/LPJ_EOSIM_L2_MCH4E.001/items/LPJ_EOSIM_L2_MCH4E.001-202302/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?assets=ensemble-mean-ch4-wetlands-emissions&color_formula=gamma+r+1.05&colormap_name=magma&rescale=0.0%2C0.0003'],\n 'minzoom': 0,\n 'maxzoom': 24,\n 'bounds': [-180.0, -90.0, 180.0, 90.0],\n 'center': [0.0, 0.0, 0]}\n\n\n\n# Create map centered on Amazon region\nregional_map = Map(\n    tiles=\"OpenStreetMap\",\n    location=[-5, -60],\n    zoom_start=5,\n)\n\ntile_layer = TileLayer(\n    tiles=selected_tile[\"tiles\"][0],\n    attr=\"GRSS VEDA\",\n    opacity=0.6\n)\ntile_layer.add_to(regional_map)\n\nregional_map\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Datasets",
      "Wetland Methane Emissions, LPJ-EOSIM Model"
    ]
  },
  {
    "objectID": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#summary",
    "href": "user-guide/notebooks/datasets/lpjeosim-wetlandch4-monthgrid-v1_User_Notebook.html#summary",
    "title": "Wetland Methane Emissions, LPJ-EOSIM Model",
    "section": "Summary",
    "text": "Summary\nThis notebook demonstrated how to: 1. Connect to the GRSS VEDA STAC API and query collection metadata 2. Retrieve and count available data granules 3. Generate and compare map visualizations across different time periods 4. Define areas of interest and compute zonal statistics 5. Create time series plots to analyze temporal patterns in methane emissions",
    "crumbs": [
      "User Guide",
      "Notebooks",
      "Datasets",
      "Wetland Methane Emissions, LPJ-EOSIM Model"
    ]
  }
]